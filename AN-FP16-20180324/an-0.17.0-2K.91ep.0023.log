I0228 07:56:38.454120  7805 caffe.cpp:639] This is NVCaffe 0.17.0 started at Wed Feb 28 07:56:37 2018
I0228 07:56:38.454349  7805 caffe.cpp:641] CuDNN version: 7101
I0228 07:56:38.454355  7805 caffe.cpp:642] CuBLAS version: 9000
I0228 07:56:38.454356  7805 caffe.cpp:643] CUDA version: 9000
I0228 07:56:38.454358  7805 caffe.cpp:644] CUDA driver version: 9000
I0228 07:56:38.454363  7805 caffe.cpp:645] Arguments: 
[0]: caffe
[1]: train
[2]: --solver
[3]: solver_fp16_2048.prototxt
[4]: --gpu=all
I0228 07:56:43.048202  7805 gpu_memory.cpp:105] GPUMemory::Manager initialized
I0228 07:56:43.049985  7805 gpu_memory.cpp:107] Total memory: 16936927232, Free: 16433610752, dev_info[0]: total=16936927232 free=16433610752
I0228 07:56:43.051663  7805 gpu_memory.cpp:107] Total memory: 16936927232, Free: 16433610752, dev_info[1]: total=16936927232 free=16481845248
I0228 07:56:43.053411  7805 gpu_memory.cpp:107] Total memory: 16936927232, Free: 16433610752, dev_info[2]: total=16936927232 free=16481845248
I0228 07:56:43.055081  7805 gpu_memory.cpp:107] Total memory: 16936927232, Free: 16433610752, dev_info[3]: total=16936927232 free=16481845248
I0228 07:56:43.056746  7805 gpu_memory.cpp:107] Total memory: 16936927232, Free: 16433610752, dev_info[4]: total=16936927232 free=16481779712
I0228 07:56:43.058486  7805 gpu_memory.cpp:107] Total memory: 16936927232, Free: 16433610752, dev_info[5]: total=16936927232 free=16481845248
I0228 07:56:43.060128  7805 gpu_memory.cpp:107] Total memory: 16936927232, Free: 16433610752, dev_info[6]: total=16936927232 free=16481845248
I0228 07:56:43.061728  7805 gpu_memory.cpp:107] Total memory: 16936927232, Free: 16433610752, dev_info[7]: total=16936927232 free=16481845248
I0228 07:56:43.061736  7805 caffe.cpp:188] Using GPUs 0, 1, 2, 3, 4, 5, 6, 7
I0228 07:56:43.063071  7805 caffe.cpp:193] GPU 0: Tesla V100-SXM2-16GB
I0228 07:56:43.064427  7805 caffe.cpp:193] GPU 1: Tesla V100-SXM2-16GB
I0228 07:56:43.065762  7805 caffe.cpp:193] GPU 2: Tesla V100-SXM2-16GB
I0228 07:56:43.067070  7805 caffe.cpp:193] GPU 3: Tesla V100-SXM2-16GB
I0228 07:56:43.068379  7805 caffe.cpp:193] GPU 4: Tesla V100-SXM2-16GB
I0228 07:56:43.069628  7805 caffe.cpp:193] GPU 5: Tesla V100-SXM2-16GB
I0228 07:56:43.070865  7805 caffe.cpp:193] GPU 6: Tesla V100-SXM2-16GB
I0228 07:56:43.072110  7805 caffe.cpp:193] GPU 7: Tesla V100-SXM2-16GB
I0228 07:56:43.072208  7805 solver.cpp:40] Solver data type: FLOAT16
I0228 07:56:43.091320  7805 solver.cpp:43] Initializing solver from parameters: 
test_iter: 1042
test_interval: 200000
base_lr: 1
display: 100
max_iter: 56875
lr_policy: "poly"
power: 2
momentum: 0.9
weight_decay: 0.0005
snapshot: 1500000
snapshot_prefix: "snapshots/alexnet_fp16_2K.91ep.0023"
solver_mode: GPU
device_id: 0
net: "train_val_fp16_2048.prototxt"
snapshot_after_train: false
min_lr: 1e-05
solver_data_type: FLOAT16
larc: true
larc_policy: "clip"
larc_eta: 0.0023
test_and_snapshot_last_epochs: 5
I0228 07:56:43.095706  7805 solver.cpp:84] Creating training net from net file: train_val_fp16_2048.prototxt
I0228 07:56:43.098213  7805 net.cpp:444] The NetState phase (0) differed from the phase (1) specified by a rule in layer data
I0228 07:56:43.098254  7805 net.cpp:444] The NetState phase (0) differed from the phase (1) specified by a rule in layer top-1
I0228 07:56:43.098259  7805 net.cpp:444] The NetState phase (0) differed from the phase (1) specified by a rule in layer top-5
I0228 07:56:43.098616  7805 net.cpp:68] Initializing net from parameters: 
name: "AlexNet-fp16"
state {
  phase: TRAIN
}
default_forward_type: FLOAT16
default_backward_type: FLOAT16
default_forward_math: FLOAT16
default_backward_math: FLOAT16
global_grad_scale: 80
global_grad_scale_adaptive: true
layer {
  name: "data"
  type: "Data"
  top: "data"
  top: "label"
  include {
    phase: TRAIN
  }
  transform_param {
    mirror: true
    crop_size: 227
    mean_file: "/data/imagenet/imagenet_256x256_mean.binaryproto"
    use_gpu_transform: true
  }
  data_param {
    source: "/data/imagenet/train-lmdb-uncompressed-256x256"
    batch_size: 256
    backend: LMDB
    cache: true
    shuffle: true
  }
}
layer {
  name: "conv1"
  type: "Convolution"
  bottom: "data"
  top: "conv1"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  convolution_param {
    num_output: 96
    kernel_size: 11
    stride: 4
    weight_filler {
      type: "gaussian"
      std: 0.01
    }
    bias_filler {
      type: "constant"
      value: 0
    }
    cudnn_convolution_algo_seeker: FINDEX
  }
}
layer {
  name: "relu1"
  type: "ReLU"
  bottom: "conv1"
  top: "conv1"
}
layer {
  name: "norm1"
  type: "LRN"
  bottom: "conv1"
  top: "norm1"
  lrn_param {
    local_size: 5
    alpha: 0.0001
    beta: 0.75
  }
}
layer {
  name: "pool1"
  type: "Pooling"
  bottom: "norm1"
  top: "pool1"
  pooling_param {
    pool: MAX
    kernel_size: 3
    stride: 2
  }
}
layer {
  name: "conv2"
  type: "Convolution"
  bottom: "pool1"
  top: "conv2"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  convolution_param {
    num_output: 256
    pad: 2
    kernel_size: 5
    group: 2
    weight_filler {
      type: "gaussian"
      std: 0.01
    }
    bias_filler {
      type: "constant"
      value: 0.1
    }
    cudnn_convolution_algo_seeker: FINDEX
  }
}
layer {
  name: "relu2"
  type: "ReLU"
  bottom: "conv2"
  top: "conv2"
}
layer {
  name: "norm2"
  type: "LRN"
  bottom: "conv2"
  top: "norm2"
  lrn_param {
    local_size: 5
    alpha: 0.0001
    beta: 0.75
  }
}
layer {
  name: "pool2"
  type: "Pooling"
  bottom: "norm2"
  top: "pool2"
  pooling_param {
    pool: MAX
    kernel_size: 3
    stride: 2
  }
}
layer {
  name: "conv3"
  type: "Convolution"
  bottom: "pool2"
  top: "conv3"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  convolution_param {
    num_output: 384
    pad: 1
    kernel_size: 3
    weight_filler {
      type: "gaussian"
      std: 0.01
    }
    bias_filler {
      type: "constant"
      value: 0
    }
    cudnn_convolution_algo_seeker: FINDEX
  }
}
layer {
  name: "relu3"
  type: "ReLU"
  bottom: "conv3"
  top: "conv3"
}
layer {
  name: "conv4"
  type: "Convolution"
  bottom: "conv3"
  top: "conv4"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  convolution_param {
    num_output: 384
    pad: 1
    kernel_size: 3
    group: 2
    weight_filler {
      type: "gaussian"
      std: 0.01
    }
    bias_filler {
      type: "constant"
      value: 0.1
    }
    cudnn_convolution_algo_seeker: FINDEX
  }
}
layer {
  name: "relu4"
  type: "ReLU"
  bottom: "conv4"
  top: "conv4"
}
layer {
  name: "conv5"
  type: "Convolution"
  bottom: "conv4"
  top: "conv5"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  convolution_param {
    num_output: 256
    pad: 1
    kernel_size: 3
    group: 2
    weight_filler {
      type: "gaussian"
      std: 0.01
    }
    bias_filler {
      type: "constant"
      value: 0.1
    }
    cudnn_convolution_algo_seeker: FINDEX
  }
}
layer {
  name: "relu5"
  type: "ReLU"
  bottom: "conv5"
  top: "conv5"
}
layer {
  name: "pool5"
  type: "Pooling"
  bottom: "conv5"
  top: "pool5"
  pooling_param {
    pool: MAX
    kernel_size: 3
    stride: 2
  }
}
layer {
  name: "fc6"
  type: "InnerProduct"
  bottom: "pool5"
  top: "fc6"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  inner_product_param {
    num_output: 4096
    weight_filler {
      type: "gaussian"
      std: 0.005
    }
    bias_filler {
      type: "constant"
      value: 0.1
    }
  }
}
layer {
  name: "relu6"
  type: "ReLU"
  bottom: "fc6"
  top: "fc6"
}
layer {
  name: "drop6"
  type: "Dropout"
  bottom: "fc6"
  top: "fc6"
  dropout_param {
    dropout_ratio: 0.5
  }
}
layer {
  name: "fc7"
  type: "InnerProduct"
  bottom: "fc6"
  top: "fc7"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  inner_product_param {
    num_output: 4096
    weight_filler {
      type: "gaussian"
      std: 0.005
    }
    bias_filler {
      type: "constant"
      value: 0.1
    }
  }
}
layer {
  name: "relu7"
  type: "ReLU"
  bottom: "fc7"
  top: "fc7"
}
layer {
  name: "drop7"
  type: "Dropout"
  bottom: "fc7"
  top: "fc7"
  dropout_param {
    dropout_ratio: 0.5
  }
}
layer {
  name: "fc8"
  type: "InnerProduct"
  bottom: "fc7"
  top: "fc8"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  inner_product_param {
    num_output: 1000
    weight_filler {
      type: "gaussian"
      std: 0.01
    }
    bias_filler {
      type: "constant"
      value: 0
    }
  }
}
layer {
  name: "loss"
  type: "SoftmaxWithLoss"
  bottom: "fc8"
  bottom: "label"
  top: "loss"
}
I0228 07:56:43.098845  7805 layer_factory.hpp:172] Creating layer 'data' of type 'Data'
I0228 07:56:43.098862  7805 layer_factory.hpp:184] Layer's types are Ftype:FLOAT16 Btype:FLOAT Fmath:FLOAT16 Bmath:FLOAT16
I0228 07:56:43.099298  7805 internal_thread.cpp:19] Starting 1 internal thread(s) on device 0
I0228 07:56:43.099488  7805 data_transformer.cpp:40] Loading mean file from: /data/imagenet/imagenet_256x256_mean.binaryproto
I0228 07:56:43.101106  7879 blocking_queue.cpp:40] Data layer prefetch queue empty
I0228 07:56:43.111033  7805 data_transformer.cpp:40] Loading mean file from: /data/imagenet/imagenet_256x256_mean.binaryproto
I0228 07:56:43.114188  7805 net.cpp:187] Created Layer data (0)
I0228 07:56:43.114199  7805 net.cpp:529] data -> data
I0228 07:56:43.114225  7805 net.cpp:529] data -> label
I0228 07:56:43.114259  7805 data_reader.cpp:58] Sample Data Reader threads: 1, out queues: 1, depth: 256
I0228 07:56:43.114346  7805 internal_thread.cpp:19] Starting 1 internal thread(s) on device 0
I0228 07:56:43.116099  7880 db_lmdb.cpp:36] Opened lmdb /data/imagenet/train-lmdb-uncompressed-256x256
I0228 07:56:43.116632  7805 data_layer.cpp:186] [0] Transform on GPU enabled
I0228 07:56:43.121294  7805 data_layer.cpp:199] [0] Output data size: 256, 3, 227, 227
I0228 07:56:43.121309  7805 data_transformer.cpp:40] Loading mean file from: /data/imagenet/imagenet_256x256_mean.binaryproto
I0228 07:56:43.127847  7805 data_transformer.cpp:40] Loading mean file from: /data/imagenet/imagenet_256x256_mean.binaryproto
I0228 07:56:43.130915  7805 internal_thread.cpp:19] Starting 1 internal thread(s) on device 0
I0228 07:56:43.130981  7805 net.cpp:247] Setting up data
I0228 07:56:43.131017  7805 net.cpp:254] TRAIN Top shape for layer 0 'data' 256 3 227 227 (39574272)
I0228 07:56:43.131027  7805 net.cpp:254] TRAIN Top shape for layer 0 'data' 256 (256)
I0228 07:56:43.131036  7805 layer_factory.hpp:172] Creating layer 'conv1' of type 'Convolution'
I0228 07:56:43.131057  7805 layer_factory.hpp:184] Layer's types are Ftype:FLOAT16 Btype:FLOAT16 Fmath:FLOAT16 Bmath:FLOAT16
I0228 07:56:43.132704  7805 net.cpp:187] Created Layer conv1 (1)
I0228 07:56:43.132728  7805 net.cpp:559] conv1 <- data
I0228 07:56:43.132762  7805 net.cpp:529] conv1 -> conv1
I0228 07:56:44.005686  7805 net.cpp:247] Setting up conv1
I0228 07:56:44.005729  7805 net.cpp:254] TRAIN Top shape for layer 1 'conv1' 256 96 55 55 (74342400)
I0228 07:56:44.005756  7805 layer_factory.hpp:172] Creating layer 'relu1' of type 'ReLU'
I0228 07:56:44.005765  7805 layer_factory.hpp:184] Layer's types are Ftype:FLOAT16 Btype:FLOAT16 Fmath:FLOAT16 Bmath:FLOAT16
I0228 07:56:44.005779  7805 net.cpp:187] Created Layer relu1 (2)
I0228 07:56:44.005784  7805 net.cpp:559] relu1 <- conv1
I0228 07:56:44.005790  7805 net.cpp:514] relu1 -> conv1 (in-place)
I0228 07:56:44.005820  7805 net.cpp:247] Setting up relu1
I0228 07:56:44.005827  7805 net.cpp:254] TRAIN Top shape for layer 2 'relu1' 256 96 55 55 (74342400)
I0228 07:56:44.005843  7805 layer_factory.hpp:172] Creating layer 'norm1' of type 'LRN'
I0228 07:56:44.005847  7805 layer_factory.hpp:184] Layer's types are Ftype:FLOAT16 Btype:FLOAT16 Fmath:FLOAT16 Bmath:FLOAT16
I0228 07:56:44.005865  7805 net.cpp:187] Created Layer norm1 (3)
I0228 07:56:44.005870  7805 net.cpp:559] norm1 <- conv1
I0228 07:56:44.005874  7805 net.cpp:529] norm1 -> norm1
I0228 07:56:44.006076  7805 net.cpp:247] Setting up norm1
I0228 07:56:44.006086  7805 net.cpp:254] TRAIN Top shape for layer 3 'norm1' 256 96 55 55 (74342400)
I0228 07:56:44.006124  7805 layer_factory.hpp:172] Creating layer 'pool1' of type 'Pooling'
I0228 07:56:44.006129  7805 layer_factory.hpp:184] Layer's types are Ftype:FLOAT16 Btype:FLOAT16 Fmath:FLOAT16 Bmath:FLOAT16
I0228 07:56:44.006139  7805 net.cpp:187] Created Layer pool1 (4)
I0228 07:56:44.006144  7805 net.cpp:559] pool1 <- norm1
I0228 07:56:44.006147  7805 net.cpp:529] pool1 -> pool1
I0228 07:56:44.006367  7805 net.cpp:247] Setting up pool1
I0228 07:56:44.006377  7805 net.cpp:254] TRAIN Top shape for layer 4 'pool1' 256 96 27 27 (17915904)
I0228 07:56:44.006381  7805 layer_factory.hpp:172] Creating layer 'conv2' of type 'Convolution'
I0228 07:56:44.006386  7805 layer_factory.hpp:184] Layer's types are Ftype:FLOAT16 Btype:FLOAT16 Fmath:FLOAT16 Bmath:FLOAT16
I0228 07:56:44.006399  7805 net.cpp:187] Created Layer conv2 (5)
I0228 07:56:44.006403  7805 net.cpp:559] conv2 <- pool1
I0228 07:56:44.006407  7805 net.cpp:529] conv2 -> conv2
I0228 07:56:44.019733  7805 net.cpp:247] Setting up conv2
I0228 07:56:44.019749  7805 net.cpp:254] TRAIN Top shape for layer 5 'conv2' 256 256 27 27 (47775744)
I0228 07:56:44.019759  7805 layer_factory.hpp:172] Creating layer 'relu2' of type 'ReLU'
I0228 07:56:44.019762  7805 layer_factory.hpp:184] Layer's types are Ftype:FLOAT16 Btype:FLOAT16 Fmath:FLOAT16 Bmath:FLOAT16
I0228 07:56:44.019768  7805 net.cpp:187] Created Layer relu2 (6)
I0228 07:56:44.019773  7805 net.cpp:559] relu2 <- conv2
I0228 07:56:44.019776  7805 net.cpp:514] relu2 -> conv2 (in-place)
I0228 07:56:44.019783  7805 net.cpp:247] Setting up relu2
I0228 07:56:44.019786  7805 net.cpp:254] TRAIN Top shape for layer 6 'relu2' 256 256 27 27 (47775744)
I0228 07:56:44.019791  7805 layer_factory.hpp:172] Creating layer 'norm2' of type 'LRN'
I0228 07:56:44.019794  7805 layer_factory.hpp:184] Layer's types are Ftype:FLOAT16 Btype:FLOAT16 Fmath:FLOAT16 Bmath:FLOAT16
I0228 07:56:44.019801  7805 net.cpp:187] Created Layer norm2 (7)
I0228 07:56:44.019804  7805 net.cpp:559] norm2 <- conv2
I0228 07:56:44.019809  7805 net.cpp:529] norm2 -> norm2
I0228 07:56:44.019964  7805 net.cpp:247] Setting up norm2
I0228 07:56:44.019973  7805 net.cpp:254] TRAIN Top shape for layer 7 'norm2' 256 256 27 27 (47775744)
I0228 07:56:44.019978  7805 layer_factory.hpp:172] Creating layer 'pool2' of type 'Pooling'
I0228 07:56:44.019981  7805 layer_factory.hpp:184] Layer's types are Ftype:FLOAT16 Btype:FLOAT16 Fmath:FLOAT16 Bmath:FLOAT16
I0228 07:56:44.019989  7805 net.cpp:187] Created Layer pool2 (8)
I0228 07:56:44.019991  7805 net.cpp:559] pool2 <- norm2
I0228 07:56:44.019995  7805 net.cpp:529] pool2 -> pool2
I0228 07:56:44.020198  7805 net.cpp:247] Setting up pool2
I0228 07:56:44.020206  7805 net.cpp:254] TRAIN Top shape for layer 8 'pool2' 256 256 13 13 (11075584)
I0228 07:56:44.020211  7805 layer_factory.hpp:172] Creating layer 'conv3' of type 'Convolution'
I0228 07:56:44.020215  7805 layer_factory.hpp:184] Layer's types are Ftype:FLOAT16 Btype:FLOAT16 Fmath:FLOAT16 Bmath:FLOAT16
I0228 07:56:44.020226  7805 net.cpp:187] Created Layer conv3 (9)
I0228 07:56:44.020231  7805 net.cpp:559] conv3 <- pool2
I0228 07:56:44.020234  7805 net.cpp:529] conv3 -> conv3
I0228 07:56:44.038699  7805 net.cpp:247] Setting up conv3
I0228 07:56:44.038717  7805 net.cpp:254] TRAIN Top shape for layer 9 'conv3' 256 384 13 13 (16613376)
I0228 07:56:44.038725  7805 layer_factory.hpp:172] Creating layer 'relu3' of type 'ReLU'
I0228 07:56:44.038729  7805 layer_factory.hpp:184] Layer's types are Ftype:FLOAT16 Btype:FLOAT16 Fmath:FLOAT16 Bmath:FLOAT16
I0228 07:56:44.038738  7805 net.cpp:187] Created Layer relu3 (10)
I0228 07:56:44.038741  7805 net.cpp:559] relu3 <- conv3
I0228 07:56:44.038745  7805 net.cpp:514] relu3 -> conv3 (in-place)
I0228 07:56:44.038751  7805 net.cpp:247] Setting up relu3
I0228 07:56:44.038765  7805 net.cpp:254] TRAIN Top shape for layer 10 'relu3' 256 384 13 13 (16613376)
I0228 07:56:44.038770  7805 layer_factory.hpp:172] Creating layer 'conv4' of type 'Convolution'
I0228 07:56:44.038774  7805 layer_factory.hpp:184] Layer's types are Ftype:FLOAT16 Btype:FLOAT16 Fmath:FLOAT16 Bmath:FLOAT16
I0228 07:56:44.038805  7805 net.cpp:187] Created Layer conv4 (11)
I0228 07:56:44.038810  7805 net.cpp:559] conv4 <- conv3
I0228 07:56:44.038815  7805 net.cpp:529] conv4 -> conv4
I0228 07:56:44.050508  7805 net.cpp:247] Setting up conv4
I0228 07:56:44.050523  7805 net.cpp:254] TRAIN Top shape for layer 11 'conv4' 256 384 13 13 (16613376)
I0228 07:56:44.050529  7805 layer_factory.hpp:172] Creating layer 'relu4' of type 'ReLU'
I0228 07:56:44.050534  7805 layer_factory.hpp:184] Layer's types are Ftype:FLOAT16 Btype:FLOAT16 Fmath:FLOAT16 Bmath:FLOAT16
I0228 07:56:44.050539  7805 net.cpp:187] Created Layer relu4 (12)
I0228 07:56:44.050541  7805 net.cpp:559] relu4 <- conv4
I0228 07:56:44.050545  7805 net.cpp:514] relu4 -> conv4 (in-place)
I0228 07:56:44.050551  7805 net.cpp:247] Setting up relu4
I0228 07:56:44.050555  7805 net.cpp:254] TRAIN Top shape for layer 12 'relu4' 256 384 13 13 (16613376)
I0228 07:56:44.050576  7805 layer_factory.hpp:172] Creating layer 'conv5' of type 'Convolution'
I0228 07:56:44.050580  7805 layer_factory.hpp:184] Layer's types are Ftype:FLOAT16 Btype:FLOAT16 Fmath:FLOAT16 Bmath:FLOAT16
I0228 07:56:44.050614  7805 net.cpp:187] Created Layer conv5 (13)
I0228 07:56:44.050618  7805 net.cpp:559] conv5 <- conv4
I0228 07:56:44.050622  7805 net.cpp:529] conv5 -> conv5
I0228 07:56:44.062642  7805 net.cpp:247] Setting up conv5
I0228 07:56:44.062659  7805 net.cpp:254] TRAIN Top shape for layer 13 'conv5' 256 256 13 13 (11075584)
I0228 07:56:44.062670  7805 layer_factory.hpp:172] Creating layer 'relu5' of type 'ReLU'
I0228 07:56:44.062674  7805 layer_factory.hpp:184] Layer's types are Ftype:FLOAT16 Btype:FLOAT16 Fmath:FLOAT16 Bmath:FLOAT16
I0228 07:56:44.062680  7805 net.cpp:187] Created Layer relu5 (14)
I0228 07:56:44.062683  7805 net.cpp:559] relu5 <- conv5
I0228 07:56:44.062687  7805 net.cpp:514] relu5 -> conv5 (in-place)
I0228 07:56:44.062693  7805 net.cpp:247] Setting up relu5
I0228 07:56:44.062716  7805 net.cpp:254] TRAIN Top shape for layer 14 'relu5' 256 256 13 13 (11075584)
I0228 07:56:44.062721  7805 layer_factory.hpp:172] Creating layer 'pool5' of type 'Pooling'
I0228 07:56:44.062726  7805 layer_factory.hpp:184] Layer's types are Ftype:FLOAT16 Btype:FLOAT16 Fmath:FLOAT16 Bmath:FLOAT16
I0228 07:56:44.062733  7805 net.cpp:187] Created Layer pool5 (15)
I0228 07:56:44.062757  7805 net.cpp:559] pool5 <- conv5
I0228 07:56:44.062777  7805 net.cpp:529] pool5 -> pool5
I0228 07:56:44.063103  7805 net.cpp:247] Setting up pool5
I0228 07:56:44.063115  7805 net.cpp:254] TRAIN Top shape for layer 15 'pool5' 256 256 6 6 (2359296)
I0228 07:56:44.063122  7805 layer_factory.hpp:172] Creating layer 'fc6' of type 'InnerProduct'
I0228 07:56:44.063130  7805 layer_factory.hpp:184] Layer's types are Ftype:FLOAT16 Btype:FLOAT16 Fmath:FLOAT16 Bmath:FLOAT16
I0228 07:56:44.063161  7805 net.cpp:187] Created Layer fc6 (16)
I0228 07:56:44.063169  7805 net.cpp:559] fc6 <- pool5
I0228 07:56:44.063174  7805 net.cpp:529] fc6 -> fc6
I0228 07:56:44.693166  7805 net.cpp:247] Setting up fc6
I0228 07:56:44.693200  7805 net.cpp:254] TRAIN Top shape for layer 16 'fc6' 256 4096 (1048576)
I0228 07:56:44.693213  7805 layer_factory.hpp:172] Creating layer 'relu6' of type 'ReLU'
I0228 07:56:44.693220  7805 layer_factory.hpp:184] Layer's types are Ftype:FLOAT16 Btype:FLOAT16 Fmath:FLOAT16 Bmath:FLOAT16
I0228 07:56:44.693230  7805 net.cpp:187] Created Layer relu6 (17)
I0228 07:56:44.693234  7805 net.cpp:559] relu6 <- fc6
I0228 07:56:44.693258  7805 net.cpp:514] relu6 -> fc6 (in-place)
I0228 07:56:44.693270  7805 net.cpp:247] Setting up relu6
I0228 07:56:44.693302  7805 net.cpp:254] TRAIN Top shape for layer 17 'relu6' 256 4096 (1048576)
I0228 07:56:44.693306  7805 layer_factory.hpp:172] Creating layer 'drop6' of type 'Dropout'
I0228 07:56:44.693321  7805 layer_factory.hpp:184] Layer's types are Ftype:FLOAT16 Btype:FLOAT16 Fmath:FLOAT16 Bmath:FLOAT16
I0228 07:56:44.693349  7805 net.cpp:187] Created Layer drop6 (18)
I0228 07:56:44.693373  7805 net.cpp:559] drop6 <- fc6
I0228 07:56:44.693377  7805 net.cpp:514] drop6 -> fc6 (in-place)
I0228 07:56:44.702522  7805 net.cpp:247] Setting up drop6
I0228 07:56:44.702538  7805 net.cpp:254] TRAIN Top shape for layer 18 'drop6' 256 4096 (1048576)
I0228 07:56:44.702543  7805 layer_factory.hpp:172] Creating layer 'fc7' of type 'InnerProduct'
I0228 07:56:44.702548  7805 layer_factory.hpp:184] Layer's types are Ftype:FLOAT16 Btype:FLOAT16 Fmath:FLOAT16 Bmath:FLOAT16
I0228 07:56:44.702579  7805 net.cpp:187] Created Layer fc7 (19)
I0228 07:56:44.702582  7805 net.cpp:559] fc7 <- fc6
I0228 07:56:44.702587  7805 net.cpp:529] fc7 -> fc7
I0228 07:56:44.984513  7805 net.cpp:247] Setting up fc7
I0228 07:56:44.984544  7805 net.cpp:254] TRAIN Top shape for layer 19 'fc7' 256 4096 (1048576)
I0228 07:56:44.984557  7805 layer_factory.hpp:172] Creating layer 'relu7' of type 'ReLU'
I0228 07:56:44.984563  7805 layer_factory.hpp:184] Layer's types are Ftype:FLOAT16 Btype:FLOAT16 Fmath:FLOAT16 Bmath:FLOAT16
I0228 07:56:44.984571  7805 net.cpp:187] Created Layer relu7 (20)
I0228 07:56:44.984576  7805 net.cpp:559] relu7 <- fc7
I0228 07:56:44.984599  7805 net.cpp:514] relu7 -> fc7 (in-place)
I0228 07:56:44.984609  7805 net.cpp:247] Setting up relu7
I0228 07:56:44.984635  7805 net.cpp:254] TRAIN Top shape for layer 20 'relu7' 256 4096 (1048576)
I0228 07:56:44.984659  7805 layer_factory.hpp:172] Creating layer 'drop7' of type 'Dropout'
I0228 07:56:44.984664  7805 layer_factory.hpp:184] Layer's types are Ftype:FLOAT16 Btype:FLOAT16 Fmath:FLOAT16 Bmath:FLOAT16
I0228 07:56:44.984674  7805 net.cpp:187] Created Layer drop7 (21)
I0228 07:56:44.984679  7805 net.cpp:559] drop7 <- fc7
I0228 07:56:44.984683  7805 net.cpp:514] drop7 -> fc7 (in-place)
I0228 07:56:44.993558  7805 net.cpp:247] Setting up drop7
I0228 07:56:44.993574  7805 net.cpp:254] TRAIN Top shape for layer 21 'drop7' 256 4096 (1048576)
I0228 07:56:44.993580  7805 layer_factory.hpp:172] Creating layer 'fc8' of type 'InnerProduct'
I0228 07:56:44.993584  7805 layer_factory.hpp:184] Layer's types are Ftype:FLOAT16 Btype:FLOAT16 Fmath:FLOAT16 Bmath:FLOAT16
I0228 07:56:44.993592  7805 net.cpp:187] Created Layer fc8 (22)
I0228 07:56:44.993597  7805 net.cpp:559] fc8 <- fc7
I0228 07:56:44.993600  7805 net.cpp:529] fc8 -> fc8
I0228 07:56:45.064867  7805 net.cpp:247] Setting up fc8
I0228 07:56:45.064882  7805 net.cpp:254] TRAIN Top shape for layer 22 'fc8' 256 1000 (256000)
I0228 07:56:45.064890  7805 layer_factory.hpp:172] Creating layer 'loss' of type 'SoftmaxWithLoss'
I0228 07:56:45.064894  7805 layer_factory.hpp:184] Layer's types are Ftype:FLOAT16 Btype:FLOAT16 Fmath:FLOAT16 Bmath:FLOAT16
I0228 07:56:45.064906  7805 net.cpp:187] Created Layer loss (23)
I0228 07:56:45.064910  7805 net.cpp:559] loss <- fc8
I0228 07:56:45.064914  7805 net.cpp:559] loss <- label
I0228 07:56:45.064939  7805 net.cpp:529] loss -> loss
I0228 07:56:45.065821  7805 net.cpp:247] Setting up loss
I0228 07:56:45.065832  7805 net.cpp:254] TRAIN Top shape for layer 23 'loss' (1)
I0228 07:56:45.065852  7805 net.cpp:258]     with loss weight 1
I0228 07:56:45.065914  7805 net.cpp:323] loss needs backward computation.
I0228 07:56:45.065919  7805 net.cpp:323] fc8 needs backward computation.
I0228 07:56:45.065923  7805 net.cpp:323] drop7 needs backward computation.
I0228 07:56:45.065927  7805 net.cpp:323] relu7 needs backward computation.
I0228 07:56:45.065930  7805 net.cpp:323] fc7 needs backward computation.
I0228 07:56:45.065935  7805 net.cpp:323] drop6 needs backward computation.
I0228 07:56:45.065938  7805 net.cpp:323] relu6 needs backward computation.
I0228 07:56:45.065961  7805 net.cpp:323] fc6 needs backward computation.
I0228 07:56:45.065964  7805 net.cpp:323] pool5 needs backward computation.
I0228 07:56:45.065987  7805 net.cpp:323] relu5 needs backward computation.
I0228 07:56:45.065991  7805 net.cpp:323] conv5 needs backward computation.
I0228 07:56:45.066020  7805 net.cpp:323] relu4 needs backward computation.
I0228 07:56:45.066042  7805 net.cpp:323] conv4 needs backward computation.
I0228 07:56:45.066046  7805 net.cpp:323] relu3 needs backward computation.
I0228 07:56:45.066051  7805 net.cpp:323] conv3 needs backward computation.
I0228 07:56:45.066071  7805 net.cpp:323] pool2 needs backward computation.
I0228 07:56:45.066077  7805 net.cpp:323] norm2 needs backward computation.
I0228 07:56:45.066082  7805 net.cpp:323] relu2 needs backward computation.
I0228 07:56:45.066085  7805 net.cpp:323] conv2 needs backward computation.
I0228 07:56:45.066092  7805 net.cpp:323] pool1 needs backward computation.
I0228 07:56:45.066095  7805 net.cpp:323] norm1 needs backward computation.
I0228 07:56:45.066099  7805 net.cpp:323] relu1 needs backward computation.
I0228 07:56:45.066104  7805 net.cpp:323] conv1 needs backward computation.
I0228 07:56:45.066110  7805 net.cpp:325] data does not need backward computation.
I0228 07:56:45.066115  7805 net.cpp:367] This network produces output loss
I0228 07:56:45.066141  7805 net.cpp:390] Top memory (TRAIN) required for data: 1064863748 diff: 1144012804
I0228 07:56:45.066148  7805 net.cpp:393] Bottom memory (TRAIN) required for data: 1064863744 diff: 1144012800
I0228 07:56:45.066151  7805 net.cpp:396] Shared (in-place) memory (TRAIN) by data: 341229568 diff: 341229568
I0228 07:56:45.066155  7805 net.cpp:399] Parameters memory (TRAIN) required for data: 121930448 diff: 121930448
I0228 07:56:45.066159  7805 net.cpp:402] Parameters shared memory (TRAIN) by data: 0 diff: 0
I0228 07:56:45.066161  7805 net.cpp:408] Network initialization done.
I0228 07:56:45.068444  7805 solver.cpp:173] Creating test net (#0) specified by net file: train_val_fp16_2048.prototxt
I0228 07:56:45.068563  7805 net.cpp:444] The NetState phase (1) differed from the phase (0) specified by a rule in layer data
I0228 07:56:45.068899  7805 net.cpp:68] Initializing net from parameters: 
name: "AlexNet-fp16"
state {
  phase: TEST
}
default_forward_type: FLOAT16
default_backward_type: FLOAT16
default_forward_math: FLOAT16
default_backward_math: FLOAT16
global_grad_scale: 80
global_grad_scale_adaptive: true
layer {
  name: "data"
  type: "Data"
  top: "data"
  top: "label"
  include {
    phase: TEST
  }
  transform_param {
    mirror: false
    crop_size: 227
    mean_file: "/data/imagenet/imagenet_256x256_mean.binaryproto"
  }
  data_param {
    source: "/data/imagenet/val-lmdb-uncompressed-256x256"
    batch_size: 6
    backend: LMDB
  }
}
layer {
  name: "conv1"
  type: "Convolution"
  bottom: "data"
  top: "conv1"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  convolution_param {
    num_output: 96
    kernel_size: 11
    stride: 4
    weight_filler {
      type: "gaussian"
      std: 0.01
    }
    bias_filler {
      type: "constant"
      value: 0
    }
    cudnn_convolution_algo_seeker: FINDEX
  }
}
layer {
  name: "relu1"
  type: "ReLU"
  bottom: "conv1"
  top: "conv1"
}
layer {
  name: "norm1"
  type: "LRN"
  bottom: "conv1"
  top: "norm1"
  lrn_param {
    local_size: 5
    alpha: 0.0001
    beta: 0.75
  }
}
layer {
  name: "pool1"
  type: "Pooling"
  bottom: "norm1"
  top: "pool1"
  pooling_param {
    pool: MAX
    kernel_size: 3
    stride: 2
  }
}
layer {
  name: "conv2"
  type: "Convolution"
  bottom: "pool1"
  top: "conv2"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  convolution_param {
    num_output: 256
    pad: 2
    kernel_size: 5
    group: 2
    weight_filler {
      type: "gaussian"
      std: 0.01
    }
    bias_filler {
      type: "constant"
      value: 0.1
    }
    cudnn_convolution_algo_seeker: FINDEX
  }
}
layer {
  name: "relu2"
  type: "ReLU"
  bottom: "conv2"
  top: "conv2"
}
layer {
  name: "norm2"
  type: "LRN"
  bottom: "conv2"
  top: "norm2"
  lrn_param {
    local_size: 5
    alpha: 0.0001
    beta: 0.75
  }
}
layer {
  name: "pool2"
  type: "Pooling"
  bottom: "norm2"
  top: "pool2"
  pooling_param {
    pool: MAX
    kernel_size: 3
    stride: 2
  }
}
layer {
  name: "conv3"
  type: "Convolution"
  bottom: "pool2"
  top: "conv3"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  convolution_param {
    num_output: 384
    pad: 1
    kernel_size: 3
    weight_filler {
      type: "gaussian"
      std: 0.01
    }
    bias_filler {
      type: "constant"
      value: 0
    }
    cudnn_convolution_algo_seeker: FINDEX
  }
}
layer {
  name: "relu3"
  type: "ReLU"
  bottom: "conv3"
  top: "conv3"
}
layer {
  name: "conv4"
  type: "Convolution"
  bottom: "conv3"
  top: "conv4"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  convolution_param {
    num_output: 384
    pad: 1
    kernel_size: 3
    group: 2
    weight_filler {
      type: "gaussian"
      std: 0.01
    }
    bias_filler {
      type: "constant"
      value: 0.1
    }
    cudnn_convolution_algo_seeker: FINDEX
  }
}
layer {
  name: "relu4"
  type: "ReLU"
  bottom: "conv4"
  top: "conv4"
}
layer {
  name: "conv5"
  type: "Convolution"
  bottom: "conv4"
  top: "conv5"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  convolution_param {
    num_output: 256
    pad: 1
    kernel_size: 3
    group: 2
    weight_filler {
      type: "gaussian"
      std: 0.01
    }
    bias_filler {
      type: "constant"
      value: 0.1
    }
    cudnn_convolution_algo_seeker: FINDEX
  }
}
layer {
  name: "relu5"
  type: "ReLU"
  bottom: "conv5"
  top: "conv5"
}
layer {
  name: "pool5"
  type: "Pooling"
  bottom: "conv5"
  top: "pool5"
  pooling_param {
    pool: MAX
    kernel_size: 3
    stride: 2
  }
}
layer {
  name: "fc6"
  type: "InnerProduct"
  bottom: "pool5"
  top: "fc6"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  inner_product_param {
    num_output: 4096
    weight_filler {
      type: "gaussian"
      std: 0.005
    }
    bias_filler {
      type: "constant"
      value: 0.1
    }
  }
}
layer {
  name: "relu6"
  type: "ReLU"
  bottom: "fc6"
  top: "fc6"
}
layer {
  name: "drop6"
  type: "Dropout"
  bottom: "fc6"
  top: "fc6"
  dropout_param {
    dropout_ratio: 0.5
  }
}
layer {
  name: "fc7"
  type: "InnerProduct"
  bottom: "fc6"
  top: "fc7"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  inner_product_param {
    num_output: 4096
    weight_filler {
      type: "gaussian"
      std: 0.005
    }
    bias_filler {
      type: "constant"
      value: 0.1
    }
  }
}
layer {
  name: "relu7"
  type: "ReLU"
  bottom: "fc7"
  top: "fc7"
}
layer {
  name: "drop7"
  type: "Dropout"
  bottom: "fc7"
  top: "fc7"
  dropout_param {
    dropout_ratio: 0.5
  }
}
layer {
  name: "fc8"
  type: "InnerProduct"
  bottom: "fc7"
  top: "fc8"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  inner_product_param {
    num_output: 1000
    weight_filler {
      type: "gaussian"
      std: 0.01
    }
    bias_filler {
      type: "constant"
      value: 0
    }
  }
}
layer {
  name: "loss"
  type: "SoftmaxWithLoss"
  bottom: "fc8"
  bottom: "label"
  top: "loss"
}
layer {
  name: "top-1"
  type: "Accuracy"
  bottom: "fc8"
  bottom: "label"
  top: "top-1"
  include {
    phase: TEST
  }
  accuracy_param {
    top_k: 1
  }
}
layer {
  name: "top-5"
  type: "Accuracy"
  bottom: "fc8"
  bottom: "label"
  top: "top-5"
  include {
    phase: TEST
  }
  accuracy_param {
    top_k: 5
  }
}
I0228 07:56:45.069046  7805 layer_factory.hpp:172] Creating layer 'data' of type 'Data'
I0228 07:56:45.069054  7805 layer_factory.hpp:184] Layer's types are Ftype:FLOAT16 Btype:FLOAT Fmath:FLOAT16 Bmath:FLOAT16
I0228 07:56:45.069082  7805 internal_thread.cpp:19] Starting 1 internal thread(s) on device 0
I0228 07:56:45.069145  7805 data_transformer.cpp:40] Loading mean file from: /data/imagenet/imagenet_256x256_mean.binaryproto
I0228 07:56:45.077788  7805 data_transformer.cpp:40] Loading mean file from: /data/imagenet/imagenet_256x256_mean.binaryproto
I0228 07:56:45.081163  7805 net.cpp:187] Created Layer data (0)
I0228 07:56:45.081173  7805 net.cpp:529] data -> data
I0228 07:56:45.081178  7805 net.cpp:529] data -> label
I0228 07:56:45.081189  7805 data_reader.cpp:58] Data Reader threads: 1, out queues: 1, depth: 6
I0228 07:56:45.081210  7805 internal_thread.cpp:19] Starting 1 internal thread(s) on device 0
I0228 07:56:45.082819  7883 db_lmdb.cpp:36] Opened lmdb /data/imagenet/val-lmdb-uncompressed-256x256
I0228 07:56:45.083875  7805 data_layer.cpp:199] (0) Output data size: 6, 3, 227, 227
I0228 07:56:45.083897  7805 data_transformer.cpp:40] Loading mean file from: /data/imagenet/imagenet_256x256_mean.binaryproto
I0228 07:56:45.090876  7805 data_transformer.cpp:40] Loading mean file from: /data/imagenet/imagenet_256x256_mean.binaryproto
I0228 07:56:45.094065  7805 internal_thread.cpp:19] Starting 1 internal thread(s) on device 0
I0228 07:56:45.094123  7805 net.cpp:247] Setting up data
I0228 07:56:45.094139  7805 net.cpp:254] TEST Top shape for layer 0 'data' 6 3 227 227 (927522)
I0228 07:56:45.094146  7805 net.cpp:254] TEST Top shape for layer 0 'data' 6 (6)
I0228 07:56:45.094156  7805 layer_factory.hpp:172] Creating layer 'label_data_1_split' of type 'Split'
I0228 07:56:45.094162  7805 layer_factory.hpp:184] Layer's types are Ftype:FLOAT16 Btype:FLOAT16 Fmath:FLOAT16 Bmath:FLOAT16
I0228 07:56:45.094184  7805 net.cpp:187] Created Layer label_data_1_split (1)
I0228 07:56:45.094192  7805 net.cpp:559] label_data_1_split <- label
I0228 07:56:45.094199  7805 net.cpp:529] label_data_1_split -> label_data_1_split_0
I0228 07:56:45.094214  7805 net.cpp:529] label_data_1_split -> label_data_1_split_1
I0228 07:56:45.094219  7805 net.cpp:529] label_data_1_split -> label_data_1_split_2
I0228 07:56:45.095947  7884 data_layer.cpp:105] (0) Parser threads: 1
I0228 07:56:45.095958  7884 data_layer.cpp:107] (0) Transformer threads: 1
I0228 07:56:45.095985  7805 net.cpp:247] Setting up label_data_1_split
I0228 07:56:45.096053  7805 net.cpp:254] TEST Top shape for layer 1 'label_data_1_split' 6 (6)
I0228 07:56:45.096071  7805 net.cpp:254] TEST Top shape for layer 1 'label_data_1_split' 6 (6)
I0228 07:56:45.096086  7805 net.cpp:254] TEST Top shape for layer 1 'label_data_1_split' 6 (6)
I0228 07:56:45.096112  7805 layer_factory.hpp:172] Creating layer 'conv1' of type 'Convolution'
I0228 07:56:45.096125  7805 layer_factory.hpp:184] Layer's types are Ftype:FLOAT16 Btype:FLOAT16 Fmath:FLOAT16 Bmath:FLOAT16
I0228 07:56:45.096163  7805 net.cpp:187] Created Layer conv1 (2)
I0228 07:56:45.096184  7805 net.cpp:559] conv1 <- data
I0228 07:56:45.096197  7805 net.cpp:529] conv1 -> conv1
I0228 07:56:45.104531  7805 net.cpp:247] Setting up conv1
I0228 07:56:45.104547  7805 net.cpp:254] TEST Top shape for layer 2 'conv1' 6 96 55 55 (1742400)
I0228 07:56:45.104560  7805 layer_factory.hpp:172] Creating layer 'relu1' of type 'ReLU'
I0228 07:56:45.104564  7805 layer_factory.hpp:184] Layer's types are Ftype:FLOAT16 Btype:FLOAT16 Fmath:FLOAT16 Bmath:FLOAT16
I0228 07:56:45.104570  7805 net.cpp:187] Created Layer relu1 (3)
I0228 07:56:45.104574  7805 net.cpp:559] relu1 <- conv1
I0228 07:56:45.104580  7805 net.cpp:514] relu1 -> conv1 (in-place)
I0228 07:56:45.104588  7805 net.cpp:247] Setting up relu1
I0228 07:56:45.104594  7805 net.cpp:254] TEST Top shape for layer 3 'relu1' 6 96 55 55 (1742400)
I0228 07:56:45.104599  7805 layer_factory.hpp:172] Creating layer 'norm1' of type 'LRN'
I0228 07:56:45.104605  7805 layer_factory.hpp:184] Layer's types are Ftype:FLOAT16 Btype:FLOAT16 Fmath:FLOAT16 Bmath:FLOAT16
I0228 07:56:45.104619  7805 net.cpp:187] Created Layer norm1 (4)
I0228 07:56:45.104636  7805 net.cpp:559] norm1 <- conv1
I0228 07:56:45.104640  7805 net.cpp:529] norm1 -> norm1
I0228 07:56:45.106258  7805 net.cpp:247] Setting up norm1
I0228 07:56:45.106274  7805 net.cpp:254] TEST Top shape for layer 4 'norm1' 6 96 55 55 (1742400)
I0228 07:56:45.106279  7805 layer_factory.hpp:172] Creating layer 'pool1' of type 'Pooling'
I0228 07:56:45.106284  7805 layer_factory.hpp:184] Layer's types are Ftype:FLOAT16 Btype:FLOAT16 Fmath:FLOAT16 Bmath:FLOAT16
I0228 07:56:45.106293  7805 net.cpp:187] Created Layer pool1 (5)
I0228 07:56:45.106297  7805 net.cpp:559] pool1 <- norm1
I0228 07:56:45.106302  7805 net.cpp:529] pool1 -> pool1
I0228 07:56:45.106542  7805 net.cpp:247] Setting up pool1
I0228 07:56:45.106568  7805 net.cpp:254] TEST Top shape for layer 5 'pool1' 6 96 27 27 (419904)
I0228 07:56:45.106573  7805 layer_factory.hpp:172] Creating layer 'conv2' of type 'Convolution'
I0228 07:56:45.106577  7805 layer_factory.hpp:184] Layer's types are Ftype:FLOAT16 Btype:FLOAT16 Fmath:FLOAT16 Bmath:FLOAT16
I0228 07:56:45.106595  7805 net.cpp:187] Created Layer conv2 (6)
I0228 07:56:45.106601  7805 net.cpp:559] conv2 <- pool1
I0228 07:56:45.106606  7805 net.cpp:529] conv2 -> conv2
I0228 07:56:45.113605  7805 net.cpp:247] Setting up conv2
I0228 07:56:45.113620  7805 net.cpp:254] TEST Top shape for layer 6 'conv2' 6 256 27 27 (1119744)
I0228 07:56:45.113628  7805 layer_factory.hpp:172] Creating layer 'relu2' of type 'ReLU'
I0228 07:56:45.113632  7805 layer_factory.hpp:184] Layer's types are Ftype:FLOAT16 Btype:FLOAT16 Fmath:FLOAT16 Bmath:FLOAT16
I0228 07:56:45.113637  7805 net.cpp:187] Created Layer relu2 (7)
I0228 07:56:45.113641  7805 net.cpp:559] relu2 <- conv2
I0228 07:56:45.113646  7805 net.cpp:514] relu2 -> conv2 (in-place)
I0228 07:56:45.113651  7805 net.cpp:247] Setting up relu2
I0228 07:56:45.113654  7805 net.cpp:254] TEST Top shape for layer 7 'relu2' 6 256 27 27 (1119744)
I0228 07:56:45.113662  7805 layer_factory.hpp:172] Creating layer 'norm2' of type 'LRN'
I0228 07:56:45.113664  7805 layer_factory.hpp:184] Layer's types are Ftype:FLOAT16 Btype:FLOAT16 Fmath:FLOAT16 Bmath:FLOAT16
I0228 07:56:45.113677  7805 net.cpp:187] Created Layer norm2 (8)
I0228 07:56:45.113679  7805 net.cpp:559] norm2 <- conv2
I0228 07:56:45.113683  7805 net.cpp:529] norm2 -> norm2
I0228 07:56:45.113857  7805 net.cpp:247] Setting up norm2
I0228 07:56:45.113865  7805 net.cpp:254] TEST Top shape for layer 8 'norm2' 6 256 27 27 (1119744)
I0228 07:56:45.113869  7805 layer_factory.hpp:172] Creating layer 'pool2' of type 'Pooling'
I0228 07:56:45.113873  7805 layer_factory.hpp:184] Layer's types are Ftype:FLOAT16 Btype:FLOAT16 Fmath:FLOAT16 Bmath:FLOAT16
I0228 07:56:45.113878  7805 net.cpp:187] Created Layer pool2 (9)
I0228 07:56:45.113881  7805 net.cpp:559] pool2 <- norm2
I0228 07:56:45.113888  7805 net.cpp:529] pool2 -> pool2
I0228 07:56:45.114120  7805 net.cpp:247] Setting up pool2
I0228 07:56:45.114128  7805 net.cpp:254] TEST Top shape for layer 9 'pool2' 6 256 13 13 (259584)
I0228 07:56:45.114132  7805 layer_factory.hpp:172] Creating layer 'conv3' of type 'Convolution'
I0228 07:56:45.114135  7805 layer_factory.hpp:184] Layer's types are Ftype:FLOAT16 Btype:FLOAT16 Fmath:FLOAT16 Bmath:FLOAT16
I0228 07:56:45.114145  7805 net.cpp:187] Created Layer conv3 (10)
I0228 07:56:45.114148  7805 net.cpp:559] conv3 <- pool2
I0228 07:56:45.114151  7805 net.cpp:529] conv3 -> conv3
I0228 07:56:45.132694  7805 net.cpp:247] Setting up conv3
I0228 07:56:45.132709  7805 net.cpp:254] TEST Top shape for layer 10 'conv3' 6 384 13 13 (389376)
I0228 07:56:45.132719  7805 layer_factory.hpp:172] Creating layer 'relu3' of type 'ReLU'
I0228 07:56:45.132722  7805 layer_factory.hpp:184] Layer's types are Ftype:FLOAT16 Btype:FLOAT16 Fmath:FLOAT16 Bmath:FLOAT16
I0228 07:56:45.132728  7805 net.cpp:187] Created Layer relu3 (11)
I0228 07:56:45.132732  7805 net.cpp:559] relu3 <- conv3
I0228 07:56:45.132736  7805 net.cpp:514] relu3 -> conv3 (in-place)
I0228 07:56:45.132742  7805 net.cpp:247] Setting up relu3
I0228 07:56:45.132745  7805 net.cpp:254] TEST Top shape for layer 11 'relu3' 6 384 13 13 (389376)
I0228 07:56:45.132750  7805 layer_factory.hpp:172] Creating layer 'conv4' of type 'Convolution'
I0228 07:56:45.132755  7805 layer_factory.hpp:184] Layer's types are Ftype:FLOAT16 Btype:FLOAT16 Fmath:FLOAT16 Bmath:FLOAT16
I0228 07:56:45.132763  7805 net.cpp:187] Created Layer conv4 (12)
I0228 07:56:45.132766  7805 net.cpp:559] conv4 <- conv3
I0228 07:56:45.132771  7805 net.cpp:529] conv4 -> conv4
I0228 07:56:45.147817  7805 net.cpp:247] Setting up conv4
I0228 07:56:45.147832  7805 net.cpp:254] TEST Top shape for layer 12 'conv4' 6 384 13 13 (389376)
I0228 07:56:45.147840  7805 layer_factory.hpp:172] Creating layer 'relu4' of type 'ReLU'
I0228 07:56:45.147843  7805 layer_factory.hpp:184] Layer's types are Ftype:FLOAT16 Btype:FLOAT16 Fmath:FLOAT16 Bmath:FLOAT16
I0228 07:56:45.147861  7805 net.cpp:187] Created Layer relu4 (13)
I0228 07:56:45.147879  7805 net.cpp:559] relu4 <- conv4
I0228 07:56:45.147884  7805 net.cpp:514] relu4 -> conv4 (in-place)
I0228 07:56:45.147902  7805 net.cpp:247] Setting up relu4
I0228 07:56:45.147905  7805 net.cpp:254] TEST Top shape for layer 13 'relu4' 6 384 13 13 (389376)
I0228 07:56:45.147908  7805 layer_factory.hpp:172] Creating layer 'conv5' of type 'Convolution'
I0228 07:56:45.147912  7805 layer_factory.hpp:184] Layer's types are Ftype:FLOAT16 Btype:FLOAT16 Fmath:FLOAT16 Bmath:FLOAT16
I0228 07:56:45.147922  7805 net.cpp:187] Created Layer conv5 (14)
I0228 07:56:45.147927  7805 net.cpp:559] conv5 <- conv4
I0228 07:56:45.147931  7805 net.cpp:529] conv5 -> conv5
I0228 07:56:45.159488  7805 net.cpp:247] Setting up conv5
I0228 07:56:45.159504  7805 net.cpp:254] TEST Top shape for layer 14 'conv5' 6 256 13 13 (259584)
I0228 07:56:45.159533  7805 layer_factory.hpp:172] Creating layer 'relu5' of type 'ReLU'
I0228 07:56:45.159536  7805 layer_factory.hpp:184] Layer's types are Ftype:FLOAT16 Btype:FLOAT16 Fmath:FLOAT16 Bmath:FLOAT16
I0228 07:56:45.159541  7805 net.cpp:187] Created Layer relu5 (15)
I0228 07:56:45.159545  7805 net.cpp:559] relu5 <- conv5
I0228 07:56:45.159549  7805 net.cpp:514] relu5 -> conv5 (in-place)
I0228 07:56:45.159574  7805 net.cpp:247] Setting up relu5
I0228 07:56:45.159579  7805 net.cpp:254] TEST Top shape for layer 15 'relu5' 6 256 13 13 (259584)
I0228 07:56:45.159584  7805 layer_factory.hpp:172] Creating layer 'pool5' of type 'Pooling'
I0228 07:56:45.159590  7805 layer_factory.hpp:184] Layer's types are Ftype:FLOAT16 Btype:FLOAT16 Fmath:FLOAT16 Bmath:FLOAT16
I0228 07:56:45.159613  7805 net.cpp:187] Created Layer pool5 (16)
I0228 07:56:45.159636  7805 net.cpp:559] pool5 <- conv5
I0228 07:56:45.159641  7805 net.cpp:529] pool5 -> pool5
I0228 07:56:45.159997  7805 net.cpp:247] Setting up pool5
I0228 07:56:45.160007  7805 net.cpp:254] TEST Top shape for layer 16 'pool5' 6 256 6 6 (55296)
I0228 07:56:45.160014  7805 layer_factory.hpp:172] Creating layer 'fc6' of type 'InnerProduct'
I0228 07:56:45.160020  7805 layer_factory.hpp:184] Layer's types are Ftype:FLOAT16 Btype:FLOAT16 Fmath:FLOAT16 Bmath:FLOAT16
I0228 07:56:45.160046  7805 net.cpp:187] Created Layer fc6 (17)
I0228 07:56:45.160053  7805 net.cpp:559] fc6 <- pool5
I0228 07:56:45.160056  7805 net.cpp:529] fc6 -> fc6
I0228 07:56:45.792737  7805 net.cpp:247] Setting up fc6
I0228 07:56:45.792793  7805 net.cpp:254] TEST Top shape for layer 17 'fc6' 6 4096 (24576)
I0228 07:56:45.792809  7805 layer_factory.hpp:172] Creating layer 'relu6' of type 'ReLU'
I0228 07:56:45.792816  7805 layer_factory.hpp:184] Layer's types are Ftype:FLOAT16 Btype:FLOAT16 Fmath:FLOAT16 Bmath:FLOAT16
I0228 07:56:45.792845  7805 net.cpp:187] Created Layer relu6 (18)
I0228 07:56:45.792850  7805 net.cpp:559] relu6 <- fc6
I0228 07:56:45.792877  7805 net.cpp:514] relu6 -> fc6 (in-place)
I0228 07:56:45.792928  7805 net.cpp:247] Setting up relu6
I0228 07:56:45.792934  7805 net.cpp:254] TEST Top shape for layer 18 'relu6' 6 4096 (24576)
I0228 07:56:45.792939  7805 layer_factory.hpp:172] Creating layer 'drop6' of type 'Dropout'
I0228 07:56:45.792943  7805 layer_factory.hpp:184] Layer's types are Ftype:FLOAT16 Btype:FLOAT16 Fmath:FLOAT16 Bmath:FLOAT16
I0228 07:56:45.792971  7805 net.cpp:187] Created Layer drop6 (19)
I0228 07:56:45.792976  7805 net.cpp:559] drop6 <- fc6
I0228 07:56:45.792980  7805 net.cpp:514] drop6 -> fc6 (in-place)
I0228 07:56:45.802459  7805 net.cpp:247] Setting up drop6
I0228 07:56:45.802474  7805 net.cpp:254] TEST Top shape for layer 19 'drop6' 6 4096 (24576)
I0228 07:56:45.802498  7805 layer_factory.hpp:172] Creating layer 'fc7' of type 'InnerProduct'
I0228 07:56:45.802503  7805 layer_factory.hpp:184] Layer's types are Ftype:FLOAT16 Btype:FLOAT16 Fmath:FLOAT16 Bmath:FLOAT16
I0228 07:56:45.802531  7805 net.cpp:187] Created Layer fc7 (20)
I0228 07:56:45.802534  7805 net.cpp:559] fc7 <- fc6
I0228 07:56:45.802557  7805 net.cpp:529] fc7 -> fc7
I0228 07:56:46.080552  7805 net.cpp:247] Setting up fc7
I0228 07:56:46.080576  7805 net.cpp:254] TEST Top shape for layer 20 'fc7' 6 4096 (24576)
I0228 07:56:46.080586  7805 layer_factory.hpp:172] Creating layer 'relu7' of type 'ReLU'
I0228 07:56:46.080591  7805 layer_factory.hpp:184] Layer's types are Ftype:FLOAT16 Btype:FLOAT16 Fmath:FLOAT16 Bmath:FLOAT16
I0228 07:56:46.080598  7805 net.cpp:187] Created Layer relu7 (21)
I0228 07:56:46.080602  7805 net.cpp:559] relu7 <- fc7
I0228 07:56:46.080607  7805 net.cpp:514] relu7 -> fc7 (in-place)
I0228 07:56:46.080633  7805 net.cpp:247] Setting up relu7
I0228 07:56:46.080639  7805 net.cpp:254] TEST Top shape for layer 21 'relu7' 6 4096 (24576)
I0228 07:56:46.080643  7805 layer_factory.hpp:172] Creating layer 'drop7' of type 'Dropout'
I0228 07:56:46.080646  7805 layer_factory.hpp:184] Layer's types are Ftype:FLOAT16 Btype:FLOAT16 Fmath:FLOAT16 Bmath:FLOAT16
I0228 07:56:46.080673  7805 net.cpp:187] Created Layer drop7 (22)
I0228 07:56:46.080695  7805 net.cpp:559] drop7 <- fc7
I0228 07:56:46.080699  7805 net.cpp:514] drop7 -> fc7 (in-place)
I0228 07:56:46.089532  7805 net.cpp:247] Setting up drop7
I0228 07:56:46.089547  7805 net.cpp:254] TEST Top shape for layer 22 'drop7' 6 4096 (24576)
I0228 07:56:46.089552  7805 layer_factory.hpp:172] Creating layer 'fc8' of type 'InnerProduct'
I0228 07:56:46.089556  7805 layer_factory.hpp:184] Layer's types are Ftype:FLOAT16 Btype:FLOAT16 Fmath:FLOAT16 Bmath:FLOAT16
I0228 07:56:46.089565  7805 net.cpp:187] Created Layer fc8 (23)
I0228 07:56:46.089570  7805 net.cpp:559] fc8 <- fc7
I0228 07:56:46.089573  7805 net.cpp:529] fc8 -> fc8
I0228 07:56:46.160588  7805 net.cpp:247] Setting up fc8
I0228 07:56:46.160604  7805 net.cpp:254] TEST Top shape for layer 23 'fc8' 6 1000 (6000)
I0228 07:56:46.160611  7805 layer_factory.hpp:172] Creating layer 'fc8_fc8_0_split' of type 'Split'
I0228 07:56:46.160615  7805 layer_factory.hpp:184] Layer's types are Ftype:FLOAT16 Btype:FLOAT16 Fmath:FLOAT16 Bmath:FLOAT16
I0228 07:56:46.160622  7805 net.cpp:187] Created Layer fc8_fc8_0_split (24)
I0228 07:56:46.160625  7805 net.cpp:559] fc8_fc8_0_split <- fc8
I0228 07:56:46.160630  7805 net.cpp:529] fc8_fc8_0_split -> fc8_fc8_0_split_0
I0228 07:56:46.160636  7805 net.cpp:529] fc8_fc8_0_split -> fc8_fc8_0_split_1
I0228 07:56:46.160658  7805 net.cpp:529] fc8_fc8_0_split -> fc8_fc8_0_split_2
I0228 07:56:46.161051  7805 net.cpp:247] Setting up fc8_fc8_0_split
I0228 07:56:46.161061  7805 net.cpp:254] TEST Top shape for layer 24 'fc8_fc8_0_split' 6 1000 (6000)
I0228 07:56:46.161065  7805 net.cpp:254] TEST Top shape for layer 24 'fc8_fc8_0_split' 6 1000 (6000)
I0228 07:56:46.161070  7805 net.cpp:254] TEST Top shape for layer 24 'fc8_fc8_0_split' 6 1000 (6000)
I0228 07:56:46.161074  7805 layer_factory.hpp:172] Creating layer 'loss' of type 'SoftmaxWithLoss'
I0228 07:56:46.161079  7805 layer_factory.hpp:184] Layer's types are Ftype:FLOAT16 Btype:FLOAT16 Fmath:FLOAT16 Bmath:FLOAT16
I0228 07:56:46.161087  7805 net.cpp:187] Created Layer loss (25)
I0228 07:56:46.161092  7805 net.cpp:559] loss <- fc8_fc8_0_split_0
I0228 07:56:46.161097  7805 net.cpp:559] loss <- label_data_1_split_0
I0228 07:56:46.161103  7805 net.cpp:529] loss -> loss
I0228 07:56:46.161762  7805 net.cpp:247] Setting up loss
I0228 07:56:46.161772  7805 net.cpp:254] TEST Top shape for layer 25 'loss' (1)
I0228 07:56:46.161775  7805 net.cpp:258]     with loss weight 1
I0228 07:56:46.161806  7805 layer_factory.hpp:172] Creating layer 'top-1' of type 'Accuracy'
I0228 07:56:46.161810  7805 layer_factory.hpp:184] Layer's types are Ftype:FLOAT16 Btype:FLOAT16 Fmath:FLOAT16 Bmath:FLOAT16
I0228 07:56:46.161841  7805 net.cpp:187] Created Layer top-1 (26)
I0228 07:56:46.161846  7805 net.cpp:559] top-1 <- fc8_fc8_0_split_1
I0228 07:56:46.161851  7805 net.cpp:559] top-1 <- label_data_1_split_1
I0228 07:56:46.161875  7805 net.cpp:529] top-1 -> top-1
I0228 07:56:46.161903  7805 net.cpp:247] Setting up top-1
I0228 07:56:46.161909  7805 net.cpp:254] TEST Top shape for layer 26 'top-1' (1)
I0228 07:56:46.161914  7805 layer_factory.hpp:172] Creating layer 'top-5' of type 'Accuracy'
I0228 07:56:46.161952  7805 layer_factory.hpp:184] Layer's types are Ftype:FLOAT16 Btype:FLOAT16 Fmath:FLOAT16 Bmath:FLOAT16
I0228 07:56:46.161962  7805 net.cpp:187] Created Layer top-5 (27)
I0228 07:56:46.161967  7805 net.cpp:559] top-5 <- fc8_fc8_0_split_2
I0228 07:56:46.161990  7805 net.cpp:559] top-5 <- label_data_1_split_2
I0228 07:56:46.161996  7805 net.cpp:529] top-5 -> top-5
I0228 07:56:46.162021  7805 net.cpp:247] Setting up top-5
I0228 07:56:46.162027  7805 net.cpp:254] TEST Top shape for layer 27 'top-5' (1)
I0228 07:56:46.162034  7805 net.cpp:325] top-5 does not need backward computation.
I0228 07:56:46.162039  7805 net.cpp:325] top-1 does not need backward computation.
I0228 07:56:46.162045  7805 net.cpp:323] loss needs backward computation.
I0228 07:56:46.162050  7805 net.cpp:323] fc8_fc8_0_split needs backward computation.
I0228 07:56:46.162056  7805 net.cpp:323] fc8 needs backward computation.
I0228 07:56:46.162060  7805 net.cpp:323] drop7 needs backward computation.
I0228 07:56:46.162063  7805 net.cpp:323] relu7 needs backward computation.
I0228 07:56:46.162066  7805 net.cpp:323] fc7 needs backward computation.
I0228 07:56:46.162072  7805 net.cpp:323] drop6 needs backward computation.
I0228 07:56:46.162075  7805 net.cpp:323] relu6 needs backward computation.
I0228 07:56:46.162080  7805 net.cpp:323] fc6 needs backward computation.
I0228 07:56:46.162083  7805 net.cpp:323] pool5 needs backward computation.
I0228 07:56:46.162089  7805 net.cpp:323] relu5 needs backward computation.
I0228 07:56:46.162093  7805 net.cpp:323] conv5 needs backward computation.
I0228 07:56:46.162099  7805 net.cpp:323] relu4 needs backward computation.
I0228 07:56:46.162103  7805 net.cpp:323] conv4 needs backward computation.
I0228 07:56:46.162109  7805 net.cpp:323] relu3 needs backward computation.
I0228 07:56:46.162113  7805 net.cpp:323] conv3 needs backward computation.
I0228 07:56:46.162117  7805 net.cpp:323] pool2 needs backward computation.
I0228 07:56:46.162122  7805 net.cpp:323] norm2 needs backward computation.
I0228 07:56:46.162127  7805 net.cpp:323] relu2 needs backward computation.
I0228 07:56:46.162132  7805 net.cpp:323] conv2 needs backward computation.
I0228 07:56:46.162137  7805 net.cpp:323] pool1 needs backward computation.
I0228 07:56:46.162140  7805 net.cpp:323] norm1 needs backward computation.
I0228 07:56:46.162147  7805 net.cpp:323] relu1 needs backward computation.
I0228 07:56:46.162150  7805 net.cpp:323] conv1 needs backward computation.
I0228 07:56:46.162155  7805 net.cpp:325] label_data_1_split does not need backward computation.
I0228 07:56:46.162161  7805 net.cpp:325] data does not need backward computation.
I0228 07:56:46.162168  7805 net.cpp:367] This network produces output loss
I0228 07:56:46.162171  7805 net.cpp:367] This network produces output top-1
I0228 07:56:46.162174  7805 net.cpp:367] This network produces output top-5
I0228 07:56:46.162205  7805 net.cpp:390] Top memory (TEST) required for data: 24993792 diff: 26848848
I0228 07:56:46.162212  7805 net.cpp:393] Bottom memory (TEST) required for data: 24993780 diff: 26848836
I0228 07:56:46.162215  7805 net.cpp:396] Shared (in-place) memory (TEST) by data: 7997568 diff: 7997568
I0228 07:56:46.162220  7805 net.cpp:399] Parameters memory (TEST) required for data: 121930448 diff: 121930448
I0228 07:56:46.162222  7805 net.cpp:402] Parameters shared memory (TEST) by data: 0 diff: 0
I0228 07:56:46.162228  7805 net.cpp:408] Network initialization done.
I0228 07:56:46.162319  7805 solver.cpp:54] Solver scaffolding done.
libibverbs: Warning: couldn't open config directory '/etc/libibverbs.d'.
libibverbs: Warning: no userspace device-specific driver found for /sys/class/infiniband_verbs/uverbs3
libibverbs: Warning: no userspace device-specific driver found for /sys/class/infiniband_verbs/uverbs2
libibverbs: Warning: no userspace device-specific driver found for /sys/class/infiniband_verbs/uverbs1
libibverbs: Warning: no userspace device-specific driver found for /sys/class/infiniband_verbs/uverbs0
I0228 07:56:46.168325  7805 parallel.cpp:99] [0 - 0] P2pSync adding callback
I0228 07:56:46.168342  7805 parallel.cpp:99] [1 - 1] P2pSync adding callback
I0228 07:56:46.168347  7805 parallel.cpp:99] [2 - 2] P2pSync adding callback
I0228 07:56:46.168350  7805 parallel.cpp:99] [3 - 3] P2pSync adding callback
I0228 07:56:46.168354  7805 parallel.cpp:99] [4 - 4] P2pSync adding callback
I0228 07:56:46.168357  7805 parallel.cpp:99] [5 - 5] P2pSync adding callback
I0228 07:56:46.168403  7805 parallel.cpp:99] [6 - 6] P2pSync adding callback
I0228 07:56:46.168407  7805 parallel.cpp:99] [7 - 7] P2pSync adding callback
I0228 07:56:46.168409  7805 parallel.cpp:55] Starting Optimization
I0228 07:56:46.168411  7805 internal_thread.cpp:19] Starting 1 internal thread(s) on device 0
I0228 07:56:46.168493  7805 internal_thread.cpp:19] Starting 1 internal thread(s) on device 1
I0228 07:56:46.168534  7805 internal_thread.cpp:19] Starting 1 internal thread(s) on device 2
I0228 07:56:46.168764  7805 internal_thread.cpp:19] Starting 1 internal thread(s) on device 3
I0228 07:56:46.168848  7805 internal_thread.cpp:19] Starting 1 internal thread(s) on device 4
I0228 07:56:46.168961  7805 internal_thread.cpp:19] Starting 1 internal thread(s) on device 5
I0228 07:56:46.169046  7805 internal_thread.cpp:19] Starting 1 internal thread(s) on device 6
I0228 07:56:46.169101  7805 internal_thread.cpp:19] Starting 1 internal thread(s) on device 7
I0228 07:56:46.182597  7887 common.cpp:530] NVML initialized, thread 7887
Unexpected end of /proc/mounts line `overlay / overlay rw,relatime,lowerdir=/var/lib/docker/overlay2/l/GYNNY4IQNBZLUFRA6HS7RJJ5SL:/var/lib/docker/overlay2/l/P4SDBPLOBQXYYKL37FSTBLWEUE:/var/lib/docker/overlay2/l/H2DW7J3UPVQVPF3U3TIH7FNMTB:/var/lib/docker/overlay2/l/4PS43TJJKEJIUBMICF6BKTLALA:/var/lib/docker/overlay2/l/MQVA3TEOWH7KMMM5YZBGRH4KDJ:/var/lib/docker/overlay2/l/SISSVFQIPJ7MFRECAR25NDUUHP:/var/lib/docker/overlay2/l/WOURMRTBCIFNFCBBWHFH3WKNEC:/var/lib/docker/overlay2/l/PGBLTPYREWRMDIQRQAJCK2Q4MP:/var/lib/docker/overlay2/l/SQL3MNICHWX6Z'
Unexpected end of /proc/mounts line `IOT5FPDNBFW74:/var/lib/docker/overlay2/l/BU7AA54C3G74RYE6UAT6BVIPZT:/var/lib/docker/overlay2/l/7YIN7ZGPLF5GQEGBM3TRARVKEH:/var/lib/docker/overlay2/l/JV4MSMTBLAXI2XOGDHZXXAYMTT:/var/lib/docker/overlay2/l/IXVQRWTGBCCEDNPHUWZSPHUGSC:/var/lib/docker/overlay2/l/DEKVP6CR5SG47UUU37E7MJY2SL:/var/lib/docker/overlay2/l/SV26EWB7NO2O5UWOGJXQFZTRUX:/var/lib/docker/overlay2/l/JLTG6WXRQLTK6JPDN36EXSHKEM:/var/lib/docker/overlay2/l/HRXNLXFHR6LGFKQP5QSZR3KVGI:/var/lib/docker/overlay2/l/J2HUJAM3TBZYUAUK2GD5TRI545:/var/lib/do'
Unexpected end of /proc/mounts line `cker/overlay2/l/2SDXM7MIAGRGPGHNCEZFX444DU:/var/lib/docker/overlay2/l/5ZQ7ZGLHBFUULMC2MPGXWOF5A7:/var/lib/docker/overlay2/l/WBBO65K5FHJNCEELJFKZDI4RJB:/var/lib/docker/overlay2/l/5G2DWD6VWDK7WY4DYSZ7MWJDUJ:/var/lib/docker/overlay2/l/VGRBU3UPPWFYOKHLHO2T6A6CW7:/var/lib/docker/overlay2/l/G6WJ4UHZHS7Z4B42QE7ESTPTLH:/var/lib/docker/overlay2/l/CIN5GJDGPG7U5TBRCCJTWPM6PO:/var/lib/docker/overlay2/l/6VM53LECTON5BBB6P7YEKZQEEX:/var/lib/docker/overlay2/l/LF4HIOWKPUWBHXXG3UFY3M75YM:/var/lib/docker/overlay2/l/NCRQ2WOD4'
Unexpected end of /proc/mounts line `N65A3GYHJWWDH4RL4:/var/lib/docker/overlay2/l/IJGRG55XZFDJU4IVU6DY6623LF:/var/lib/docker/overlay2/l/5QE2B5GCZV6V6LMFEYFZMJXSJR:/var/lib/docker/overlay2/l/TJNYOFHPHG735NLW5LOGZOMMYF:/var/lib/docker/overlay2/l/WGIV5H5YA3UGADC7RSC53N7DVO:/var/lib/docker/overlay2/l/QHUTNSACITN4IGTW6RKN6A5XVW:/var/lib/docker/overlay2/l/B3QUTI7BFOSJBKOFW4CKPR776M:/var/lib/docker/overlay2/l/PWDPVM34TWEP6WK5K4XEHIM5GV:/var/lib/docker/overlay2/l/WLGZC55T6STBD7KST5LA2SEY6I:/var/lib/docker/overlay2/l/LEE6FQZ3PYN7BICWKFEGLGLHT4:/var/li'
I0228 07:56:46.240249  7887 common.cpp:552] NVML succeeded to set CPU affinity on device 1, thread 7887
I0228 07:56:46.241114  7887 solver.cpp:40] Solver data type: FLOAT16
I0228 07:56:46.243726  7887 internal_thread.cpp:19] Starting 1 internal thread(s) on device 1
I0228 07:56:46.246431  7886 common.cpp:552] NVML succeeded to set CPU affinity on device 0, thread 7886
I0228 07:56:46.253489  7888 common.cpp:552] NVML succeeded to set CPU affinity on device 2, thread 7888
I0228 07:56:46.253621  7888 solver.cpp:40] Solver data type: FLOAT16
I0228 07:56:46.255800  7888 internal_thread.cpp:19] Starting 1 internal thread(s) on device 2
I0228 07:56:46.260939  7889 common.cpp:552] NVML succeeded to set CPU affinity on device 3, thread 7889
I0228 07:56:46.260984  7889 solver.cpp:40] Solver data type: FLOAT16
I0228 07:56:46.263797  7889 internal_thread.cpp:19] Starting 1 internal thread(s) on device 3
I0228 07:56:46.268484  7890 common.cpp:552] NVML succeeded to set CPU affinity on device 4, thread 7890
I0228 07:56:46.268558  7890 solver.cpp:40] Solver data type: FLOAT16
I0228 07:56:46.269860  7887 data_reader.cpp:58] Sample Data Reader threads: 1, out queues: 1, depth: 256
I0228 07:56:46.269912  7887 internal_thread.cpp:19] Starting 1 internal thread(s) on device 1
I0228 07:56:46.274020  7897 db_lmdb.cpp:36] Opened lmdb /data/imagenet/train-lmdb-uncompressed-256x256
I0228 07:56:46.274979  7890 internal_thread.cpp:19] Starting 1 internal thread(s) on device 4
I0228 07:56:46.277793  7891 common.cpp:552] NVML succeeded to set CPU affinity on device 5, thread 7891
I0228 07:56:46.280045  7891 solver.cpp:40] Solver data type: FLOAT16
I0228 07:56:46.280095  7887 data_layer.cpp:186] [1] Transform on GPU enabled
I0228 07:56:46.281527  7888 data_reader.cpp:58] Sample Data Reader threads: 1, out queues: 1, depth: 256
I0228 07:56:46.281576  7888 internal_thread.cpp:19] Starting 1 internal thread(s) on device 2
I0228 07:56:46.285696  7899 db_lmdb.cpp:36] Opened lmdb /data/imagenet/train-lmdb-uncompressed-256x256
I0228 07:56:46.286234  7892 common.cpp:552] NVML succeeded to set CPU affinity on device 6, thread 7892
I0228 07:56:46.286283  7892 solver.cpp:40] Solver data type: FLOAT16
I0228 07:56:46.286917  7891 internal_thread.cpp:19] Starting 1 internal thread(s) on device 5
I0228 07:56:46.292570  7888 data_layer.cpp:186] [2] Transform on GPU enabled
I0228 07:56:46.292919  7892 internal_thread.cpp:19] Starting 1 internal thread(s) on device 6
I0228 07:56:46.296600  7893 common.cpp:552] NVML succeeded to set CPU affinity on device 7, thread 7893
I0228 07:56:46.297844  7893 solver.cpp:40] Solver data type: FLOAT16
I0228 07:56:46.297855  7889 data_reader.cpp:58] Sample Data Reader threads: 1, out queues: 1, depth: 256
I0228 07:56:46.297924  7889 internal_thread.cpp:19] Starting 1 internal thread(s) on device 3
I0228 07:56:46.302115  7902 db_lmdb.cpp:36] Opened lmdb /data/imagenet/train-lmdb-uncompressed-256x256
I0228 07:56:46.303203  7893 internal_thread.cpp:19] Starting 1 internal thread(s) on device 7
I0228 07:56:46.309903  7889 data_layer.cpp:186] [3] Transform on GPU enabled
I0228 07:56:46.322556  7890 data_reader.cpp:58] Sample Data Reader threads: 1, out queues: 1, depth: 256
I0228 07:56:46.322646  7890 internal_thread.cpp:19] Starting 1 internal thread(s) on device 4
I0228 07:56:46.326130  7891 data_reader.cpp:58] Sample Data Reader threads: 1, out queues: 1, depth: 256
I0228 07:56:46.326140  7904 db_lmdb.cpp:36] Opened lmdb /data/imagenet/train-lmdb-uncompressed-256x256
I0228 07:56:46.326233  7891 internal_thread.cpp:19] Starting 1 internal thread(s) on device 5
I0228 07:56:46.328258  7890 data_layer.cpp:186] [4] Transform on GPU enabled
I0228 07:56:46.329484  7892 data_reader.cpp:58] Sample Data Reader threads: 1, out queues: 1, depth: 256
I0228 07:56:46.329526  7905 db_lmdb.cpp:36] Opened lmdb /data/imagenet/train-lmdb-uncompressed-256x256
I0228 07:56:46.329602  7892 internal_thread.cpp:19] Starting 1 internal thread(s) on device 6
I0228 07:56:46.332445  7891 data_layer.cpp:186] [5] Transform on GPU enabled
I0228 07:56:46.334054  7906 db_lmdb.cpp:36] Opened lmdb /data/imagenet/train-lmdb-uncompressed-256x256
I0228 07:56:46.334076  7893 data_reader.cpp:58] Sample Data Reader threads: 1, out queues: 1, depth: 256
I0228 07:56:46.334182  7893 internal_thread.cpp:19] Starting 1 internal thread(s) on device 7
I0228 07:56:46.336817  7892 data_layer.cpp:186] [6] Transform on GPU enabled
I0228 07:56:46.337916  7907 db_lmdb.cpp:36] Opened lmdb /data/imagenet/train-lmdb-uncompressed-256x256
I0228 07:56:46.337996  7887 data_layer.cpp:199] [1] Output data size: 256, 3, 227, 227
I0228 07:56:46.344102  7893 data_layer.cpp:186] [7] Transform on GPU enabled
I0228 07:56:46.344452  7888 data_layer.cpp:199] [2] Output data size: 256, 3, 227, 227
I0228 07:56:46.350832  7889 data_layer.cpp:199] [3] Output data size: 256, 3, 227, 227
I0228 07:56:46.360158  7890 data_layer.cpp:199] [4] Output data size: 256, 3, 227, 227
I0228 07:56:46.363719  7891 data_layer.cpp:199] [5] Output data size: 256, 3, 227, 227
I0228 07:56:46.365373  7887 internal_thread.cpp:19] Starting 1 internal thread(s) on device 1
I0228 07:56:46.373744  7892 data_layer.cpp:199] [6] Output data size: 256, 3, 227, 227
I0228 07:56:46.375216  7888 internal_thread.cpp:19] Starting 1 internal thread(s) on device 2
I0228 07:56:46.387092  7889 internal_thread.cpp:19] Starting 1 internal thread(s) on device 3
I0228 07:56:46.392516  7890 internal_thread.cpp:19] Starting 1 internal thread(s) on device 4
I0228 07:56:46.392583  7893 data_layer.cpp:199] [7] Output data size: 256, 3, 227, 227
I0228 07:56:46.395676  7891 internal_thread.cpp:19] Starting 1 internal thread(s) on device 5
I0228 07:56:46.413187  7893 internal_thread.cpp:19] Starting 1 internal thread(s) on device 7
I0228 07:56:46.413563  7892 internal_thread.cpp:19] Starting 1 internal thread(s) on device 6
I0228 07:56:48.924100  7887 solver.cpp:173] Creating test net (#0) specified by net file: train_val_fp16_2048.prototxt
I0228 07:56:48.924337  7887 internal_thread.cpp:19] Starting 1 internal thread(s) on device 1
I0228 07:56:48.994047  7887 data_reader.cpp:58] Data Reader threads: 1, out queues: 1, depth: 6
I0228 07:56:48.994083  7887 internal_thread.cpp:19] Starting 1 internal thread(s) on device 1
I0228 07:56:48.995930  7916 db_lmdb.cpp:36] Opened lmdb /data/imagenet/val-lmdb-uncompressed-256x256
I0228 07:56:49.007737  7887 data_layer.cpp:199] (1) Output data size: 6, 3, 227, 227
I0228 07:56:49.039278  7887 internal_thread.cpp:19] Starting 1 internal thread(s) on device 1
I0228 07:56:49.041007  7917 data_layer.cpp:105] (1) Parser threads: 1
I0228 07:56:49.041021  7917 data_layer.cpp:107] (1) Transformer threads: 1
I0228 07:56:49.948823  7888 solver.cpp:173] Creating test net (#0) specified by net file: train_val_fp16_2048.prototxt
I0228 07:56:49.950022  7888 internal_thread.cpp:19] Starting 1 internal thread(s) on device 2
I0228 07:56:50.057873  7888 data_reader.cpp:58] Data Reader threads: 1, out queues: 1, depth: 6
I0228 07:56:50.057893  7888 internal_thread.cpp:19] Starting 1 internal thread(s) on device 2
I0228 07:56:50.059510  7919 db_lmdb.cpp:36] Opened lmdb /data/imagenet/val-lmdb-uncompressed-256x256
I0228 07:56:50.228135  7888 data_layer.cpp:199] (2) Output data size: 6, 3, 227, 227
I0228 07:56:50.350338  7888 internal_thread.cpp:19] Starting 1 internal thread(s) on device 2
I0228 07:56:50.352202  7920 data_layer.cpp:105] (2) Parser threads: 1
I0228 07:56:50.352217  7920 data_layer.cpp:107] (2) Transformer threads: 1
I0228 07:56:52.188853  7889 solver.cpp:173] Creating test net (#0) specified by net file: train_val_fp16_2048.prototxt
I0228 07:56:52.189116  7889 internal_thread.cpp:19] Starting 1 internal thread(s) on device 3
I0228 07:56:52.357193  7887 solver.cpp:54] Solver scaffolding done.
I0228 07:56:52.378842  7889 data_reader.cpp:58] Data Reader threads: 1, out queues: 1, depth: 6
I0228 07:56:52.378867  7889 internal_thread.cpp:19] Starting 1 internal thread(s) on device 3
I0228 07:56:52.380570  7922 db_lmdb.cpp:36] Opened lmdb /data/imagenet/val-lmdb-uncompressed-256x256
I0228 07:56:52.449605  7889 data_layer.cpp:199] (3) Output data size: 6, 3, 227, 227
I0228 07:56:52.551362  7889 internal_thread.cpp:19] Starting 1 internal thread(s) on device 3
I0228 07:56:52.553092  7923 data_layer.cpp:105] (3) Parser threads: 1
I0228 07:56:52.553103  7923 data_layer.cpp:107] (3) Transformer threads: 1
I0228 07:56:52.690505  7891 solver.cpp:173] Creating test net (#0) specified by net file: train_val_fp16_2048.prototxt
I0228 07:56:52.690912  7891 internal_thread.cpp:19] Starting 1 internal thread(s) on device 5
I0228 07:56:52.796819  7891 data_reader.cpp:58] Data Reader threads: 1, out queues: 1, depth: 6
I0228 07:56:52.796874  7891 internal_thread.cpp:19] Starting 1 internal thread(s) on device 5
I0228 07:56:52.799590  7925 db_lmdb.cpp:36] Opened lmdb /data/imagenet/val-lmdb-uncompressed-256x256
I0228 07:56:52.810405  7891 data_layer.cpp:199] (5) Output data size: 6, 3, 227, 227
I0228 07:56:52.830235  7891 internal_thread.cpp:19] Starting 1 internal thread(s) on device 5
I0228 07:56:52.832072  7926 data_layer.cpp:105] (5) Parser threads: 1
I0228 07:56:52.832084  7926 data_layer.cpp:107] (5) Transformer threads: 1
I0228 07:56:52.912255  7888 solver.cpp:54] Solver scaffolding done.
I0228 07:56:53.393134  7890 solver.cpp:173] Creating test net (#0) specified by net file: train_val_fp16_2048.prototxt
I0228 07:56:53.393492  7890 internal_thread.cpp:19] Starting 1 internal thread(s) on device 4
I0228 07:56:53.405854  7890 data_reader.cpp:58] Data Reader threads: 1, out queues: 1, depth: 6
I0228 07:56:53.405875  7890 internal_thread.cpp:19] Starting 1 internal thread(s) on device 4
I0228 07:56:53.407706  7928 db_lmdb.cpp:36] Opened lmdb /data/imagenet/val-lmdb-uncompressed-256x256
I0228 07:56:53.409296  7890 data_layer.cpp:199] (4) Output data size: 6, 3, 227, 227
I0228 07:56:53.420501  7890 internal_thread.cpp:19] Starting 1 internal thread(s) on device 4
I0228 07:56:53.422251  7929 data_layer.cpp:105] (4) Parser threads: 1
I0228 07:56:53.422263  7929 data_layer.cpp:107] (4) Transformer threads: 1
I0228 07:56:54.032127  7892 solver.cpp:173] Creating test net (#0) specified by net file: train_val_fp16_2048.prototxt
I0228 07:56:54.032483  7892 internal_thread.cpp:19] Starting 1 internal thread(s) on device 6
I0228 07:56:54.045624  7892 data_reader.cpp:58] Data Reader threads: 1, out queues: 1, depth: 6
I0228 07:56:54.045644  7892 internal_thread.cpp:19] Starting 1 internal thread(s) on device 6
I0228 07:56:54.047483  7931 db_lmdb.cpp:36] Opened lmdb /data/imagenet/val-lmdb-uncompressed-256x256
I0228 07:56:54.049024  7892 data_layer.cpp:199] (6) Output data size: 6, 3, 227, 227
I0228 07:56:54.061192  7892 internal_thread.cpp:19] Starting 1 internal thread(s) on device 6
I0228 07:56:54.062927  7932 data_layer.cpp:105] (6) Parser threads: 1
I0228 07:56:54.062938  7932 data_layer.cpp:107] (6) Transformer threads: 1
I0228 07:56:54.098193  7889 solver.cpp:54] Solver scaffolding done.
I0228 07:56:54.169152  7893 solver.cpp:173] Creating test net (#0) specified by net file: train_val_fp16_2048.prototxt
I0228 07:56:54.169504  7893 internal_thread.cpp:19] Starting 1 internal thread(s) on device 7
I0228 07:56:54.190311  7893 data_reader.cpp:58] Data Reader threads: 1, out queues: 1, depth: 6
I0228 07:56:54.190331  7893 internal_thread.cpp:19] Starting 1 internal thread(s) on device 7
I0228 07:56:54.193192  7934 db_lmdb.cpp:36] Opened lmdb /data/imagenet/val-lmdb-uncompressed-256x256
I0228 07:56:54.235283  7893 data_layer.cpp:199] (7) Output data size: 6, 3, 227, 227
I0228 07:56:54.273607  7893 internal_thread.cpp:19] Starting 1 internal thread(s) on device 7
I0228 07:56:54.275574  7935 data_layer.cpp:105] (7) Parser threads: 1
I0228 07:56:54.275588  7935 data_layer.cpp:107] (7) Transformer threads: 1
I0228 07:56:54.275838  7891 solver.cpp:54] Solver scaffolding done.
I0228 07:56:54.662787  7890 solver.cpp:54] Solver scaffolding done.
I0228 07:56:55.265022  7892 solver.cpp:54] Solver scaffolding done.
I0228 07:56:55.407902  7893 solver.cpp:54] Solver scaffolding done.
I0228 07:56:56.600649  7890 parallel.cpp:130] [4 - 4] P2pSync adding callback
I0228 07:56:56.600735  7890 solver.cpp:430] Solving AlexNet-fp16
I0228 07:56:56.600740  7890 solver.cpp:431] Learning Rate Policy: poly
I0228 07:56:56.600828  7891 parallel.cpp:130] [5 - 5] P2pSync adding callback
I0228 07:56:56.600899  7891 solver.cpp:430] Solving AlexNet-fp16
I0228 07:56:56.600905  7891 solver.cpp:431] Learning Rate Policy: poly
I0228 07:56:56.600913  7886 parallel.cpp:130] [0 - 0] P2pSync adding callback
I0228 07:56:56.600931  7886 solver.cpp:430] Solving AlexNet-fp16
I0228 07:56:56.600924  7888 parallel.cpp:130] [2 - 2] P2pSync adding callback
I0228 07:56:56.600939  7889 parallel.cpp:130] [3 - 3] P2pSync adding callback
I0228 07:56:56.600925  7887 parallel.cpp:130] [1 - 1] P2pSync adding callback
I0228 07:56:56.600973  7889 solver.cpp:430] Solving AlexNet-fp16
I0228 07:56:56.600955  7888 solver.cpp:430] Solving AlexNet-fp16
I0228 07:56:56.600939  7886 solver.cpp:431] Learning Rate Policy: poly
I0228 07:56:56.600976  7893 parallel.cpp:130] [7 - 7] P2pSync adding callback
I0228 07:56:56.600980  7889 solver.cpp:431] Learning Rate Policy: poly
I0228 07:56:56.600982  7888 solver.cpp:431] Learning Rate Policy: poly
I0228 07:56:56.600998  7887 solver.cpp:430] Solving AlexNet-fp16
I0228 07:56:56.601004  7887 solver.cpp:431] Learning Rate Policy: poly
I0228 07:56:56.600999  7892 parallel.cpp:130] [6 - 6] P2pSync adding callback
I0228 07:56:56.601001  7893 solver.cpp:430] Solving AlexNet-fp16
I0228 07:56:56.601018  7892 solver.cpp:430] Solving AlexNet-fp16
I0228 07:56:56.601022  7893 solver.cpp:431] Learning Rate Policy: poly
I0228 07:56:56.601023  7892 solver.cpp:431] Learning Rate Policy: poly
I0228 07:56:56.601068  7892 net.cpp:1396] [6] Reserving 121930624 bytes of shared learnable space for type FLOAT16
I0228 07:56:56.601068  7886 net.cpp:1396] [0] Reserving 121930624 bytes of shared learnable space for type FLOAT16
I0228 07:56:56.601068  7891 net.cpp:1396] [5] Reserving 121930624 bytes of shared learnable space for type FLOAT16
I0228 07:56:56.601068  7890 net.cpp:1396] [4] Reserving 121930624 bytes of shared learnable space for type FLOAT16
I0228 07:56:56.601083  7889 net.cpp:1396] [3] Reserving 121930624 bytes of shared learnable space for type FLOAT16
I0228 07:56:56.601091  7893 net.cpp:1396] [7] Reserving 121930624 bytes of shared learnable space for type FLOAT16
I0228 07:56:56.601102  7888 net.cpp:1396] [2] Reserving 121930624 bytes of shared learnable space for type FLOAT16
I0228 07:56:56.601212  7887 net.cpp:1396] [1] Reserving 121930624 bytes of shared learnable space for type FLOAT16
I0228 07:56:56.700453  7890 solver.cpp:224] Starting Optimization on GPU 4
I0228 07:56:56.700455  7892 solver.cpp:224] Starting Optimization on GPU 6
I0228 07:56:56.700480  7889 solver.cpp:224] Starting Optimization on GPU 3
I0228 07:56:56.700481  7886 solver.cpp:224] Starting Optimization on GPU 0
I0228 07:56:56.700484  7891 solver.cpp:224] Starting Optimization on GPU 5
I0228 07:56:56.700482  7887 solver.cpp:224] Starting Optimization on GPU 1
I0228 07:56:56.700484  7888 solver.cpp:224] Starting Optimization on GPU 2
I0228 07:56:56.700481  7893 solver.cpp:224] Starting Optimization on GPU 7
I0228 07:56:56.700752  7936 common.cpp:552] NVML succeeded to set CPU affinity on device 4, thread 7936
I0228 07:56:56.700911  7938 common.cpp:552] NVML succeeded to set CPU affinity on device 2, thread 7938
I0228 07:56:56.700968  7939 common.cpp:552] NVML succeeded to set CPU affinity on device 3, thread 7939
I0228 07:56:56.701009  7941 common.cpp:552] NVML succeeded to set CPU affinity on device 1, thread 7941
I0228 07:56:56.701113  7937 common.cpp:552] NVML succeeded to set CPU affinity on device 6, thread 7937
I0228 07:56:56.701165  7940 common.cpp:552] NVML succeeded to set CPU affinity on device 5, thread 7940
I0228 07:56:56.701316  7942 common.cpp:552] NVML succeeded to set CPU affinity on device 7, thread 7942
I0228 07:56:56.702675  7943 common.cpp:552] NVML succeeded to set CPU affinity on device 0, thread 7943
I0228 07:56:56.711930  7886 solver.cpp:264] [MultiGPU] Initial Test started...
I0228 07:56:56.711972  7886 solver.cpp:513] Iteration 0, Testing net (#0)
I0228 07:56:58.337043  7886 solver.cpp:599]     Test net output #0: loss = 6.92969 (* 1 = 6.92969 loss)
I0228 07:56:58.337110  7886 solver.cpp:599]     Test net output #1: top-1 = 0
I0228 07:56:58.337116  7886 solver.cpp:599]     Test net output #2: top-5 = 0
I0228 07:56:58.337256  7886 solver.cpp:269] [MultiGPU] Initial Test completed in 1.62523s
I0228 07:56:58.348259  7909 data_layer.cpp:68] [2] Reduced parser threads count from 2 to 1 because cache is used
I0228 07:56:58.359223  7908 data_layer.cpp:68] [1] Reduced parser threads count from 2 to 1 because cache is used
I0228 07:56:58.359241  7908 internal_thread.cpp:40] Restarting 4 internal thread(s) on device 1
I0228 07:56:58.370576  7911 data_layer.cpp:68] [4] Reduced parser threads count from 2 to 1 because cache is used
I0228 07:56:58.381707  7913 data_layer.cpp:68] [7] Reduced parser threads count from 2 to 1 because cache is used
I0228 07:56:58.392887  7914 data_layer.cpp:68] [6] Reduced parser threads count from 2 to 1 because cache is used
I0228 07:56:58.392904  7914 internal_thread.cpp:40] Restarting 4 internal thread(s) on device 6
I0228 07:56:58.403625  7910 data_layer.cpp:68] [3] Reduced parser threads count from 2 to 1 because cache is used
I0228 07:56:58.403640  7910 internal_thread.cpp:40] Restarting 4 internal thread(s) on device 3
I0228 07:56:58.414810  7912 data_layer.cpp:68] [5] Reduced parser threads count from 2 to 1 because cache is used
I0228 07:56:58.414825  7912 internal_thread.cpp:40] Restarting 4 internal thread(s) on device 5
I0228 07:56:58.425878  7881 data_layer.cpp:68] [0] Reduced parser threads count from 2 to 1 because cache is used
I0228 07:56:58.425892  7881 internal_thread.cpp:40] Restarting 4 internal thread(s) on device 0
I0228 07:56:58.425947  7909 internal_thread.cpp:40] Restarting 4 internal thread(s) on device 2
I0228 07:56:58.426010  7908 internal_thread.cpp:19] Starting 1 internal thread(s) on device 1
I0228 07:56:58.426046  7911 internal_thread.cpp:40] Restarting 4 internal thread(s) on device 4
I0228 07:56:58.426177  7913 internal_thread.cpp:40] Restarting 4 internal thread(s) on device 7
I0228 07:56:58.426208  7914 internal_thread.cpp:19] Starting 1 internal thread(s) on device 6
I0228 07:56:58.426327  7910 internal_thread.cpp:19] Starting 1 internal thread(s) on device 3
I0228 07:56:58.426334  7908 data_transformer.cpp:40] Loading mean file from: /data/imagenet/imagenet_256x256_mean.binaryproto
I0228 07:56:58.426352  7912 internal_thread.cpp:19] Starting 1 internal thread(s) on device 5
I0228 07:56:58.428293  7964 common.cpp:552] NVML succeeded to set CPU affinity on device 1, thread 7964
I0228 07:56:58.429911  7966 common.cpp:552] NVML succeeded to set CPU affinity on device 6, thread 7966
I0228 07:56:58.429913  7914 data_transformer.cpp:40] Loading mean file from: /data/imagenet/imagenet_256x256_mean.binaryproto
I0228 07:56:58.429949  7912 data_transformer.cpp:40] Loading mean file from: /data/imagenet/imagenet_256x256_mean.binaryproto
I0228 07:56:58.431880  7971 common.cpp:552] NVML succeeded to set CPU affinity on device 5, thread 7971
I0228 07:56:58.431896  7881 internal_thread.cpp:19] Starting 1 internal thread(s) on device 0
I0228 07:56:58.434799  7974 common.cpp:552] NVML succeeded to set CPU affinity on device 3, thread 7974
I0228 07:56:58.434816  7910 data_transformer.cpp:40] Loading mean file from: /data/imagenet/imagenet_256x256_mean.binaryproto
I0228 07:56:58.434857  7909 internal_thread.cpp:19] Starting 1 internal thread(s) on device 2
I0228 07:56:58.434931  7911 internal_thread.cpp:19] Starting 1 internal thread(s) on device 4
I0228 07:56:58.434985  7909 data_transformer.cpp:40] Loading mean file from: /data/imagenet/imagenet_256x256_mean.binaryproto
I0228 07:56:58.435135  7913 internal_thread.cpp:19] Starting 1 internal thread(s) on device 7
I0228 07:56:58.437125  7981 common.cpp:552] NVML succeeded to set CPU affinity on device 2, thread 7981
I0228 07:56:58.439121  7980 common.cpp:552] NVML succeeded to set CPU affinity on device 0, thread 7980
I0228 07:56:58.439122  7881 data_transformer.cpp:40] Loading mean file from: /data/imagenet/imagenet_256x256_mean.binaryproto
I0228 07:56:58.439170  7911 data_transformer.cpp:40] Loading mean file from: /data/imagenet/imagenet_256x256_mean.binaryproto
I0228 07:56:58.441464  7982 common.cpp:552] NVML succeeded to set CPU affinity on device 4, thread 7982
I0228 07:56:58.443380  7983 common.cpp:552] NVML succeeded to set CPU affinity on device 7, thread 7983
I0228 07:56:58.443424  7913 data_transformer.cpp:40] Loading mean file from: /data/imagenet/imagenet_256x256_mean.binaryproto
I0228 07:56:58.443523  7908 data_transformer.cpp:40] Loading mean file from: /data/imagenet/imagenet_256x256_mean.binaryproto
I0228 07:56:58.449142  7912 data_transformer.cpp:40] Loading mean file from: /data/imagenet/imagenet_256x256_mean.binaryproto
I0228 07:56:58.452599  7914 data_transformer.cpp:40] Loading mean file from: /data/imagenet/imagenet_256x256_mean.binaryproto
I0228 07:56:58.457893  7910 data_transformer.cpp:40] Loading mean file from: /data/imagenet/imagenet_256x256_mean.binaryproto
I0228 07:56:58.461748  7909 data_transformer.cpp:40] Loading mean file from: /data/imagenet/imagenet_256x256_mean.binaryproto
I0228 07:56:58.463629  7912 data_transformer.cpp:40] Loading mean file from: /data/imagenet/imagenet_256x256_mean.binaryproto
I0228 07:56:58.466428  7911 data_transformer.cpp:40] Loading mean file from: /data/imagenet/imagenet_256x256_mean.binaryproto
I0228 07:56:58.466954  7914 data_transformer.cpp:40] Loading mean file from: /data/imagenet/imagenet_256x256_mean.binaryproto
I0228 07:56:58.470343  7913 data_transformer.cpp:40] Loading mean file from: /data/imagenet/imagenet_256x256_mean.binaryproto
I0228 07:56:58.472914  7881 data_transformer.cpp:40] Loading mean file from: /data/imagenet/imagenet_256x256_mean.binaryproto
I0228 07:56:58.473126  7908 data_transformer.cpp:40] Loading mean file from: /data/imagenet/imagenet_256x256_mean.binaryproto
I0228 07:56:58.475597  7910 data_transformer.cpp:40] Loading mean file from: /data/imagenet/imagenet_256x256_mean.binaryproto
I0228 07:56:58.478001  7909 data_transformer.cpp:40] Loading mean file from: /data/imagenet/imagenet_256x256_mean.binaryproto
I0228 07:56:58.480713  7912 data_transformer.cpp:40] Loading mean file from: /data/imagenet/imagenet_256x256_mean.binaryproto
I0228 07:56:58.480938  7911 data_transformer.cpp:40] Loading mean file from: /data/imagenet/imagenet_256x256_mean.binaryproto
I0228 07:56:58.485518  7914 data_transformer.cpp:40] Loading mean file from: /data/imagenet/imagenet_256x256_mean.binaryproto
I0228 07:56:58.485734  7913 data_transformer.cpp:40] Loading mean file from: /data/imagenet/imagenet_256x256_mean.binaryproto
I0228 07:56:58.490730  7908 data_transformer.cpp:40] Loading mean file from: /data/imagenet/imagenet_256x256_mean.binaryproto
I0228 07:56:58.491056  7881 data_transformer.cpp:40] Loading mean file from: /data/imagenet/imagenet_256x256_mean.binaryproto
I0228 07:56:58.494520  7910 data_transformer.cpp:40] Loading mean file from: /data/imagenet/imagenet_256x256_mean.binaryproto
I0228 07:56:58.499272  7909 data_transformer.cpp:40] Loading mean file from: /data/imagenet/imagenet_256x256_mean.binaryproto
I0228 07:56:58.499634  7912 data_reader.cpp:58] Data Reader threads: 1, out queues: 4, depth: 256
I0228 07:56:58.499958  7912 internal_thread.cpp:19] Starting 1 internal thread(s) on device 5
I0228 07:56:58.500077  7912 data_layer.cpp:186] [5] Transform on GPU enabled
I0228 07:56:58.502166  7984 db_lmdb.cpp:36] Opened lmdb /data/imagenet/train-lmdb-uncompressed-256x256
I0228 07:56:58.502934  7911 data_transformer.cpp:40] Loading mean file from: /data/imagenet/imagenet_256x256_mean.binaryproto
I0228 07:56:58.506552  7913 data_transformer.cpp:40] Loading mean file from: /data/imagenet/imagenet_256x256_mean.binaryproto
I0228 07:56:58.507169  7914 data_reader.cpp:58] Data Reader threads: 1, out queues: 4, depth: 256
I0228 07:56:58.507485  7914 internal_thread.cpp:19] Starting 1 internal thread(s) on device 6
I0228 07:56:58.507560  7914 data_layer.cpp:186] [6] Transform on GPU enabled
I0228 07:56:58.510259  7985 db_lmdb.cpp:36] Opened lmdb /data/imagenet/train-lmdb-uncompressed-256x256
I0228 07:56:58.510310  7908 data_reader.cpp:58] Data Reader threads: 1, out queues: 4, depth: 256
I0228 07:56:58.510661  7908 internal_thread.cpp:19] Starting 1 internal thread(s) on device 1
I0228 07:56:58.510788  7908 data_layer.cpp:186] [1] Transform on GPU enabled
I0228 07:56:58.512979  7881 data_transformer.cpp:40] Loading mean file from: /data/imagenet/imagenet_256x256_mean.binaryproto
I0228 07:56:58.512980  7986 db_lmdb.cpp:36] Opened lmdb /data/imagenet/train-lmdb-uncompressed-256x256
I0228 07:56:58.513020  7911 data_reader.cpp:58] Data Reader threads: 1, out queues: 4, depth: 256
I0228 07:56:58.513176  7911 internal_thread.cpp:19] Starting 1 internal thread(s) on device 4
I0228 07:56:58.513324  7911 data_layer.cpp:186] [4] Transform on GPU enabled
I0228 07:56:58.515036  7987 db_lmdb.cpp:36] Opened lmdb /data/imagenet/train-lmdb-uncompressed-256x256
I0228 07:56:58.515637  7909 data_reader.cpp:58] Data Reader threads: 1, out queues: 4, depth: 256
I0228 07:56:58.515970  7909 internal_thread.cpp:19] Starting 1 internal thread(s) on device 2
I0228 07:56:58.516023  7909 data_layer.cpp:186] [2] Transform on GPU enabled
I0228 07:56:58.517633  7988 db_lmdb.cpp:36] Opened lmdb /data/imagenet/train-lmdb-uncompressed-256x256
I0228 07:56:58.517705  7910 data_reader.cpp:58] Data Reader threads: 1, out queues: 4, depth: 256
I0228 07:56:58.517973  7910 internal_thread.cpp:19] Starting 1 internal thread(s) on device 3
I0228 07:56:58.518059  7910 data_layer.cpp:186] [3] Transform on GPU enabled
I0228 07:56:58.520558  7989 db_lmdb.cpp:36] Opened lmdb /data/imagenet/train-lmdb-uncompressed-256x256
I0228 07:56:58.520596  7913 data_reader.cpp:58] Data Reader threads: 1, out queues: 4, depth: 256
I0228 07:56:58.521071  7913 internal_thread.cpp:19] Starting 1 internal thread(s) on device 7
I0228 07:56:58.521245  7913 data_layer.cpp:186] [7] Transform on GPU enabled
I0228 07:56:58.523875  7990 db_lmdb.cpp:36] Opened lmdb /data/imagenet/train-lmdb-uncompressed-256x256
I0228 07:56:58.525207  7881 data_reader.cpp:58] Data Reader threads: 1, out queues: 4, depth: 256
I0228 07:56:58.525485  7881 internal_thread.cpp:19] Starting 1 internal thread(s) on device 0
I0228 07:56:58.525586  7881 data_layer.cpp:186] [0] Transform on GPU enabled
I0228 07:56:58.528009  7991 db_lmdb.cpp:36] Opened lmdb /data/imagenet/train-lmdb-uncompressed-256x256
I0228 07:56:58.565938  7912 data_layer.cpp:199] [5] Output data size: 256, 3, 227, 227
I0228 07:56:58.565980  7912 data_layer.cpp:105] [5] Parser threads: 1 (auto)
I0228 07:56:58.565985  7912 data_layer.cpp:107] [5] Transformer threads: 4 (auto)
I0228 07:56:58.586666  7914 data_layer.cpp:199] [6] Output data size: 256, 3, 227, 227
I0228 07:56:58.586719  7914 data_layer.cpp:105] [6] Parser threads: 1 (auto)
I0228 07:56:58.586724  7914 data_layer.cpp:107] [6] Transformer threads: 4 (auto)
I0228 07:56:58.589138  7908 data_layer.cpp:199] [1] Output data size: 256, 3, 227, 227
I0228 07:56:58.589179  7908 data_layer.cpp:105] [1] Parser threads: 1 (auto)
I0228 07:56:58.589236  7908 data_layer.cpp:107] [1] Transformer threads: 4 (auto)
I0228 07:56:58.594261  7909 data_layer.cpp:199] [2] Output data size: 256, 3, 227, 227
I0228 07:56:58.594310  7909 data_layer.cpp:105] [2] Parser threads: 1 (auto)
I0228 07:56:58.594316  7909 data_layer.cpp:107] [2] Transformer threads: 4 (auto)
I0228 07:56:58.594347  7911 data_layer.cpp:199] [4] Output data size: 256, 3, 227, 227
I0228 07:56:58.594391  7911 data_layer.cpp:105] [4] Parser threads: 1 (auto)
I0228 07:56:58.594415  7911 data_layer.cpp:107] [4] Transformer threads: 4 (auto)
I0228 07:56:58.623256  7910 data_layer.cpp:199] [3] Output data size: 256, 3, 227, 227
I0228 07:56:58.623333  7910 data_layer.cpp:105] [3] Parser threads: 1 (auto)
I0228 07:56:58.623356  7910 data_layer.cpp:107] [3] Transformer threads: 4 (auto)
I0228 07:56:58.626065  7913 data_layer.cpp:199] [7] Output data size: 256, 3, 227, 227
I0228 07:56:58.626153  7913 data_layer.cpp:105] [7] Parser threads: 1 (auto)
I0228 07:56:58.626207  7913 data_layer.cpp:107] [7] Transformer threads: 4 (auto)
I0228 07:56:58.643980  7881 data_layer.cpp:199] [0] Output data size: 256, 3, 227, 227
I0228 07:56:58.644067  7881 data_layer.cpp:105] [0] Parser threads: 1 (auto)
I0228 07:56:58.644101  7881 data_layer.cpp:107] [0] Transformer threads: 4 (auto)
I0228 07:56:58.759609  7968 blocking_queue.cpp:40] Waiting for datum
I0228 07:56:59.381841  7886 solver.cpp:353] Iteration 0 (1.04451 s), loss = 6.91406
I0228 07:56:59.383221  7886 solver.cpp:371]     Train net output #0: loss = 6.91406 (* 1 = 6.91406 loss)
I0228 07:56:59.383242  7886 sgd_solver.cpp:170] Iteration 0, lr = 1, m = 0.9, wd = 0.0005, gs = 1
I0228 07:56:59.473404  7886 solver.cpp:353] Iteration 1 (0.0915451 s), loss = 6.92188
I0228 07:56:59.473624  7886 solver.cpp:371]     Train net output #0: loss = 6.92188 (* 1 = 6.92188 loss)
I0228 07:56:59.821092  7892 cudnn_conv_layer.cpp:853] [6] Conv Algos (F,BD,BF): 'conv1' with space 0.04M 3/1 1T 1 1 	(avail 13.63G, req 0.04M)	t: 0 0 3.73
I0228 07:57:00.072381  7887 cudnn_conv_layer.cpp:853] [1] Conv Algos (F,BD,BF): 'conv1' with space 0.04M 3/1 1T 1 1 	(avail 13.63G, req 0.04M)	t: 0 0 3.74
I0228 07:57:00.086057  7886 cudnn_conv_layer.cpp:853] [0] Conv Algos (F,BD,BF): 'conv1' with space 0.04M 3/1 1p 1 1 	(avail 13.63G, req 0.04M)	t: 0 0 3.76
I0228 07:57:00.090936  7888 cudnn_conv_layer.cpp:853] [2] Conv Algos (F,BD,BF): 'conv1' with space 0.04M 3/1 1Tp 1 1T 	(avail 13.63G, req 0.04M)	t: 0 0 3.75
I0228 07:57:00.092624  7890 cudnn_conv_layer.cpp:853] [4] Conv Algos (F,BD,BF): 'conv1' with space 0.04M 3/1 1Tp 1 1T 	(avail 13.63G, req 0.04M)	t: 0 0 3.76
I0228 07:57:00.096266  7893 cudnn_conv_layer.cpp:853] [7] Conv Algos (F,BD,BF): 'conv1' with space 0.04M 3/1 0 1 1T 	(avail 13.63G, req 0.04M)	t: 0 0 3.91
I0228 07:57:00.108952  7891 cudnn_conv_layer.cpp:853] [5] Conv Algos (F,BD,BF): 'conv1' with space 0.04M 3/1 1 1 1T 	(avail 13.63G, req 0.04M)	t: 0 0 3.75
I0228 07:57:00.110816  7889 cudnn_conv_layer.cpp:853] [3] Conv Algos (F,BD,BF): 'conv1' with space 0.04M 3/1 1p 1 1T 	(avail 13.63G, req 0.04M)	t: 0 0 3.68
I0228 07:57:00.787219  7892 cudnn_conv_layer.cpp:853] [6] Conv Algos (F,BD,BF): 'conv2' with space 0.56G 96/2 5p 3p 5Tp 	(avail 13.07G, req 0.56G)	t: 0 1.06 1.19
I0228 07:57:00.792028  7887 cudnn_conv_layer.cpp:853] [1] Conv Algos (F,BD,BF): 'conv2' with space 0.56G 96/2 5p 3p 5p 	(avail 13.07G, req 0.56G)	t: 0 1.06 1.2
I0228 07:57:01.074748  7886 cudnn_conv_layer.cpp:853] [0] Conv Algos (F,BD,BF): 'conv2' with space 0.56G 96/2 5p 3p 5p 	(avail 13.07G, req 0.56G)	t: 0 1.05 1.2
I0228 07:57:01.091928  7888 cudnn_conv_layer.cpp:853] [2] Conv Algos (F,BD,BF): 'conv2' with space 0.56G 96/2 5p 3p 5Tp 	(avail 13.07G, req 0.56G)	t: 0 1.06 1.19
I0228 07:57:01.092106  7893 cudnn_conv_layer.cpp:853] [7] Conv Algos (F,BD,BF): 'conv2' with space 0.56G 96/2 5p 3p 5p 	(avail 13.07G, req 0.56G)	t: 0 1.04 1.19
I0228 07:57:01.095921  7891 cudnn_conv_layer.cpp:853] [5] Conv Algos (F,BD,BF): 'conv2' with space 0.56G 96/2 5p 3p 5Tp 	(avail 13.07G, req 0.56G)	t: 0 1.04 1.19
I0228 07:57:01.299319  7890 cudnn_conv_layer.cpp:853] [4] Conv Algos (F,BD,BF): 'conv2' with space 0.56G 96/2 5p 3p 5Tp 	(avail 13.07G, req 0.56G)	t: 0 1.05 1.19
I0228 07:57:01.301797  7889 cudnn_conv_layer.cpp:853] [3] Conv Algos (F,BD,BF): 'conv2' with space 0.56G 96/2 5p 3p 5Tp 	(avail 13.07G, req 0.56G)	t: 0 1.04 1.19
I0228 07:57:01.493953  7892 cudnn_conv_layer.cpp:853] [6] Conv Algos (F,BD,BF): 'conv3' with space 0.56G 256/1 7T 5T 1Tp 	(avail 13.07G, req 0.56G)	t: 0 0.74 0.93
I0228 07:57:01.768772  7887 cudnn_conv_layer.cpp:853] [1] Conv Algos (F,BD,BF): 'conv3' with space 0.56G 256/1 7T 5T 1Tp 	(avail 13.07G, req 0.56G)	t: 0 0.72 0.96
I0228 07:57:01.816076  7886 cudnn_conv_layer.cpp:853] [0] Conv Algos (F,BD,BF): 'conv3' with space 0.56G 256/1 7T 5T 1Tp 	(avail 13.07G, req 0.56G)	t: 0 0.72 0.93
I0228 07:57:02.079216  7888 cudnn_conv_layer.cpp:853] [2] Conv Algos (F,BD,BF): 'conv3' with space 0.56G 256/1 7T 5T 1Tp 	(avail 13.07G, req 0.56G)	t: 0 0.71 0.92
I0228 07:57:02.085078  7893 cudnn_conv_layer.cpp:853] [7] Conv Algos (F,BD,BF): 'conv3' with space 0.56G 256/1 7T 5T 1Tp 	(avail 13.07G, req 0.56G)	t: 0 0.71 0.94
I0228 07:57:02.088907  7891 cudnn_conv_layer.cpp:853] [5] Conv Algos (F,BD,BF): 'conv3' with space 0.56G 256/1 7T 5T 1Tp 	(avail 13.07G, req 0.56G)	t: 0 0.72 0.93
I0228 07:57:02.096086  7889 cudnn_conv_layer.cpp:853] [3] Conv Algos (F,BD,BF): 'conv3' with space 0.56G 256/1 7T 5T 1Tp 	(avail 13.07G, req 0.56G)	t: 0 0.71 0.93
I0228 07:57:02.098805  7890 cudnn_conv_layer.cpp:853] [4] Conv Algos (F,BD,BF): 'conv3' with space 0.56G 256/1 7T 5T 1Tp 	(avail 13.07G, req 0.56G)	t: 0 0.71 0.94
I0228 07:57:02.343091  7887 cudnn_conv_layer.cpp:853] [1] Conv Algos (F,BD,BF): 'conv4' with space 0.56G 384/2 7T 5T 5T 	(avail 13.07G, req 0.56G)	t: 0 0.43 0.96
I0228 07:57:02.612406  7886 cudnn_conv_layer.cpp:853] [0] Conv Algos (F,BD,BF): 'conv4' with space 0.56G 384/2 7T 5T 5 	(avail 13.07G, req 0.56G)	t: 0 0.43 0.96
I0228 07:57:02.614110  7892 cudnn_conv_layer.cpp:853] [6] Conv Algos (F,BD,BF): 'conv4' with space 0.56G 384/2 7T 5T 5 	(avail 13.07G, req 0.56G)	t: 0 0.42 0.96
I0228 07:57:02.830400  7888 cudnn_conv_layer.cpp:853] [2] Conv Algos (F,BD,BF): 'conv4' with space 0.56G 384/2 7T 5T 5 	(avail 13.07G, req 0.56G)	t: 0 0.42 0.95
I0228 07:57:02.838167  7889 cudnn_conv_layer.cpp:853] [3] Conv Algos (F,BD,BF): 'conv4' with space 0.56G 384/2 7T 5T 5 	(avail 13.07G, req 0.56G)	t: 0 0.43 0.95
I0228 07:57:02.845741  7893 cudnn_conv_layer.cpp:853] [7] Conv Algos (F,BD,BF): 'conv4' with space 0.56G 384/2 7T 5T 5T 	(avail 13.07G, req 0.56G)	t: 0 0.42 0.96
I0228 07:57:02.861083  7891 cudnn_conv_layer.cpp:853] [5] Conv Algos (F,BD,BF): 'conv4' with space 0.56G 384/2 7T 5T 5T 	(avail 13.07G, req 0.56G)	t: 0 0.43 0.96
I0228 07:57:02.929554  7887 cudnn_conv_layer.cpp:853] [1] Conv Algos (F,BD,BF): 'conv5' with space 0.56G 384/2 7T 5T 2p 	(avail 13.07G, req 0.56G)	t: 0 0.37 0.87
I0228 07:57:02.993492  7890 cudnn_conv_layer.cpp:853] [4] Conv Algos (F,BD,BF): 'conv4' with space 0.56G 384/2 7T 5T 5T 	(avail 13.07G, req 0.56G)	t: 0 0.43 0.96
I0228 07:57:03.276176  7886 cudnn_conv_layer.cpp:853] [0] Conv Algos (F,BD,BF): 'conv5' with space 0.56G 384/2 7T 5T 2p 	(avail 13.07G, req 0.56G)	t: 0 0.36 0.87
I0228 07:57:03.279489  7892 cudnn_conv_layer.cpp:853] [6] Conv Algos (F,BD,BF): 'conv5' with space 0.56G 384/2 7T 5T 2p 	(avail 13.07G, req 0.56G)	t: 0 0.38 0.9
I0228 07:57:03.282958  7889 cudnn_conv_layer.cpp:853] [3] Conv Algos (F,BD,BF): 'conv5' with space 0.56G 384/2 7T 5T 2p 	(avail 13.07G, req 0.56G)	t: 0 0.36 0.87
I0228 07:57:03.285868  7891 cudnn_conv_layer.cpp:853] [5] Conv Algos (F,BD,BF): 'conv5' with space 0.56G 384/2 7T 5T 2p 	(avail 13.07G, req 0.56G)	t: 0 0.36 0.9
I0228 07:57:03.288532  7893 cudnn_conv_layer.cpp:853] [7] Conv Algos (F,BD,BF): 'conv5' with space 0.56G 384/2 7T 5T 2p 	(avail 13.07G, req 0.56G)	t: 0 0.36 0.88
I0228 07:57:03.291654  7888 cudnn_conv_layer.cpp:853] [2] Conv Algos (F,BD,BF): 'conv5' with space 0.56G 384/2 7T 5T 2p 	(avail 13.07G, req 0.56G)	t: 0 0.36 0.9
I0228 07:57:03.535022  7890 cudnn_conv_layer.cpp:853] [4] Conv Algos (F,BD,BF): 'conv5' with space 0.56G 384/2 7T 5T 2p 	(avail 13.07G, req 0.56G)	t: 0 0.38 0.88
I0228 07:57:03.570286  7886 solver.cpp:353] Iteration 2 (4.09679 s), loss = 6.90234
I0228 07:57:03.570389  7886 solver.cpp:371]     Train net output #0: loss = 6.90234 (* 1 = 6.90234 loss)
I0228 07:57:03.947160  7948 blocking_queue.cpp:40] Waiting for datum
I0228 07:57:04.306759  7953 blocking_queue.cpp:40] Waiting for datum
I0228 07:57:04.666311  7963 blocking_queue.cpp:40] Waiting for datum
I0228 07:57:05.039728  7955 blocking_queue.cpp:40] Waiting for datum
I0228 07:57:05.466238  7958 blocking_queue.cpp:40] Waiting for datum
I0228 07:57:05.911577  7962 blocking_queue.cpp:40] Waiting for datum
I0228 07:57:06.302985  7953 blocking_queue.cpp:40] Waiting for datum
I0228 07:57:06.745277  7960 blocking_queue.cpp:40] Waiting for datum
I0228 07:57:07.138810  7953 blocking_queue.cpp:40] Waiting for datum
I0228 07:57:07.641317  7970 blocking_queue.cpp:40] Waiting for datum
I0228 07:57:08.058025  7951 blocking_queue.cpp:40] Waiting for datum
I0228 07:57:08.533640  7950 blocking_queue.cpp:40] Waiting for datum
I0228 07:57:08.997589  7945 blocking_queue.cpp:40] Waiting for datum
I0228 07:57:09.413074  7963 blocking_queue.cpp:40] Waiting for datum
I0228 07:57:09.894333  7952 blocking_queue.cpp:40] Waiting for datum
I0228 07:57:10.310892  7947 blocking_queue.cpp:40] Waiting for datum
I0228 07:57:10.336818  7886 solver.cpp:347] Iteration 100 (14.4834 iter/s, 6.76638s/98 iter), loss = 6.75391
I0228 07:57:10.336926  7886 solver.cpp:371]     Train net output #0: loss = 6.75391 (* 1 = 6.75391 loss)
I0228 07:57:10.336941  7886 sgd_solver.cpp:170] Iteration 100, lr = 0.996487, m = 0.9, wd = 0.0005, gs = 169.85
I0228 07:57:10.791648  7953 blocking_queue.cpp:40] Waiting for datum
I0228 07:57:11.268860  7957 blocking_queue.cpp:40] Waiting for datum
I0228 07:57:11.669661  7959 blocking_queue.cpp:40] Waiting for datum
I0228 07:57:12.126353  7973 blocking_queue.cpp:40] Waiting for datum
I0228 07:57:12.522886  7959 blocking_queue.cpp:40] Waiting for datum
I0228 07:57:13.003897  7963 blocking_queue.cpp:40] Waiting for datum
I0228 07:57:13.478466  7968 blocking_queue.cpp:40] Waiting for datum
I0228 07:57:13.881640  7975 blocking_queue.cpp:40] Waiting for datum
I0228 07:57:14.355129  7973 blocking_queue.cpp:40] Waiting for datum
I0228 07:57:14.767480  7954 blocking_queue.cpp:40] Waiting for datum
I0228 07:57:15.226603  7972 blocking_queue.cpp:40] Waiting for datum
I0228 07:57:15.687494  7949 blocking_queue.cpp:40] Waiting for datum
I0228 07:57:16.093493  7951 blocking_queue.cpp:40] Waiting for datum
I0228 07:57:16.560103  7961 blocking_queue.cpp:40] Waiting for datum
I0228 07:57:16.969888  7969 blocking_queue.cpp:40] Waiting for datum
I0228 07:57:17.234930  7886 solver.cpp:347] Iteration 200 (14.4968 iter/s, 6.89807s/100 iter), loss = 6.48438
I0228 07:57:17.235052  7886 solver.cpp:371]     Train net output #0: loss = 6.48438 (* 1 = 6.48438 loss)
I0228 07:57:17.235069  7886 sgd_solver.cpp:170] Iteration 200, lr = 0.992979, m = 0.9, wd = 0.0005, gs = 421.8
I0228 07:57:17.424201  7975 blocking_queue.cpp:40] Waiting for datum
I0228 07:57:17.886176  7970 blocking_queue.cpp:40] Waiting for datum
I0228 07:57:18.297142  7947 blocking_queue.cpp:40] Waiting for datum
I0228 07:57:18.760068  7952 blocking_queue.cpp:40] Waiting for datum
I0228 07:57:19.152520  7947 blocking_queue.cpp:40] Waiting for datum
I0228 07:57:19.608626  7975 blocking_queue.cpp:40] Waiting for datum
I0228 07:57:20.079843  7973 blocking_queue.cpp:40] Waiting for datum
I0228 07:57:20.492130  7976 blocking_queue.cpp:40] Waiting for datum
I0228 07:57:20.974387  7946 blocking_queue.cpp:40] Waiting for datum
I0228 07:57:21.395195  7969 blocking_queue.cpp:40] Waiting for datum
I0228 07:57:21.853844  7958 blocking_queue.cpp:40] Waiting for datum
I0228 07:57:22.321009  7952 blocking_queue.cpp:40] Waiting for datum
I0228 07:57:22.730999  7959 blocking_queue.cpp:40] Waiting for datum
I0228 07:57:23.206490  7968 blocking_queue.cpp:40] Waiting for datum
I0228 07:57:23.621028  7979 blocking_queue.cpp:40] Waiting for datum
I0228 07:57:24.093178  7963 blocking_queue.cpp:40] Waiting for datum
I0228 07:57:24.181536  7886 solver.cpp:347] Iteration 300 (14.3956 iter/s, 6.94656s/100 iter), loss = 6.26562
I0228 07:57:24.181679  7886 solver.cpp:371]     Train net output #0: loss = 6.26562 (* 1 = 6.26562 loss)
I0228 07:57:24.181694  7886 sgd_solver.cpp:170] Iteration 300, lr = 0.989478, m = 0.9, wd = 0.0005, gs = 1397.17
I0228 07:57:24.564007  7952 blocking_queue.cpp:40] Waiting for datum
I0228 07:57:24.993443  7969 blocking_queue.cpp:40] Waiting for datum
I0228 07:57:25.456308  7950 blocking_queue.cpp:40] Waiting for datum
I0228 07:57:25.872267  7947 blocking_queue.cpp:40] Waiting for datum
I0228 07:57:26.316853  7945 blocking_queue.cpp:40] Waiting for datum
I0228 07:57:26.742959  7972 blocking_queue.cpp:40] Waiting for datum
I0228 07:57:27.214205  7961 blocking_queue.cpp:40] Waiting for datum
I0228 07:57:27.620054  7969 blocking_queue.cpp:40] Waiting for datum
I0228 07:57:28.068262  7977 blocking_queue.cpp:40] Waiting for datum
I0228 07:57:28.533526  7952 blocking_queue.cpp:40] Waiting for datum
I0228 07:57:28.935644  7951 blocking_queue.cpp:40] Waiting for datum
I0228 07:57:29.417186  7973 blocking_queue.cpp:40] Waiting for datum
I0228 07:57:29.831147  7959 blocking_queue.cpp:40] Waiting for datum
I0228 07:57:30.309335  7958 blocking_queue.cpp:40] Waiting for datum
I0228 07:57:30.794621  7945 blocking_queue.cpp:40] Waiting for datum
I0228 07:57:31.224053  7950 blocking_queue.cpp:40] Waiting for datum
I0228 07:57:31.298640  7886 solver.cpp:347] Iteration 400 (14.0508 iter/s, 7.11702s/100 iter), loss = 5.94922
I0228 07:57:31.298748  7886 solver.cpp:371]     Train net output #0: loss = 5.94922 (* 1 = 5.94922 loss)
I0228 07:57:31.298763  7886 sgd_solver.cpp:170] Iteration 400, lr = 0.985983, m = 0.9, wd = 0.0005, gs = 940.17
I0228 07:57:31.715193  7962 blocking_queue.cpp:40] Waiting for datum
I0228 07:57:32.131640  7951 blocking_queue.cpp:40] Waiting for datum
I0228 07:57:32.616283  7977 blocking_queue.cpp:40] Waiting for datum
I0228 07:57:32.616286  7963 blocking_queue.cpp:40] Waiting for datum
I0228 07:57:33.101855  7973 blocking_queue.cpp:40] Waiting for datum
I0228 07:57:33.522732  7951 blocking_queue.cpp:40] Waiting for datum
I0228 07:57:34.006541  7970 blocking_queue.cpp:40] Waiting for datum
I0228 07:57:34.426215  7951 blocking_queue.cpp:40] Waiting for datum
I0228 07:57:34.908516  7946 blocking_queue.cpp:40] Waiting for datum
I0228 07:57:35.398072  7961 blocking_queue.cpp:40] Waiting for datum
I0228 07:57:35.822041  7951 blocking_queue.cpp:40] Waiting for datum
I0228 07:57:36.295702  7954 blocking_queue.cpp:40] Waiting for datum
I0228 07:57:36.710958  7951 blocking_queue.cpp:40] Waiting for datum
I0228 07:57:37.192988  7950 blocking_queue.cpp:40] Waiting for datum
I0228 07:57:37.675787  7957 blocking_queue.cpp:40] Waiting for datum
I0228 07:57:38.094640  7955 blocking_queue.cpp:40] Waiting for datum
I0228 07:57:38.408592  7886 solver.cpp:347] Iteration 500 (14.065 iter/s, 7.10986s/100 iter), loss = 5.78125
I0228 07:57:38.408710  7886 solver.cpp:371]     Train net output #0: loss = 5.78125 (* 1 = 5.78125 loss)
I0228 07:57:38.408723  7886 sgd_solver.cpp:170] Iteration 500, lr = 0.982495, m = 0.9, wd = 0.0005, gs = 1021.77
I0228 07:57:38.569458  7961 blocking_queue.cpp:40] Waiting for datum
I0228 07:57:38.992640  7969 blocking_queue.cpp:40] Waiting for datum
I0228 07:57:39.477062  7946 blocking_queue.cpp:40] Waiting for datum
I0228 07:57:39.942028  7973 blocking_queue.cpp:40] Waiting for datum
I0228 07:57:40.351130  7947 blocking_queue.cpp:40] Waiting for datum
I0228 07:57:40.819984  7957 blocking_queue.cpp:40] Waiting for datum
I0228 07:57:41.232180  7955 blocking_queue.cpp:40] Waiting for datum
I0228 07:57:41.699688  7946 blocking_queue.cpp:40] Waiting for datum
I0228 07:57:42.161959  7976 blocking_queue.cpp:40] Waiting for datum
I0228 07:57:42.161978  7953 blocking_queue.cpp:40] Waiting for datum
I0228 07:57:42.584419  7958 blocking_queue.cpp:40] Waiting for datum
I0228 07:57:43.051563  7945 blocking_queue.cpp:40] Waiting for datum
I0228 07:57:43.464232  7959 blocking_queue.cpp:40] Waiting for datum
I0228 07:57:43.926394  7950 blocking_queue.cpp:40] Waiting for datum
I0228 07:57:44.337545  7969 blocking_queue.cpp:40] Waiting for datum
I0228 07:57:44.805122  7961 blocking_queue.cpp:40] Waiting for datum
I0228 07:57:45.216864  7959 blocking_queue.cpp:40] Waiting for datum
I0228 07:57:45.477368  7886 solver.cpp:347] Iteration 600 (14.1469 iter/s, 7.06869s/100 iter), loss = 5.57422
I0228 07:57:45.477494  7886 solver.cpp:371]     Train net output #0: loss = 5.57422 (* 1 = 5.57422 loss)
I0228 07:57:45.477509  7886 sgd_solver.cpp:170] Iteration 600, lr = 0.979012, m = 0.9, wd = 0.0005, gs = 768.93
I0228 07:57:45.662607  7968 blocking_queue.cpp:40] Waiting for datum
I0228 07:57:46.113224  7953 blocking_queue.cpp:40] Waiting for datum
I0228 07:57:46.530120  7975 blocking_queue.cpp:40] Waiting for datum
I0228 07:57:46.994956  7970 blocking_queue.cpp:40] Waiting for datum
I0228 07:57:47.078537  7988 data_reader.cpp:158] Cached 1281167 records by 8 threads
I0228 07:57:47.078861  7991 data_reader.cpp:178] Shuffling 1281167 records...
I0228 07:57:51.170470  7886 solver.cpp:347] Iteration 700 (17.5654 iter/s, 5.69301s/100 iter), 1.1/90.9ep, loss = 5.51953
I0228 07:57:51.170637  7886 solver.cpp:371]     Train net output #0: loss = 5.51953 (* 1 = 5.51953 loss)
I0228 07:57:51.170655  7886 sgd_solver.cpp:170] Iteration 700, lr = 0.975536, m = 0.9, wd = 0.0005, gs = 1788.85
I0228 07:57:56.354254  7886 solver.cpp:347] Iteration 800 (19.2912 iter/s, 5.18372s/100 iter), 1.3/90.9ep, loss = 5.19531
I0228 07:57:56.354531  7886 solver.cpp:371]     Train net output #0: loss = 5.19531 (* 1 = 5.19531 loss)
I0228 07:57:56.354543  7886 sgd_solver.cpp:170] Iteration 800, lr = 0.972066, m = 0.9, wd = 0.0005, gs = 841.14
I0228 07:58:01.264972  7886 solver.cpp:347] Iteration 900 (20.3641 iter/s, 4.9106s/100 iter), 1.4/90.9ep, loss = 5.13672
I0228 07:58:01.265149  7886 solver.cpp:371]     Train net output #0: loss = 5.13672 (* 1 = 5.13672 loss)
I0228 07:58:01.265162  7886 sgd_solver.cpp:170] Iteration 900, lr = 0.968602, m = 0.9, wd = 0.0005, gs = 1497.63
I0228 07:58:06.166486  7886 solver.cpp:347] Iteration 1000 (20.4022 iter/s, 4.90143s/100 iter), 1.6/90.9ep, loss = 5.13672
I0228 07:58:06.166605  7886 solver.cpp:371]     Train net output #0: loss = 5.13672 (* 1 = 5.13672 loss)
I0228 07:58:06.166618  7886 sgd_solver.cpp:170] Iteration 1000, lr = 0.965144, m = 0.9, wd = 0.0005, gs = 865.62
I0228 07:58:11.119074  7886 solver.cpp:347] Iteration 1100 (20.1915 iter/s, 4.95257s/100 iter), 1.8/90.9ep, loss = 5.05859
I0228 07:58:11.119613  7886 solver.cpp:371]     Train net output #0: loss = 5.05859 (* 1 = 5.05859 loss)
I0228 07:58:11.119628  7886 sgd_solver.cpp:170] Iteration 1100, lr = 0.961693, m = 0.9, wd = 0.0005, gs = 1177.61
I0228 07:58:16.056138  7886 solver.cpp:347] Iteration 1200 (20.2553 iter/s, 4.93698s/100 iter), 1.9/90.9ep, loss = 4.88672
I0228 07:58:16.056304  7886 solver.cpp:371]     Train net output #0: loss = 4.88672 (* 1 = 4.88672 loss)
I0228 07:58:16.056336  7886 sgd_solver.cpp:170] Iteration 1200, lr = 0.958247, m = 0.9, wd = 0.0005, gs = 1019.24
I0228 07:58:18.278237  7985 data_reader.cpp:178] Shuffling 1281167 records...
I0228 07:58:21.009155  7886 solver.cpp:347] Iteration 1300 (20.1901 iter/s, 4.95292s/100 iter), 2.1/90.9ep, loss = 4.75781
I0228 07:58:21.009354  7886 solver.cpp:371]     Train net output #0: loss = 4.75781 (* 1 = 4.75781 loss)
I0228 07:58:21.009397  7886 sgd_solver.cpp:170] Iteration 1300, lr = 0.954808, m = 0.9, wd = 0.0005, gs = 1054.23
I0228 07:58:25.979908  7886 solver.cpp:347] Iteration 1400 (20.118 iter/s, 4.97066s/100 iter), 2.2/90.9ep, loss = 4.86328
I0228 07:58:25.980047  7886 solver.cpp:371]     Train net output #0: loss = 4.86328 (* 1 = 4.86328 loss)
I0228 07:58:25.980060  7886 sgd_solver.cpp:170] Iteration 1400, lr = 0.951375, m = 0.9, wd = 0.0005, gs = 919.58
I0228 07:58:30.944921  7886 solver.cpp:347] Iteration 1500 (20.1412 iter/s, 4.96496s/100 iter), 2.4/90.9ep, loss = 4.69141
I0228 07:58:30.945057  7886 solver.cpp:371]     Train net output #0: loss = 4.69141 (* 1 = 4.69141 loss)
I0228 07:58:30.945070  7886 sgd_solver.cpp:170] Iteration 1500, lr = 0.947948, m = 0.9, wd = 0.0005, gs = 804.31
I0228 07:58:35.955785  7886 solver.cpp:347] Iteration 1600 (19.9571 iter/s, 5.01074s/100 iter), 2.6/90.9ep, loss = 4.87109
I0228 07:58:35.955902  7886 solver.cpp:371]     Train net output #0: loss = 4.87109 (* 1 = 4.87109 loss)
I0228 07:58:35.955912  7886 sgd_solver.cpp:170] Iteration 1600, lr = 0.944528, m = 0.9, wd = 0.0005, gs = 1814.92
I0228 07:58:40.977205  7886 solver.cpp:347] Iteration 1700 (19.915 iter/s, 5.02134s/100 iter), 2.7/90.9ep, loss = 4.92578
I0228 07:58:40.977372  7886 solver.cpp:371]     Train net output #0: loss = 4.92578 (* 1 = 4.92578 loss)
I0228 07:58:40.977385  7886 sgd_solver.cpp:170] Iteration 1700, lr = 0.941113, m = 0.9, wd = 0.0005, gs = 929.61
I0228 07:58:45.965694  7886 solver.cpp:347] Iteration 1800 (20.0462 iter/s, 4.98847s/100 iter), 2.9/90.9ep, loss = 4.61719
I0228 07:58:45.966111  7886 solver.cpp:371]     Train net output #0: loss = 4.61719 (* 1 = 4.61719 loss)
I0228 07:58:45.966135  7886 sgd_solver.cpp:170] Iteration 1800, lr = 0.937705, m = 0.9, wd = 0.0005, gs = 1410.95
I0228 07:58:49.411643  7984 data_reader.cpp:178] Shuffling 1281167 records...
I0228 07:58:50.920825  7886 solver.cpp:347] Iteration 1900 (20.1814 iter/s, 4.95506s/100 iter), 3/90.9ep, loss = 4.5625
I0228 07:58:50.920954  7886 solver.cpp:371]     Train net output #0: loss = 4.5625 (* 1 = 4.5625 loss)
I0228 07:58:50.920964  7886 sgd_solver.cpp:170] Iteration 1900, lr = 0.934303, m = 0.9, wd = 0.0005, gs = 1347.64
I0228 07:58:55.940569  7886 solver.cpp:347] Iteration 2000 (19.922 iter/s, 5.01958s/100 iter), 3.2/90.9ep, loss = 4.26562
I0228 07:58:55.940757  7886 solver.cpp:371]     Train net output #0: loss = 4.26562 (* 1 = 4.26562 loss)
I0228 07:58:55.940770  7886 sgd_solver.cpp:170] Iteration 2000, lr = 0.930907, m = 0.9, wd = 0.0005, gs = 1109.89
I0228 07:59:00.940363  7886 solver.cpp:347] Iteration 2100 (20.001 iter/s, 4.99976s/100 iter), 3.4/90.9ep, loss = 4.18359
I0228 07:59:00.940498  7886 solver.cpp:371]     Train net output #0: loss = 4.18359 (* 1 = 4.18359 loss)
I0228 07:59:00.940549  7886 sgd_solver.cpp:170] Iteration 2100, lr = 0.927517, m = 0.9, wd = 0.0005, gs = 1018.11
I0228 07:59:05.910356  7886 solver.cpp:347] Iteration 2200 (20.1214 iter/s, 4.96983s/100 iter), 3.5/90.9ep, loss = 4.41016
I0228 07:59:05.910537  7886 solver.cpp:371]     Train net output #0: loss = 4.41016 (* 1 = 4.41016 loss)
I0228 07:59:05.910558  7886 sgd_solver.cpp:170] Iteration 2200, lr = 0.924134, m = 0.9, wd = 0.0005, gs = 1122.89
I0228 07:59:10.916982  7886 solver.cpp:347] Iteration 2300 (19.9735 iter/s, 5.00664s/100 iter), 3.7/90.9ep, loss = 3.99805
I0228 07:59:10.917089  7886 solver.cpp:371]     Train net output #0: loss = 3.99805 (* 1 = 3.99805 loss)
I0228 07:59:10.917117  7886 sgd_solver.cpp:170] Iteration 2300, lr = 0.920756, m = 0.9, wd = 0.0005, gs = 1144.96
I0228 07:59:15.896512  7886 solver.cpp:347] Iteration 2400 (20.0826 iter/s, 4.97944s/100 iter), 3.8/90.9ep, loss = 4.13281
I0228 07:59:15.896653  7886 solver.cpp:371]     Train net output #0: loss = 4.13281 (* 1 = 4.13281 loss)
I0228 07:59:15.896672  7886 sgd_solver.cpp:170] Iteration 2400, lr = 0.917385, m = 0.9, wd = 0.0005, gs = 1673.12
I0228 07:59:20.709817  7987 data_reader.cpp:178] Shuffling 1281167 records...
I0228 07:59:20.856375  7886 solver.cpp:347] Iteration 2500 (20.1622 iter/s, 4.95976s/100 iter), 4/90.9ep, loss = 4.09375
I0228 07:59:20.856537  7886 solver.cpp:371]     Train net output #0: loss = 4.09375 (* 1 = 4.09375 loss)
I0228 07:59:20.856547  7886 sgd_solver.cpp:170] Iteration 2500, lr = 0.91402, m = 0.9, wd = 0.0005, gs = 1299.23
I0228 07:59:25.888401  7886 solver.cpp:347] Iteration 2600 (19.8729 iter/s, 5.03197s/100 iter), 4.2/90.9ep, loss = 4.0625
I0228 07:59:25.888520  7886 solver.cpp:371]     Train net output #0: loss = 4.0625 (* 1 = 4.0625 loss)
I0228 07:59:25.888532  7886 sgd_solver.cpp:170] Iteration 2600, lr = 0.910661, m = 0.9, wd = 0.0005, gs = 956.92
I0228 07:59:30.921784  7886 solver.cpp:347] Iteration 2700 (19.8679 iter/s, 5.03324s/100 iter), 4.3/90.9ep, loss = 4.18359
I0228 07:59:30.921939  7886 solver.cpp:371]     Train net output #0: loss = 4.18359 (* 1 = 4.18359 loss)
I0228 07:59:30.921962  7886 sgd_solver.cpp:170] Iteration 2700, lr = 0.907309, m = 0.9, wd = 0.0005, gs = 742.13
I0228 07:59:33.376026  7983 blocking_queue.cpp:40] Data layer prefetch queue empty
I0228 07:59:35.950647  7886 solver.cpp:347] Iteration 2800 (19.8854 iter/s, 5.02882s/100 iter), 4.5/90.9ep, loss = 4.00391
I0228 07:59:35.950788  7886 solver.cpp:371]     Train net output #0: loss = 4.00391 (* 1 = 4.00391 loss)
I0228 07:59:35.950808  7886 sgd_solver.cpp:170] Iteration 2800, lr = 0.903962, m = 0.9, wd = 0.0005, gs = 944.42
I0228 07:59:40.969794  7886 solver.cpp:347] Iteration 2900 (19.9241 iter/s, 5.01904s/100 iter), 4.6/90.9ep, loss = 4.03516
I0228 07:59:40.969925  7886 solver.cpp:371]     Train net output #0: loss = 4.03516 (* 1 = 4.03516 loss)
I0228 07:59:40.969938  7886 sgd_solver.cpp:170] Iteration 2900, lr = 0.900622, m = 0.9, wd = 0.0005, gs = 986.82
I0228 07:59:45.962944  7886 solver.cpp:347] Iteration 3000 (20.0278 iter/s, 4.99307s/100 iter), 4.8/90.9ep, loss = 3.85156
I0228 07:59:45.963141  7886 solver.cpp:371]     Train net output #0: loss = 3.85156 (* 1 = 3.85156 loss)
I0228 07:59:45.963153  7886 sgd_solver.cpp:170] Iteration 3000, lr = 0.897288, m = 0.9, wd = 0.0005, gs = 1051.88
I0228 07:59:50.900609  7886 solver.cpp:347] Iteration 3100 (20.2528 iter/s, 4.93759s/100 iter), 5/90.9ep, loss = 3.92773
I0228 07:59:50.901196  7886 solver.cpp:371]     Train net output #0: loss = 3.92773 (* 1 = 3.92773 loss)
I0228 07:59:50.901219  7886 sgd_solver.cpp:170] Iteration 3100, lr = 0.89396, m = 0.9, wd = 0.0005, gs = 1031.4
I0228 07:59:51.939182  7987 data_reader.cpp:178] Shuffling 1281167 records...
I0228 07:59:55.874439  7886 solver.cpp:347] Iteration 3200 (20.1057 iter/s, 4.97372s/100 iter), 5.1/90.9ep, loss = 3.57812
I0228 07:59:55.874603  7886 solver.cpp:371]     Train net output #0: loss = 3.57812 (* 1 = 3.57812 loss)
I0228 07:59:55.874647  7886 sgd_solver.cpp:170] Iteration 3200, lr = 0.890638, m = 0.9, wd = 0.0005, gs = 1284.69
I0228 08:00:00.866932  7886 solver.cpp:347] Iteration 3300 (20.0303 iter/s, 4.99244s/100 iter), 5.3/90.9ep, loss = 3.84375
I0228 08:00:00.867063  7886 solver.cpp:371]     Train net output #0: loss = 3.84375 (* 1 = 3.84375 loss)
I0228 08:00:00.867071  7886 sgd_solver.cpp:170] Iteration 3300, lr = 0.887323, m = 0.9, wd = 0.0005, gs = 1107.21
I0228 08:00:05.829808  7886 solver.cpp:347] Iteration 3400 (20.1499 iter/s, 4.96281s/100 iter), 5.4/90.9ep, loss = 3.97461
I0228 08:00:05.829951  7886 solver.cpp:371]     Train net output #0: loss = 3.97461 (* 1 = 3.97461 loss)
I0228 08:00:05.829963  7886 sgd_solver.cpp:170] Iteration 3400, lr = 0.884013, m = 0.9, wd = 0.0005, gs = 1172.44
I0228 08:00:10.823853  7886 solver.cpp:347] Iteration 3500 (20.0243 iter/s, 4.99393s/100 iter), 5.6/90.9ep, loss = 3.98633
I0228 08:00:10.823998  7886 solver.cpp:371]     Train net output #0: loss = 3.98633 (* 1 = 3.98633 loss)
I0228 08:00:10.824059  7886 sgd_solver.cpp:170] Iteration 3500, lr = 0.88071, m = 0.9, wd = 0.0005, gs = 774.01
I0228 08:00:15.823231  7886 solver.cpp:347] Iteration 3600 (20.003 iter/s, 4.99925s/100 iter), 5.8/90.9ep, loss = 3.56641
I0228 08:00:15.823355  7886 solver.cpp:371]     Train net output #0: loss = 3.56641 (* 1 = 3.56641 loss)
I0228 08:00:15.823369  7886 sgd_solver.cpp:170] Iteration 3600, lr = 0.877413, m = 0.9, wd = 0.0005, gs = 1009.51
I0228 08:00:20.788169  7886 solver.cpp:347] Iteration 3700 (20.1415 iter/s, 4.96488s/100 iter), 5.9/90.9ep, loss = 3.75
I0228 08:00:20.788333  7886 solver.cpp:371]     Train net output #0: loss = 3.75 (* 1 = 3.75 loss)
I0228 08:00:20.788347  7886 sgd_solver.cpp:170] Iteration 3700, lr = 0.874122, m = 0.9, wd = 0.0005, gs = 978.82
I0228 08:00:23.197641  7990 data_reader.cpp:178] Shuffling 1281167 records...
I0228 08:00:25.734658  7886 solver.cpp:347] Iteration 3800 (20.2166 iter/s, 4.94642s/100 iter), 6.1/90.9ep, loss = 3.54883
I0228 08:00:25.734797  7886 solver.cpp:371]     Train net output #0: loss = 3.54883 (* 1 = 3.54883 loss)
I0228 08:00:25.734807  7886 sgd_solver.cpp:170] Iteration 3800, lr = 0.870838, m = 0.9, wd = 0.0005, gs = 751.99
I0228 08:00:30.712810  7886 solver.cpp:347] Iteration 3900 (20.0882 iter/s, 4.97806s/100 iter), 6.2/90.9ep, loss = 3.55078
I0228 08:00:30.712987  7886 solver.cpp:371]     Train net output #0: loss = 3.55078 (* 1 = 3.55078 loss)
I0228 08:00:30.713001  7886 sgd_solver.cpp:170] Iteration 3900, lr = 0.867559, m = 0.9, wd = 0.0005, gs = 1034.79
I0228 08:00:35.680089  7886 solver.cpp:347] Iteration 4000 (20.1322 iter/s, 4.96718s/100 iter), 6.4/90.9ep, loss = 3.63672
I0228 08:00:35.680207  7886 solver.cpp:371]     Train net output #0: loss = 3.63672 (* 1 = 3.63672 loss)
I0228 08:00:35.680222  7886 sgd_solver.cpp:170] Iteration 4000, lr = 0.864287, m = 0.9, wd = 0.0005, gs = 715.66
I0228 08:00:40.681768  7886 solver.cpp:347] Iteration 4100 (19.9936 iter/s, 5.00159s/100 iter), 6.6/90.9ep, loss = 3.36719
I0228 08:00:40.681900  7886 solver.cpp:371]     Train net output #0: loss = 3.36719 (* 1 = 3.36719 loss)
I0228 08:00:40.681910  7886 sgd_solver.cpp:170] Iteration 4100, lr = 0.861021, m = 0.9, wd = 0.0005, gs = 1050.48
I0228 08:00:45.700812  7886 solver.cpp:347] Iteration 4200 (19.9244 iter/s, 5.01896s/100 iter), 6.7/90.9ep, loss = 3.39258
I0228 08:00:45.700939  7886 solver.cpp:371]     Train net output #0: loss = 3.39258 (* 1 = 3.39258 loss)
I0228 08:00:45.701001  7886 sgd_solver.cpp:170] Iteration 4200, lr = 0.857761, m = 0.9, wd = 0.0005, gs = 747.81
I0228 08:00:50.657872  7886 solver.cpp:347] Iteration 4300 (20.1734 iter/s, 4.95703s/100 iter), 6.9/90.9ep, loss = 3.51953
I0228 08:00:50.658013  7886 solver.cpp:371]     Train net output #0: loss = 3.51953 (* 1 = 3.51953 loss)
I0228 08:00:50.658057  7886 sgd_solver.cpp:170] Iteration 4300, lr = 0.854507, m = 0.9, wd = 0.0005, gs = 1088.52
I0228 08:00:54.264974  7984 data_reader.cpp:178] Shuffling 1281167 records...
I0228 08:00:55.609252  7886 solver.cpp:347] Iteration 4400 (20.1968 iter/s, 4.95129s/100 iter), 7/90.9ep, loss = 3.49805
I0228 08:00:55.609426  7886 solver.cpp:371]     Train net output #0: loss = 3.49805 (* 1 = 3.49805 loss)
I0228 08:00:55.609438  7886 sgd_solver.cpp:170] Iteration 4400, lr = 0.85126, m = 0.9, wd = 0.0005, gs = 1217.76
I0228 08:01:00.630957  7886 solver.cpp:347] Iteration 4500 (19.914 iter/s, 5.02159s/100 iter), 7.2/90.9ep, loss = 3.44141
I0228 08:01:00.631134  7886 solver.cpp:371]     Train net output #0: loss = 3.44141 (* 1 = 3.44141 loss)
I0228 08:01:00.631146  7886 sgd_solver.cpp:170] Iteration 4500, lr = 0.848018, m = 0.9, wd = 0.0005, gs = 946.73
I0228 08:01:05.636226  7886 solver.cpp:347] Iteration 4600 (19.9791 iter/s, 5.00523s/100 iter), 7.4/90.9ep, loss = 3.26953
I0228 08:01:05.636369  7886 solver.cpp:371]     Train net output #0: loss = 3.26953 (* 1 = 3.26953 loss)
I0228 08:01:05.636382  7886 sgd_solver.cpp:170] Iteration 4600, lr = 0.844783, m = 0.9, wd = 0.0005, gs = 1126.55
I0228 08:01:10.663841  7886 solver.cpp:347] Iteration 4700 (19.8905 iter/s, 5.02754s/100 iter), 7.5/90.9ep, loss = 3.43945
I0228 08:01:10.664016  7886 solver.cpp:371]     Train net output #0: loss = 3.43945 (* 1 = 3.43945 loss)
I0228 08:01:10.664026  7886 sgd_solver.cpp:170] Iteration 4700, lr = 0.841554, m = 0.9, wd = 0.0005, gs = 1097.39
I0228 08:01:15.674877  7886 solver.cpp:347] Iteration 4800 (19.9563 iter/s, 5.01096s/100 iter), 7.7/90.9ep, loss = 2.94336
I0228 08:01:15.675040  7886 solver.cpp:371]     Train net output #0: loss = 2.94336 (* 1 = 2.94336 loss)
I0228 08:01:15.675053  7886 sgd_solver.cpp:170] Iteration 4800, lr = 0.838331, m = 0.9, wd = 0.0005, gs = 775.21
I0228 08:01:20.691130  7886 solver.cpp:347] Iteration 4900 (19.9355 iter/s, 5.01617s/100 iter), 7.8/90.9ep, loss = 3.10938
I0228 08:01:20.691282  7886 solver.cpp:371]     Train net output #0: loss = 3.10938 (* 1 = 3.10938 loss)
I0228 08:01:20.691292  7886 sgd_solver.cpp:170] Iteration 4900, lr = 0.835115, m = 0.9, wd = 0.0005, gs = 843.54
I0228 08:01:25.565062  7991 data_reader.cpp:178] Shuffling 1281167 records...
I0228 08:01:25.681298  7886 solver.cpp:347] Iteration 5000 (20.0398 iter/s, 4.99007s/100 iter), 8/90.9ep, loss = 3.37109
I0228 08:01:25.681452  7886 solver.cpp:371]     Train net output #0: loss = 3.37109 (* 1 = 3.37109 loss)
I0228 08:01:25.681464  7886 sgd_solver.cpp:170] Iteration 5000, lr = 0.831904, m = 0.9, wd = 0.0005, gs = 698.35
I0228 08:01:30.710711  7886 solver.cpp:347] Iteration 5100 (19.8833 iter/s, 5.02934s/100 iter), 8.2/90.9ep, loss = 3.13672
I0228 08:01:30.710832  7886 solver.cpp:371]     Train net output #0: loss = 3.13672 (* 1 = 3.13672 loss)
I0228 08:01:30.710842  7886 sgd_solver.cpp:170] Iteration 5100, lr = 0.8287, m = 0.9, wd = 0.0005, gs = 901.52
I0228 08:01:35.732115  7886 solver.cpp:347] Iteration 5200 (19.915 iter/s, 5.02134s/100 iter), 8.3/90.9ep, loss = 3.44336
I0228 08:01:35.732278  7886 solver.cpp:371]     Train net output #0: loss = 3.44336 (* 1 = 3.44336 loss)
I0228 08:01:35.732290  7886 sgd_solver.cpp:170] Iteration 5200, lr = 0.825502, m = 0.9, wd = 0.0005, gs = 596.17
I0228 08:01:40.668591  7886 solver.cpp:347] Iteration 5300 (20.2579 iter/s, 4.93635s/100 iter), 8.5/90.9ep, loss = 3.26172
I0228 08:01:40.668790  7886 solver.cpp:371]     Train net output #0: loss = 3.26172 (* 1 = 3.26172 loss)
I0228 08:01:40.668819  7886 sgd_solver.cpp:170] Iteration 5300, lr = 0.82231, m = 0.9, wd = 0.0005, gs = 948.8
I0228 08:01:45.632460  7886 solver.cpp:347] Iteration 5400 (20.1461 iter/s, 4.96375s/100 iter), 8.6/90.9ep, loss = 3.25
I0228 08:01:45.632633  7886 solver.cpp:371]     Train net output #0: loss = 3.25 (* 1 = 3.25 loss)
I0228 08:01:45.632653  7886 sgd_solver.cpp:170] Iteration 5400, lr = 0.819124, m = 0.9, wd = 0.0005, gs = 892.34
I0228 08:01:50.594727  7886 solver.cpp:347] Iteration 5500 (20.1521 iter/s, 4.96227s/100 iter), 8.8/90.9ep, loss = 3.04102
I0228 08:01:50.594892  7886 solver.cpp:371]     Train net output #0: loss = 3.04102 (* 1 = 3.04102 loss)
I0228 08:01:50.594902  7886 sgd_solver.cpp:170] Iteration 5500, lr = 0.815945, m = 0.9, wd = 0.0005, gs = 863.59
I0228 08:01:55.598626  7886 solver.cpp:347] Iteration 5600 (19.9849 iter/s, 5.00378s/100 iter), 9/90.9ep, loss = 3.31445
I0228 08:01:55.599117  7886 solver.cpp:371]     Train net output #0: loss = 3.31445 (* 1 = 3.31445 loss)
I0228 08:01:55.599131  7886 sgd_solver.cpp:170] Iteration 5600, lr = 0.812772, m = 0.9, wd = 0.0005, gs = 770.86
I0228 08:01:56.827471  7990 data_reader.cpp:178] Shuffling 1281167 records...
I0228 08:02:00.558010  7886 solver.cpp:347] Iteration 5700 (20.1641 iter/s, 4.95931s/100 iter), 9.1/90.9ep, loss = 2.99023
I0228 08:02:00.558178  7886 solver.cpp:371]     Train net output #0: loss = 2.99023 (* 1 = 2.99023 loss)
I0228 08:02:00.558187  7886 sgd_solver.cpp:170] Iteration 5700, lr = 0.809604, m = 0.9, wd = 0.0005, gs = 1168.37
I0228 08:02:05.538460  7886 solver.cpp:347] Iteration 5800 (20.0789 iter/s, 4.98036s/100 iter), 9.3/90.9ep, loss = 3.1582
I0228 08:02:05.538622  7886 solver.cpp:371]     Train net output #0: loss = 3.1582 (* 1 = 3.1582 loss)
I0228 08:02:05.538635  7886 sgd_solver.cpp:170] Iteration 5800, lr = 0.806444, m = 0.9, wd = 0.0005, gs = 778.04
I0228 08:02:10.527772  7886 solver.cpp:347] Iteration 5900 (20.0433 iter/s, 4.9892s/100 iter), 9.4/90.9ep, loss = 3.12109
I0228 08:02:10.527935  7886 solver.cpp:371]     Train net output #0: loss = 3.12109 (* 1 = 3.12109 loss)
I0228 08:02:10.527964  7886 sgd_solver.cpp:170] Iteration 5900, lr = 0.803289, m = 0.9, wd = 0.0005, gs = 734.41
I0228 08:02:15.520819  7886 solver.cpp:347] Iteration 6000 (20.028 iter/s, 4.99302s/100 iter), 9.6/90.9ep, loss = 3.23828
I0228 08:02:15.520920  7886 solver.cpp:371]     Train net output #0: loss = 3.23828 (* 1 = 3.23828 loss)
I0228 08:02:15.520941  7886 sgd_solver.cpp:170] Iteration 6000, lr = 0.80014, m = 0.9, wd = 0.0005, gs = 634.18
I0228 08:02:20.527066  7886 solver.cpp:347] Iteration 6100 (19.9754 iter/s, 5.00617s/100 iter), 9.8/90.9ep, loss = 3.16602
I0228 08:02:20.527248  7886 solver.cpp:371]     Train net output #0: loss = 3.16602 (* 1 = 3.16602 loss)
I0228 08:02:20.527277  7886 sgd_solver.cpp:170] Iteration 6100, lr = 0.796998, m = 0.9, wd = 0.0005, gs = 604.43
I0228 08:02:23.963923  7964 blocking_queue.cpp:40] Data layer prefetch queue empty
I0228 08:02:25.529068  7886 solver.cpp:347] Iteration 6200 (19.9923 iter/s, 5.00192s/100 iter), 9.9/90.9ep, loss = 3.02148
I0228 08:02:25.529158  7886 solver.cpp:371]     Train net output #0: loss = 3.02148 (* 1 = 3.02148 loss)
I0228 08:02:25.529181  7886 sgd_solver.cpp:170] Iteration 6200, lr = 0.793861, m = 0.9, wd = 0.0005, gs = 572.09
I0228 08:02:27.980686  7985 data_reader.cpp:178] Shuffling 1281167 records...
I0228 08:02:30.534673  7886 solver.cpp:347] Iteration 6300 (19.9779 iter/s, 5.00552s/100 iter), 10.1/90.9ep, loss = 2.82031
I0228 08:02:30.534807  7886 solver.cpp:371]     Train net output #0: loss = 2.82031 (* 1 = 2.82031 loss)
I0228 08:02:30.534884  7886 sgd_solver.cpp:170] Iteration 6300, lr = 0.790731, m = 0.9, wd = 0.0005, gs = 606.62
I0228 08:02:35.558523  7886 solver.cpp:347] Iteration 6400 (19.9053 iter/s, 5.02378s/100 iter), 10.2/90.9ep, loss = 3.1582
I0228 08:02:35.558755  7886 solver.cpp:371]     Train net output #0: loss = 3.1582 (* 1 = 3.1582 loss)
I0228 08:02:35.558768  7886 sgd_solver.cpp:170] Iteration 6400, lr = 0.787607, m = 0.9, wd = 0.0005, gs = 566.03
I0228 08:02:40.551410  7886 solver.cpp:347] Iteration 6500 (20.0289 iter/s, 4.9928s/100 iter), 10.4/90.9ep, loss = 2.66992
I0228 08:02:40.551616  7886 solver.cpp:371]     Train net output #0: loss = 2.66992 (* 1 = 2.66992 loss)
I0228 08:02:40.551630  7886 sgd_solver.cpp:170] Iteration 6500, lr = 0.78449, m = 0.9, wd = 0.0005, gs = 922.69
I0228 08:02:45.540758  7886 solver.cpp:347] Iteration 6600 (20.0432 iter/s, 4.98922s/100 iter), 10.6/90.9ep, loss = 3.17773
I0228 08:02:45.540942  7886 solver.cpp:371]     Train net output #0: loss = 3.17773 (* 1 = 3.17773 loss)
I0228 08:02:45.540999  7886 sgd_solver.cpp:170] Iteration 6600, lr = 0.781378, m = 0.9, wd = 0.0005, gs = 985.72
I0228 08:02:50.516882  7886 solver.cpp:347] Iteration 6700 (20.0961 iter/s, 4.9761s/100 iter), 10.7/90.9ep, loss = 2.76953
I0228 08:02:50.517021  7886 solver.cpp:371]     Train net output #0: loss = 2.76953 (* 1 = 2.76953 loss)
I0228 08:02:50.517042  7886 sgd_solver.cpp:170] Iteration 6700, lr = 0.778273, m = 0.9, wd = 0.0005, gs = 669.59
I0228 08:02:55.537520  7886 solver.cpp:347] Iteration 6800 (19.9181 iter/s, 5.02056s/100 iter), 10.9/90.9ep, loss = 3.04688
I0228 08:02:55.537634  7886 solver.cpp:371]     Train net output #0: loss = 3.04688 (* 1 = 3.04688 loss)
I0228 08:02:55.537644  7886 sgd_solver.cpp:170] Iteration 6800, lr = 0.775174, m = 0.9, wd = 0.0005, gs = 969.52
I0228 08:02:59.385115  7989 data_reader.cpp:178] Shuffling 1281167 records...
I0228 08:03:00.563602  7886 solver.cpp:347] Iteration 6900 (19.8967 iter/s, 5.02597s/100 iter), 11/90.9ep, loss = 2.94922
I0228 08:03:00.563758  7886 solver.cpp:371]     Train net output #0: loss = 2.94922 (* 1 = 2.94922 loss)
I0228 08:03:00.563767  7886 sgd_solver.cpp:170] Iteration 6900, lr = 0.772081, m = 0.9, wd = 0.0005, gs = 612.34
I0228 08:03:05.600816  7886 solver.cpp:347] Iteration 7000 (19.8524 iter/s, 5.03717s/100 iter), 11.2/90.9ep, loss = 3.00391
I0228 08:03:05.600968  7886 solver.cpp:371]     Train net output #0: loss = 3.00391 (* 1 = 3.00391 loss)
I0228 08:03:05.600982  7886 sgd_solver.cpp:170] Iteration 7000, lr = 0.768994, m = 0.9, wd = 0.0005, gs = 927.94
I0228 08:03:10.650215  7886 solver.cpp:347] Iteration 7100 (19.805 iter/s, 5.04923s/100 iter), 11.3/90.9ep, loss = 2.99609
I0228 08:03:10.650362  7886 solver.cpp:371]     Train net output #0: loss = 2.99609 (* 1 = 2.99609 loss)
I0228 08:03:10.650374  7886 sgd_solver.cpp:170] Iteration 7100, lr = 0.765914, m = 0.9, wd = 0.0005, gs = 591.38
I0228 08:03:15.679280  7886 solver.cpp:347] Iteration 7200 (19.8846 iter/s, 5.02902s/100 iter), 11.5/90.9ep, loss = 2.93359
I0228 08:03:15.679410  7886 solver.cpp:371]     Train net output #0: loss = 2.93359 (* 1 = 2.93359 loss)
I0228 08:03:15.679435  7886 sgd_solver.cpp:170] Iteration 7200, lr = 0.762839, m = 0.9, wd = 0.0005, gs = 990.54
I0228 08:03:20.751317  7886 solver.cpp:347] Iteration 7300 (19.7163 iter/s, 5.07195s/100 iter), 11.7/90.9ep, loss = 2.91406
I0228 08:03:20.751448  7886 solver.cpp:371]     Train net output #0: loss = 2.91406 (* 1 = 2.91406 loss)
I0228 08:03:20.751458  7886 sgd_solver.cpp:170] Iteration 7300, lr = 0.759771, m = 0.9, wd = 0.0005, gs = 835.1
I0228 08:03:25.687819  7886 solver.cpp:347] Iteration 7400 (20.258 iter/s, 4.93633s/100 iter), 11.8/90.9ep, loss = 2.95117
I0228 08:03:25.688062  7886 solver.cpp:371]     Train net output #0: loss = 2.95117 (* 1 = 2.95117 loss)
I0228 08:03:25.688087  7886 sgd_solver.cpp:170] Iteration 7400, lr = 0.756709, m = 0.9, wd = 0.0005, gs = 760.4
I0228 08:03:30.618273  7886 solver.cpp:347] Iteration 7500 (20.2822 iter/s, 4.93044s/100 iter), 12/90.9ep, loss = 2.72266
I0228 08:03:30.618839  7886 solver.cpp:371]     Train net output #0: loss = 2.72266 (* 1 = 2.72266 loss)
I0228 08:03:30.618854  7886 sgd_solver.cpp:170] Iteration 7500, lr = 0.753653, m = 0.9, wd = 0.0005, gs = 656.79
I0228 08:03:30.665400  7988 data_reader.cpp:178] Shuffling 1281167 records...
I0228 08:03:35.601379  7886 solver.cpp:347] Iteration 7600 (20.0682 iter/s, 4.98301s/100 iter), 12.1/90.9ep, loss = 2.52539
I0228 08:03:35.601516  7886 solver.cpp:371]     Train net output #0: loss = 2.52539 (* 1 = 2.52539 loss)
I0228 08:03:35.601528  7886 sgd_solver.cpp:170] Iteration 7600, lr = 0.750603, m = 0.9, wd = 0.0005, gs = 516.28
I0228 08:03:40.598537  7886 solver.cpp:347] Iteration 7700 (20.0118 iter/s, 4.99706s/100 iter), 12.3/90.9ep, loss = 2.87305
I0228 08:03:40.598711  7886 solver.cpp:371]     Train net output #0: loss = 2.87305 (* 1 = 2.87305 loss)
I0228 08:03:40.598731  7886 sgd_solver.cpp:170] Iteration 7700, lr = 0.74756, m = 0.9, wd = 0.0005, gs = 814.45
I0228 08:03:45.609069  7886 solver.cpp:347] Iteration 7800 (19.9581 iter/s, 5.01049s/100 iter), 12.5/90.9ep, loss = 2.68359
I0228 08:03:45.609205  7886 solver.cpp:371]     Train net output #0: loss = 2.68359 (* 1 = 2.68359 loss)
I0228 08:03:45.609216  7886 sgd_solver.cpp:170] Iteration 7800, lr = 0.744523, m = 0.9, wd = 0.0005, gs = 682.48
I0228 08:03:50.577657  7886 solver.cpp:347] Iteration 7900 (20.1269 iter/s, 4.96847s/100 iter), 12.6/90.9ep, loss = 2.7793
I0228 08:03:50.577811  7886 solver.cpp:371]     Train net output #0: loss = 2.7793 (* 1 = 2.7793 loss)
I0228 08:03:50.577832  7886 sgd_solver.cpp:170] Iteration 7900, lr = 0.741491, m = 0.9, wd = 0.0005, gs = 856.38
I0228 08:03:55.564254  7886 solver.cpp:347] Iteration 8000 (20.0541 iter/s, 4.9865s/100 iter), 12.8/90.9ep, loss = 2.85938
I0228 08:03:55.564426  7886 solver.cpp:371]     Train net output #0: loss = 2.85938 (* 1 = 2.85938 loss)
I0228 08:03:55.564436  7886 sgd_solver.cpp:170] Iteration 8000, lr = 0.738466, m = 0.9, wd = 0.0005, gs = 729.37
I0228 08:04:00.495343  7886 solver.cpp:347] Iteration 8100 (20.2801 iter/s, 4.93095s/100 iter), 12.9/90.9ep, loss = 2.98633
I0228 08:04:00.495487  7886 solver.cpp:371]     Train net output #0: loss = 2.98633 (* 1 = 2.98633 loss)
I0228 08:04:00.495502  7886 sgd_solver.cpp:170] Iteration 8100, lr = 0.735448, m = 0.9, wd = 0.0005, gs = 673.53
I0228 08:04:01.758844  7984 data_reader.cpp:178] Shuffling 1281167 records...
I0228 08:04:05.509528  7886 solver.cpp:347] Iteration 8200 (19.9435 iter/s, 5.01416s/100 iter), 13.1/90.9ep, loss = 2.46289
I0228 08:04:05.509635  7886 solver.cpp:371]     Train net output #0: loss = 2.46289 (* 1 = 2.46289 loss)
I0228 08:04:05.509645  7886 sgd_solver.cpp:170] Iteration 8200, lr = 0.732435, m = 0.9, wd = 0.0005, gs = 633.35
I0228 08:04:10.514216  7886 solver.cpp:347] Iteration 8300 (19.9816 iter/s, 5.0046s/100 iter), 13.3/90.9ep, loss = 2.67578
I0228 08:04:10.514346  7886 solver.cpp:371]     Train net output #0: loss = 2.67578 (* 1 = 2.67578 loss)
I0228 08:04:10.514367  7886 sgd_solver.cpp:170] Iteration 8300, lr = 0.729429, m = 0.9, wd = 0.0005, gs = 748.64
I0228 08:04:15.509924  7886 solver.cpp:347] Iteration 8400 (20.0175 iter/s, 4.99563s/100 iter), 13.4/90.9ep, loss = 2.57031
I0228 08:04:15.510098  7886 solver.cpp:371]     Train net output #0: loss = 2.57031 (* 1 = 2.57031 loss)
I0228 08:04:15.510110  7886 sgd_solver.cpp:170] Iteration 8400, lr = 0.726428, m = 0.9, wd = 0.0005, gs = 765.35
I0228 08:04:20.456324  7886 solver.cpp:347] Iteration 8500 (20.217 iter/s, 4.94632s/100 iter), 13.6/90.9ep, loss = 2.78516
I0228 08:04:20.456449  7886 solver.cpp:371]     Train net output #0: loss = 2.78516 (* 1 = 2.78516 loss)
I0228 08:04:20.456459  7886 sgd_solver.cpp:170] Iteration 8500, lr = 0.723434, m = 0.9, wd = 0.0005, gs = 528.09
I0228 08:04:25.410568  7886 solver.cpp:347] Iteration 8600 (20.1851 iter/s, 4.95415s/100 iter), 13.7/90.9ep, loss = 2.91602
I0228 08:04:25.410691  7886 solver.cpp:371]     Train net output #0: loss = 2.91602 (* 1 = 2.91602 loss)
I0228 08:04:25.410735  7886 sgd_solver.cpp:170] Iteration 8600, lr = 0.720447, m = 0.9, wd = 0.0005, gs = 752.68
I0228 08:04:30.389176  7886 solver.cpp:347] Iteration 8700 (20.0863 iter/s, 4.97852s/100 iter), 13.9/90.9ep, loss = 2.79297
I0228 08:04:30.389339  7886 solver.cpp:371]     Train net output #0: loss = 2.79297 (* 1 = 2.79297 loss)
I0228 08:04:30.389412  7886 sgd_solver.cpp:170] Iteration 8700, lr = 0.717465, m = 0.9, wd = 0.0005, gs = 627.16
I0228 08:04:33.025425  7988 data_reader.cpp:178] Shuffling 1281167 records...
I0228 08:04:35.386654  7886 solver.cpp:347] Iteration 8800 (20.0103 iter/s, 4.99743s/100 iter), 14.1/90.9ep, loss = 2.58594
I0228 08:04:35.386787  7886 solver.cpp:371]     Train net output #0: loss = 2.58594 (* 1 = 2.58594 loss)
I0228 08:04:35.386801  7886 sgd_solver.cpp:170] Iteration 8800, lr = 0.714489, m = 0.9, wd = 0.0005, gs = 700.51
I0228 08:04:40.411345  7886 solver.cpp:347] Iteration 8900 (19.9021 iter/s, 5.02459s/100 iter), 14.2/90.9ep, loss = 2.53906
I0228 08:04:40.411486  7886 solver.cpp:371]     Train net output #0: loss = 2.53906 (* 1 = 2.53906 loss)
I0228 08:04:40.411499  7886 sgd_solver.cpp:170] Iteration 8900, lr = 0.71152, m = 0.9, wd = 0.0005, gs = 942.45
I0228 08:04:45.413847  7886 solver.cpp:347] Iteration 9000 (19.9905 iter/s, 5.00238s/100 iter), 14.4/90.9ep, loss = 2.64648
I0228 08:04:45.414017  7886 solver.cpp:371]     Train net output #0: loss = 2.64648 (* 1 = 2.64648 loss)
I0228 08:04:45.414047  7886 sgd_solver.cpp:170] Iteration 9000, lr = 0.708557, m = 0.9, wd = 0.0005, gs = 727.82
I0228 08:04:50.412762  7886 solver.cpp:347] Iteration 9100 (20.0045 iter/s, 4.99887s/100 iter), 14.5/90.9ep, loss = 2.83789
I0228 08:04:50.412952  7886 solver.cpp:371]     Train net output #0: loss = 2.83789 (* 1 = 2.83789 loss)
I0228 08:04:50.412964  7886 sgd_solver.cpp:170] Iteration 9100, lr = 0.7056, m = 0.9, wd = 0.0005, gs = 658.59
I0228 08:04:55.429611  7886 solver.cpp:347] Iteration 9200 (19.9334 iter/s, 5.0167s/100 iter), 14.7/90.9ep, loss = 2.72656
I0228 08:04:55.429720  7886 solver.cpp:371]     Train net output #0: loss = 2.72656 (* 1 = 2.72656 loss)
I0228 08:04:55.429740  7886 sgd_solver.cpp:170] Iteration 9200, lr = 0.702649, m = 0.9, wd = 0.0005, gs = 657.8
I0228 08:05:00.452757  7886 solver.cpp:347] Iteration 9300 (19.908 iter/s, 5.02311s/100 iter), 14.9/90.9ep, loss = 2.71289
I0228 08:05:00.452900  7886 solver.cpp:371]     Train net output #0: loss = 2.71289 (* 1 = 2.71289 loss)
I0228 08:05:00.452913  7886 sgd_solver.cpp:170] Iteration 9300, lr = 0.699705, m = 0.9, wd = 0.0005, gs = 630.39
I0228 08:05:04.310679  7986 data_reader.cpp:178] Shuffling 1281167 records...
I0228 08:05:05.467526  7886 solver.cpp:347] Iteration 9400 (19.9416 iter/s, 5.01465s/100 iter), 15/90.9ep, loss = 2.48242
I0228 08:05:05.467644  7886 solver.cpp:371]     Train net output #0: loss = 2.48242 (* 1 = 2.48242 loss)
I0228 08:05:05.467658  7886 sgd_solver.cpp:170] Iteration 9400, lr = 0.696766, m = 0.9, wd = 0.0005, gs = 605.24
I0228 08:05:10.481338  7886 solver.cpp:347] Iteration 9500 (19.9452 iter/s, 5.01374s/100 iter), 15.2/90.9ep, loss = 2.52734
I0228 08:05:10.481518  7886 solver.cpp:371]     Train net output #0: loss = 2.52734 (* 1 = 2.52734 loss)
I0228 08:05:10.481544  7886 sgd_solver.cpp:170] Iteration 9500, lr = 0.693834, m = 0.9, wd = 0.0005, gs = 603.59
I0228 08:05:15.425791  7886 solver.cpp:347] Iteration 9600 (20.225 iter/s, 4.94437s/100 iter), 15.3/90.9ep, loss = 2.625
I0228 08:05:15.426059  7886 solver.cpp:371]     Train net output #0: loss = 2.625 (* 1 = 2.625 loss)
I0228 08:05:15.426072  7886 sgd_solver.cpp:170] Iteration 9600, lr = 0.690908, m = 0.9, wd = 0.0005, gs = 674.96
I0228 08:05:16.266314  7966 blocking_queue.cpp:40] Data layer prefetch queue empty
I0228 08:05:20.397939  7886 solver.cpp:347] Iteration 9700 (20.1124 iter/s, 4.97205s/100 iter), 15.5/90.9ep, loss = 2.43945
I0228 08:05:20.398082  7886 solver.cpp:371]     Train net output #0: loss = 2.43945 (* 1 = 2.43945 loss)
I0228 08:05:20.398114  7886 sgd_solver.cpp:170] Iteration 9700, lr = 0.687988, m = 0.9, wd = 0.0005, gs = 921.9
I0228 08:05:25.379228  7886 solver.cpp:347] Iteration 9800 (20.0754 iter/s, 4.98122s/100 iter), 15.7/90.9ep, loss = 2.75977
I0228 08:05:25.379354  7886 solver.cpp:371]     Train net output #0: loss = 2.75977 (* 1 = 2.75977 loss)
I0228 08:05:25.379364  7886 sgd_solver.cpp:170] Iteration 9800, lr = 0.685075, m = 0.9, wd = 0.0005, gs = 677.38
I0228 08:05:30.367378  7886 solver.cpp:347] Iteration 9900 (20.048 iter/s, 4.98803s/100 iter), 15.8/90.9ep, loss = 2.80078
I0228 08:05:30.367558  7886 solver.cpp:371]     Train net output #0: loss = 2.80078 (* 1 = 2.80078 loss)
I0228 08:05:30.367571  7886 sgd_solver.cpp:170] Iteration 9900, lr = 0.682167, m = 0.9, wd = 0.0005, gs = 645.22
I0228 08:05:35.330751  7886 solver.cpp:347] Iteration 10000 (20.148 iter/s, 4.96327s/100 iter), 16/90.9ep, loss = 2.66211
I0228 08:05:35.331333  7886 solver.cpp:371]     Train net output #0: loss = 2.66211 (* 1 = 2.66211 loss)
I0228 08:05:35.331348  7886 sgd_solver.cpp:170] Iteration 10000, lr = 0.679266, m = 0.9, wd = 0.0005, gs = 671.21
I0228 08:05:35.582482  7985 data_reader.cpp:178] Shuffling 1281167 records...
I0228 08:05:40.316577  7886 solver.cpp:347] Iteration 10100 (20.0572 iter/s, 4.98575s/100 iter), 16.1/90.9ep, loss = 2.64258
I0228 08:05:40.316761  7886 solver.cpp:371]     Train net output #0: loss = 2.64258 (* 1 = 2.64258 loss)
I0228 08:05:40.316774  7886 sgd_solver.cpp:170] Iteration 10100, lr = 0.676371, m = 0.9, wd = 0.0005, gs = 747.74
I0228 08:05:45.328083  7886 solver.cpp:347] Iteration 10200 (19.9544 iter/s, 5.01144s/100 iter), 16.3/90.9ep, loss = 2.57617
I0228 08:05:45.328223  7886 solver.cpp:371]     Train net output #0: loss = 2.57617 (* 1 = 2.57617 loss)
I0228 08:05:45.328235  7886 sgd_solver.cpp:170] Iteration 10200, lr = 0.673482, m = 0.9, wd = 0.0005, gs = 476.2
I0228 08:05:50.316964  7886 solver.cpp:347] Iteration 10300 (20.0449 iter/s, 4.98879s/100 iter), 16.5/90.9ep, loss = 2.53125
I0228 08:05:50.317078  7886 solver.cpp:371]     Train net output #0: loss = 2.53125 (* 1 = 2.53125 loss)
I0228 08:05:50.317090  7886 sgd_solver.cpp:170] Iteration 10300, lr = 0.670599, m = 0.9, wd = 0.0005, gs = 517.64
I0228 08:05:55.323673  7886 solver.cpp:347] Iteration 10400 (19.9735 iter/s, 5.00663s/100 iter), 16.6/90.9ep, loss = 2.63086
I0228 08:05:55.323851  7886 solver.cpp:371]     Train net output #0: loss = 2.63086 (* 1 = 2.63086 loss)
I0228 08:05:55.323863  7886 sgd_solver.cpp:170] Iteration 10400, lr = 0.667722, m = 0.9, wd = 0.0005, gs = 542.55
I0228 08:06:00.301095  7886 solver.cpp:347] Iteration 10500 (20.091 iter/s, 4.97735s/100 iter), 16.8/90.9ep, loss = 2.69727
I0228 08:06:00.301231  7886 solver.cpp:371]     Train net output #0: loss = 2.69727 (* 1 = 2.69727 loss)
I0228 08:06:00.301244  7886 sgd_solver.cpp:170] Iteration 10500, lr = 0.664852, m = 0.9, wd = 0.0005, gs = 502.64
I0228 08:06:05.278219  7886 solver.cpp:347] Iteration 10600 (20.0922 iter/s, 4.97705s/100 iter), 16.9/90.9ep, loss = 2.62695
I0228 08:06:05.278348  7886 solver.cpp:371]     Train net output #0: loss = 2.62695 (* 1 = 2.62695 loss)
I0228 08:06:05.278360  7886 sgd_solver.cpp:170] Iteration 10600, lr = 0.661988, m = 0.9, wd = 0.0005, gs = 559.84
I0228 08:06:06.726990  7987 data_reader.cpp:178] Shuffling 1281167 records...
I0228 08:06:10.276695  7886 solver.cpp:347] Iteration 10700 (20.0064 iter/s, 4.9984s/100 iter), 17.1/90.9ep, loss = 2.5957
I0228 08:06:10.276809  7886 solver.cpp:371]     Train net output #0: loss = 2.5957 (* 1 = 2.5957 loss)
I0228 08:06:10.276836  7886 sgd_solver.cpp:170] Iteration 10700, lr = 0.65913, m = 0.9, wd = 0.0005, gs = 555.05
I0228 08:06:15.269608  7886 solver.cpp:347] Iteration 10800 (20.029 iter/s, 4.99276s/100 iter), 17.3/90.9ep, loss = 2.18555
I0228 08:06:15.269703  7886 solver.cpp:371]     Train net output #0: loss = 2.18555 (* 1 = 2.18555 loss)
I0228 08:06:15.269716  7886 sgd_solver.cpp:170] Iteration 10800, lr = 0.656278, m = 0.9, wd = 0.0005, gs = 735.6
I0228 08:06:20.259127  7886 solver.cpp:347] Iteration 10900 (20.0422 iter/s, 4.98947s/100 iter), 17.4/90.9ep, loss = 2.68945
I0228 08:06:20.259265  7886 solver.cpp:371]     Train net output #0: loss = 2.68945 (* 1 = 2.68945 loss)
I0228 08:06:20.259277  7886 sgd_solver.cpp:170] Iteration 10900, lr = 0.653432, m = 0.9, wd = 0.0005, gs = 703.76
I0228 08:06:25.261754  7886 solver.cpp:347] Iteration 11000 (19.9899 iter/s, 5.00251s/100 iter), 17.6/90.9ep, loss = 2.45898
I0228 08:06:25.261906  7886 solver.cpp:371]     Train net output #0: loss = 2.45898 (* 1 = 2.45898 loss)
I0228 08:06:25.261919  7886 sgd_solver.cpp:170] Iteration 11000, lr = 0.650593, m = 0.9, wd = 0.0005, gs = 597.48
I0228 08:06:30.243283  7886 solver.cpp:347] Iteration 11100 (20.0744 iter/s, 4.98146s/100 iter), 17.7/90.9ep, loss = 2.52344
I0228 08:06:30.243413  7886 solver.cpp:371]     Train net output #0: loss = 2.52344 (* 1 = 2.52344 loss)
I0228 08:06:30.243435  7886 sgd_solver.cpp:170] Iteration 11100, lr = 0.64776, m = 0.9, wd = 0.0005, gs = 591.27
I0228 08:06:35.236507  7886 solver.cpp:347] Iteration 11200 (20.0274 iter/s, 4.99317s/100 iter), 17.9/90.9ep, loss = 2.50391
I0228 08:06:35.236631  7886 solver.cpp:371]     Train net output #0: loss = 2.50391 (* 1 = 2.50391 loss)
I0228 08:06:35.236640  7886 sgd_solver.cpp:170] Iteration 11200, lr = 0.644933, m = 0.9, wd = 0.0005, gs = 552.01
I0228 08:06:37.909723  7984 data_reader.cpp:178] Shuffling 1281167 records...
I0228 08:06:40.252950  7886 solver.cpp:347] Iteration 11300 (19.9348 iter/s, 5.01637s/100 iter), 18.1/90.9ep, loss = 2.54102
I0228 08:06:40.253079  7886 solver.cpp:371]     Train net output #0: loss = 2.54102 (* 1 = 2.54102 loss)
I0228 08:06:40.253098  7886 sgd_solver.cpp:170] Iteration 11300, lr = 0.642112, m = 0.9, wd = 0.0005, gs = 513.71
I0228 08:06:45.278733  7886 solver.cpp:347] Iteration 11400 (19.8977 iter/s, 5.0257s/100 iter), 18.2/90.9ep, loss = 2.42578
I0228 08:06:45.278861  7886 solver.cpp:371]     Train net output #0: loss = 2.42578 (* 1 = 2.42578 loss)
I0228 08:06:45.278872  7886 sgd_solver.cpp:170] Iteration 11400, lr = 0.639297, m = 0.9, wd = 0.0005, gs = 532.37
I0228 08:06:50.312379  7886 solver.cpp:347] Iteration 11500 (19.8668 iter/s, 5.03352s/100 iter), 18.4/90.9ep, loss = 2.52734
I0228 08:06:50.312608  7886 solver.cpp:371]     Train net output #0: loss = 2.52734 (* 1 = 2.52734 loss)
I0228 08:06:50.312647  7886 sgd_solver.cpp:170] Iteration 11500, lr = 0.636488, m = 0.9, wd = 0.0005, gs = 536.63
I0228 08:06:55.348172  7886 solver.cpp:347] Iteration 11600 (19.858 iter/s, 5.03576s/100 iter), 18.5/90.9ep, loss = 2.66406
I0228 08:06:55.348345  7886 solver.cpp:371]     Train net output #0: loss = 2.66406 (* 1 = 2.66406 loss)
I0228 08:06:55.348356  7886 sgd_solver.cpp:170] Iteration 11600, lr = 0.633686, m = 0.9, wd = 0.0005, gs = 548.77
I0228 08:07:00.368186  7886 solver.cpp:347] Iteration 11700 (19.9208 iter/s, 5.01989s/100 iter), 18.7/90.9ep, loss = 2.43359
I0228 08:07:00.368305  7886 solver.cpp:371]     Train net output #0: loss = 2.43359 (* 1 = 2.43359 loss)
I0228 08:07:00.368331  7886 sgd_solver.cpp:170] Iteration 11700, lr = 0.63089, m = 0.9, wd = 0.0005, gs = 456.69
I0228 08:07:05.336592  7886 solver.cpp:347] Iteration 11800 (20.1277 iter/s, 4.96827s/100 iter), 18.9/90.9ep, loss = 2.80078
I0228 08:07:05.336771  7886 solver.cpp:371]     Train net output #0: loss = 2.80078 (* 1 = 2.80078 loss)
I0228 08:07:05.336784  7886 sgd_solver.cpp:170] Iteration 11800, lr = 0.6281, m = 0.9, wd = 0.0005, gs = 556.69
I0228 08:07:09.322250  7990 data_reader.cpp:178] Shuffling 1281167 records...
I0228 08:07:10.258919  7886 solver.cpp:347] Iteration 11900 (20.3156 iter/s, 4.92233s/100 iter), 19/90.9ep, loss = 2.30859
I0228 08:07:10.259057  7886 solver.cpp:371]     Train net output #0: loss = 2.30859 (* 1 = 2.30859 loss)
I0228 08:07:10.259130  7886 sgd_solver.cpp:170] Iteration 11900, lr = 0.625316, m = 0.9, wd = 0.0005, gs = 662.47
I0228 08:07:15.249505  7886 solver.cpp:347] Iteration 12000 (20.0382 iter/s, 4.99048s/100 iter), 19.2/90.9ep, loss = 2.41602
I0228 08:07:15.249641  7886 solver.cpp:371]     Train net output #0: loss = 2.41602 (* 1 = 2.41602 loss)
I0228 08:07:15.249652  7886 sgd_solver.cpp:170] Iteration 12000, lr = 0.622538, m = 0.9, wd = 0.0005, gs = 688.43
I0228 08:07:20.264466  7886 solver.cpp:347] Iteration 12100 (19.9406 iter/s, 5.01489s/100 iter), 19.3/90.9ep, loss = 2.43359
I0228 08:07:20.264611  7886 solver.cpp:371]     Train net output #0: loss = 2.43359 (* 1 = 2.43359 loss)
I0228 08:07:20.264621  7886 sgd_solver.cpp:170] Iteration 12100, lr = 0.619767, m = 0.9, wd = 0.0005, gs = 427.59
I0228 08:07:25.278692  7886 solver.cpp:347] Iteration 12200 (19.9438 iter/s, 5.0141s/100 iter), 19.5/90.9ep, loss = 2.57031
I0228 08:07:25.278805  7886 solver.cpp:371]     Train net output #0: loss = 2.57031 (* 1 = 2.57031 loss)
I0228 08:07:25.278815  7886 sgd_solver.cpp:170] Iteration 12200, lr = 0.617002, m = 0.9, wd = 0.0005, gs = 499.34
I0228 08:07:30.279111  7886 solver.cpp:347] Iteration 12300 (19.9984 iter/s, 5.00039s/100 iter), 19.7/90.9ep, loss = 2.75977
I0228 08:07:30.279212  7886 solver.cpp:371]     Train net output #0: loss = 2.75977 (* 1 = 2.75977 loss)
I0228 08:07:30.279242  7886 sgd_solver.cpp:170] Iteration 12300, lr = 0.614242, m = 0.9, wd = 0.0005, gs = 610.93
I0228 08:07:35.248543  7886 solver.cpp:347] Iteration 12400 (20.1235 iter/s, 4.96932s/100 iter), 19.8/90.9ep, loss = 2.42773
I0228 08:07:35.248708  7886 solver.cpp:371]     Train net output #0: loss = 2.42773 (* 1 = 2.42773 loss)
I0228 08:07:35.248723  7886 sgd_solver.cpp:170] Iteration 12400, lr = 0.61149, m = 0.9, wd = 0.0005, gs = 746.58
I0228 08:07:40.190279  7886 solver.cpp:347] Iteration 12500 (20.2362 iter/s, 4.94165s/100 iter), 20/90.9ep, loss = 2.71875
I0228 08:07:40.190731  7886 solver.cpp:371]     Train net output #0: loss = 2.71875 (* 1 = 2.71875 loss)
I0228 08:07:40.190752  7886 sgd_solver.cpp:170] Iteration 12500, lr = 0.608743, m = 0.9, wd = 0.0005, gs = 592
I0228 08:07:40.438382  7988 data_reader.cpp:178] Shuffling 1281167 records...
I0228 08:07:45.181568  7886 solver.cpp:347] Iteration 12600 (20.0351 iter/s, 4.99124s/100 iter), 20.1/90.9ep, loss = 2.37305
I0228 08:07:45.181754  7886 solver.cpp:371]     Train net output #0: loss = 2.37305 (* 1 = 2.37305 loss)
I0228 08:07:45.181764  7886 sgd_solver.cpp:170] Iteration 12600, lr = 0.606002, m = 0.9, wd = 0.0005, gs = 420.3
I0228 08:07:50.171156  7886 solver.cpp:347] Iteration 12700 (20.0422 iter/s, 4.98946s/100 iter), 20.3/90.9ep, loss = 2.47656
I0228 08:07:50.171344  7886 solver.cpp:371]     Train net output #0: loss = 2.47656 (* 1 = 2.47656 loss)
I0228 08:07:50.171386  7886 sgd_solver.cpp:170] Iteration 12700, lr = 0.603268, m = 0.9, wd = 0.0005, gs = 471.57
I0228 08:07:55.184082  7886 solver.cpp:347] Iteration 12800 (19.9489 iter/s, 5.01281s/100 iter), 20.5/90.9ep, loss = 2.46094
I0228 08:07:55.184233  7886 solver.cpp:371]     Train net output #0: loss = 2.46094 (* 1 = 2.46094 loss)
I0228 08:07:55.184274  7886 sgd_solver.cpp:170] Iteration 12800, lr = 0.60054, m = 0.9, wd = 0.0005, gs = 457.75
I0228 08:08:00.185257  7886 solver.cpp:347] Iteration 12900 (19.9956 iter/s, 5.00109s/100 iter), 20.6/90.9ep, loss = 2.59766
I0228 08:08:00.185465  7886 solver.cpp:371]     Train net output #0: loss = 2.59766 (* 1 = 2.59766 loss)
I0228 08:08:00.185503  7886 sgd_solver.cpp:170] Iteration 12900, lr = 0.597818, m = 0.9, wd = 0.0005, gs = 555.15
I0228 08:08:05.162539  7886 solver.cpp:347] Iteration 13000 (20.0914 iter/s, 4.97727s/100 iter), 20.8/90.9ep, loss = 2.50781
I0228 08:08:05.162691  7886 solver.cpp:371]     Train net output #0: loss = 2.50781 (* 1 = 2.50781 loss)
I0228 08:08:05.162739  7886 sgd_solver.cpp:170] Iteration 13000, lr = 0.595102, m = 0.9, wd = 0.0005, gs = 578.69
I0228 08:08:07.801877  7983 blocking_queue.cpp:40] Data layer prefetch queue empty
I0228 08:08:10.153301  7886 solver.cpp:347] Iteration 13100 (20.0373 iter/s, 4.99068s/100 iter), 20.9/90.9ep, loss = 2.45312
I0228 08:08:10.153456  7886 solver.cpp:371]     Train net output #0: loss = 2.45312 (* 1 = 2.45312 loss)
I0228 08:08:10.153496  7886 sgd_solver.cpp:170] Iteration 13100, lr = 0.592392, m = 0.9, wd = 0.0005, gs = 443.3
I0228 08:08:11.641273  7985 data_reader.cpp:178] Shuffling 1281167 records...
I0228 08:08:15.146397  7886 solver.cpp:347] Iteration 13200 (20.0281 iter/s, 4.99299s/100 iter), 21.1/90.9ep, loss = 2.63867
I0228 08:08:15.146569  7886 solver.cpp:371]     Train net output #0: loss = 2.63867 (* 1 = 2.63867 loss)
I0228 08:08:15.146598  7886 sgd_solver.cpp:170] Iteration 13200, lr = 0.589689, m = 0.9, wd = 0.0005, gs = 497.31
I0228 08:08:20.188798  7886 solver.cpp:347] Iteration 13300 (19.8325 iter/s, 5.04224s/100 iter), 21.3/90.9ep, loss = 2.18164
I0228 08:08:20.188921  7886 solver.cpp:371]     Train net output #0: loss = 2.18164 (* 1 = 2.18164 loss)
I0228 08:08:20.188933  7886 sgd_solver.cpp:170] Iteration 13300, lr = 0.586992, m = 0.9, wd = 0.0005, gs = 603.32
I0228 08:08:25.182883  7886 solver.cpp:347] Iteration 13400 (20.0239 iter/s, 4.99404s/100 iter), 21.4/90.9ep, loss = 2.2832
I0228 08:08:25.183049  7886 solver.cpp:371]     Train net output #0: loss = 2.2832 (* 1 = 2.2832 loss)
I0228 08:08:25.183073  7886 sgd_solver.cpp:170] Iteration 13400, lr = 0.584301, m = 0.9, wd = 0.0005, gs = 502.98
I0228 08:08:30.162029  7886 solver.cpp:347] Iteration 13500 (20.084 iter/s, 4.97909s/100 iter), 21.6/90.9ep, loss = 2.38281
I0228 08:08:30.162190  7886 solver.cpp:371]     Train net output #0: loss = 2.38281 (* 1 = 2.38281 loss)
I0228 08:08:30.162200  7886 sgd_solver.cpp:170] Iteration 13500, lr = 0.581616, m = 0.9, wd = 0.0005, gs = 494.01
I0228 08:08:35.154525  7886 solver.cpp:347] Iteration 13600 (20.0303 iter/s, 4.99242s/100 iter), 21.7/90.9ep, loss = 2.39844
I0228 08:08:35.154661  7886 solver.cpp:371]     Train net output #0: loss = 2.39844 (* 1 = 2.39844 loss)
I0228 08:08:35.154673  7886 sgd_solver.cpp:170] Iteration 13600, lr = 0.578937, m = 0.9, wd = 0.0005, gs = 558.26
I0228 08:08:40.130656  7886 solver.cpp:347] Iteration 13700 (20.0965 iter/s, 4.976s/100 iter), 21.9/90.9ep, loss = 2.56445
I0228 08:08:40.130796  7886 solver.cpp:371]     Train net output #0: loss = 2.56445 (* 1 = 2.56445 loss)
I0228 08:08:40.130808  7886 sgd_solver.cpp:170] Iteration 13700, lr = 0.576265, m = 0.9, wd = 0.0005, gs = 500.16
I0228 08:08:42.946079  7990 data_reader.cpp:178] Shuffling 1281167 records...
I0228 08:08:45.089938  7886 solver.cpp:347] Iteration 13800 (20.1644 iter/s, 4.95922s/100 iter), 22.1/90.9ep, loss = 2.58789
I0228 08:08:45.090057  7886 solver.cpp:371]     Train net output #0: loss = 2.58789 (* 1 = 2.58789 loss)
I0228 08:08:45.090102  7886 sgd_solver.cpp:170] Iteration 13800, lr = 0.573598, m = 0.9, wd = 0.0005, gs = 438.01
I0228 08:08:50.129328  7886 solver.cpp:347] Iteration 13900 (19.8439 iter/s, 5.03934s/100 iter), 22.2/90.9ep, loss = 2.57617
I0228 08:08:50.129462  7886 solver.cpp:371]     Train net output #0: loss = 2.57617 (* 1 = 2.57617 loss)
I0228 08:08:50.129472  7886 sgd_solver.cpp:170] Iteration 13900, lr = 0.570938, m = 0.9, wd = 0.0005, gs = 445.19
I0228 08:08:55.100389  7886 solver.cpp:347] Iteration 14000 (20.117 iter/s, 4.97092s/100 iter), 22.4/90.9ep, loss = 2.36719
I0228 08:08:55.100550  7886 solver.cpp:371]     Train net output #0: loss = 2.36719 (* 1 = 2.36719 loss)
I0228 08:08:55.100561  7886 sgd_solver.cpp:170] Iteration 14000, lr = 0.568284, m = 0.9, wd = 0.0005, gs = 511.83
I0228 08:09:00.083804  7886 solver.cpp:347] Iteration 14100 (20.0669 iter/s, 4.98333s/100 iter), 22.5/90.9ep, loss = 2.33008
I0228 08:09:00.084013  7886 solver.cpp:371]     Train net output #0: loss = 2.33008 (* 1 = 2.33008 loss)
I0228 08:09:00.084025  7886 sgd_solver.cpp:170] Iteration 14100, lr = 0.565636, m = 0.9, wd = 0.0005, gs = 555.18
I0228 08:09:05.074726  7886 solver.cpp:347] Iteration 14200 (20.0366 iter/s, 4.99087s/100 iter), 22.7/90.9ep, loss = 2.42188
I0228 08:09:05.074875  7886 solver.cpp:371]     Train net output #0: loss = 2.42188 (* 1 = 2.42188 loss)
I0228 08:09:05.074884  7886 sgd_solver.cpp:170] Iteration 14200, lr = 0.562995, m = 0.9, wd = 0.0005, gs = 551.43
I0228 08:09:10.051147  7886 solver.cpp:347] Iteration 14300 (20.0953 iter/s, 4.97628s/100 iter), 22.9/90.9ep, loss = 2.40625
I0228 08:09:10.051308  7886 solver.cpp:371]     Train net output #0: loss = 2.40625 (* 1 = 2.40625 loss)
I0228 08:09:10.051322  7886 sgd_solver.cpp:170] Iteration 14300, lr = 0.560359, m = 0.9, wd = 0.0005, gs = 485.35
I0228 08:09:14.087757  7990 data_reader.cpp:178] Shuffling 1281167 records...
I0228 08:09:15.026064  7886 solver.cpp:347] Iteration 14400 (20.1011 iter/s, 4.97486s/100 iter), 23/90.9ep, loss = 2.44727
I0228 08:09:15.026242  7886 solver.cpp:371]     Train net output #0: loss = 2.44727 (* 1 = 2.44727 loss)
I0228 08:09:15.026252  7886 sgd_solver.cpp:170] Iteration 14400, lr = 0.55773, m = 0.9, wd = 0.0005, gs = 474.12
I0228 08:09:19.991500  7886 solver.cpp:347] Iteration 14500 (20.1395 iter/s, 4.96537s/100 iter), 23.2/90.9ep, loss = 2.47656
I0228 08:09:19.991616  7886 solver.cpp:371]     Train net output #0: loss = 2.47656 (* 1 = 2.47656 loss)
I0228 08:09:19.991626  7886 sgd_solver.cpp:170] Iteration 14500, lr = 0.555107, m = 0.9, wd = 0.0005, gs = 397.24
I0228 08:09:24.982770  7886 solver.cpp:347] Iteration 14600 (20.0353 iter/s, 4.99119s/100 iter), 23.3/90.9ep, loss = 2.58984
I0228 08:09:24.983007  7886 solver.cpp:371]     Train net output #0: loss = 2.58984 (* 1 = 2.58984 loss)
I0228 08:09:24.983021  7886 sgd_solver.cpp:170] Iteration 14600, lr = 0.55249, m = 0.9, wd = 0.0005, gs = 576.49
I0228 08:09:29.988790  7886 solver.cpp:347] Iteration 14700 (19.9766 iter/s, 5.00586s/100 iter), 23.5/90.9ep, loss = 2.52148
I0228 08:09:29.988896  7886 solver.cpp:371]     Train net output #0: loss = 2.52148 (* 1 = 2.52148 loss)
I0228 08:09:29.988907  7886 sgd_solver.cpp:170] Iteration 14700, lr = 0.549879, m = 0.9, wd = 0.0005, gs = 434.71
I0228 08:09:35.013470  7886 solver.cpp:347] Iteration 14800 (19.9021 iter/s, 5.0246s/100 iter), 23.7/90.9ep, loss = 2.48047
I0228 08:09:35.013655  7886 solver.cpp:371]     Train net output #0: loss = 2.48047 (* 1 = 2.48047 loss)
I0228 08:09:35.013669  7886 sgd_solver.cpp:170] Iteration 14800, lr = 0.547275, m = 0.9, wd = 0.0005, gs = 497.71
I0228 08:09:40.004441  7886 solver.cpp:347] Iteration 14900 (20.0366 iter/s, 4.99088s/100 iter), 23.8/90.9ep, loss = 2.42969
I0228 08:09:40.004595  7886 solver.cpp:371]     Train net output #0: loss = 2.42969 (* 1 = 2.42969 loss)
I0228 08:09:40.004604  7886 sgd_solver.cpp:170] Iteration 14900, lr = 0.544676, m = 0.9, wd = 0.0005, gs = 648.76
I0228 08:09:45.019330  7886 solver.cpp:347] Iteration 15000 (19.9409 iter/s, 5.01481s/100 iter), 24/90.9ep, loss = 2.52539
I0228 08:09:45.019815  7886 solver.cpp:371]     Train net output #0: loss = 2.52539 (* 1 = 2.52539 loss)
I0228 08:09:45.019837  7886 sgd_solver.cpp:170] Iteration 15000, lr = 0.542084, m = 0.9, wd = 0.0005, gs = 525.16
I0228 08:09:45.463134  7988 data_reader.cpp:178] Shuffling 1281167 records...
I0228 08:09:50.007508  7886 solver.cpp:347] Iteration 15100 (20.0477 iter/s, 4.98809s/100 iter), 24.1/90.9ep, loss = 2.5293
I0228 08:09:50.007647  7886 solver.cpp:371]     Train net output #0: loss = 2.5293 (* 1 = 2.5293 loss)
I0228 08:09:50.007658  7886 sgd_solver.cpp:170] Iteration 15100, lr = 0.539498, m = 0.9, wd = 0.0005, gs = 581.25
I0228 08:09:55.021797  7886 solver.cpp:347] Iteration 15200 (19.9433 iter/s, 5.01421s/100 iter), 24.3/90.9ep, loss = 2.57227
I0228 08:09:55.022022  7886 solver.cpp:371]     Train net output #0: loss = 2.57227 (* 1 = 2.57227 loss)
I0228 08:09:55.022063  7886 sgd_solver.cpp:170] Iteration 15200, lr = 0.536919, m = 0.9, wd = 0.0005, gs = 582.46
I0228 08:10:00.010344  7886 solver.cpp:347] Iteration 15300 (20.0462 iter/s, 4.98848s/100 iter), 24.5/90.9ep, loss = 2.35938
I0228 08:10:00.010462  7886 solver.cpp:371]     Train net output #0: loss = 2.35938 (* 1 = 2.35938 loss)
I0228 08:10:00.010475  7886 sgd_solver.cpp:170] Iteration 15300, lr = 0.534345, m = 0.9, wd = 0.0005, gs = 453.35
I0228 08:10:05.052119  7886 solver.cpp:347] Iteration 15400 (19.8347 iter/s, 5.04167s/100 iter), 24.6/90.9ep, loss = 2.23828
I0228 08:10:05.052279  7886 solver.cpp:371]     Train net output #0: loss = 2.23828 (* 1 = 2.23828 loss)
I0228 08:10:05.052289  7886 sgd_solver.cpp:170] Iteration 15400, lr = 0.531778, m = 0.9, wd = 0.0005, gs = 454.13
I0228 08:10:10.083053  7886 solver.cpp:347] Iteration 15500 (19.8773 iter/s, 5.03085s/100 iter), 24.8/90.9ep, loss = 2.23047
I0228 08:10:10.083277  7886 solver.cpp:371]     Train net output #0: loss = 2.23047 (* 1 = 2.23047 loss)
I0228 08:10:10.083287  7886 sgd_solver.cpp:170] Iteration 15500, lr = 0.529216, m = 0.9, wd = 0.0005, gs = 430.95
I0228 08:10:15.054231  7886 solver.cpp:347] Iteration 15600 (20.1163 iter/s, 4.97108s/100 iter), 24.9/90.9ep, loss = 2.32031
I0228 08:10:15.054831  7886 solver.cpp:371]     Train net output #0: loss = 2.32031 (* 1 = 2.32031 loss)
I0228 08:10:15.054853  7886 sgd_solver.cpp:170] Iteration 15600, lr = 0.526661, m = 0.9, wd = 0.0005, gs = 553.26
I0228 08:10:16.668738  7990 data_reader.cpp:178] Shuffling 1281167 records...
I0228 08:10:20.028723  7886 solver.cpp:347] Iteration 15700 (20.1028 iter/s, 4.97443s/100 iter), 25.1/90.9ep, loss = 2.11719
I0228 08:10:20.028904  7886 solver.cpp:371]     Train net output #0: loss = 2.11719 (* 1 = 2.11719 loss)
I0228 08:10:20.028916  7886 sgd_solver.cpp:170] Iteration 15700, lr = 0.524112, m = 0.9, wd = 0.0005, gs = 596.98
I0228 08:10:25.058869  7886 solver.cpp:347] Iteration 15800 (19.8804 iter/s, 5.03007s/100 iter), 25.3/90.9ep, loss = 2.17969
I0228 08:10:25.059039  7886 solver.cpp:371]     Train net output #0: loss = 2.17969 (* 1 = 2.17969 loss)
I0228 08:10:25.059064  7886 sgd_solver.cpp:170] Iteration 15800, lr = 0.52157, m = 0.9, wd = 0.0005, gs = 473.64
I0228 08:10:30.068967  7886 solver.cpp:347] Iteration 15900 (19.96 iter/s, 5.01001s/100 iter), 25.4/90.9ep, loss = 2.40039
I0228 08:10:30.069142  7886 solver.cpp:371]     Train net output #0: loss = 2.40039 (* 1 = 2.40039 loss)
I0228 08:10:30.069155  7886 sgd_solver.cpp:170] Iteration 15900, lr = 0.519033, m = 0.9, wd = 0.0005, gs = 471.56
I0228 08:10:35.127835  7886 solver.cpp:347] Iteration 16000 (19.7676 iter/s, 5.05879s/100 iter), 25.6/90.9ep, loss = 2.61133
I0228 08:10:35.127991  7886 solver.cpp:371]     Train net output #0: loss = 2.61133 (* 1 = 2.61133 loss)
I0228 08:10:35.128000  7886 sgd_solver.cpp:170] Iteration 16000, lr = 0.516503, m = 0.9, wd = 0.0005, gs = 500.47
I0228 08:10:40.156075  7886 solver.cpp:347] Iteration 16100 (19.8879 iter/s, 5.02817s/100 iter), 25.7/90.9ep, loss = 2.55273
I0228 08:10:40.156309  7886 solver.cpp:371]     Train net output #0: loss = 2.55273 (* 1 = 2.55273 loss)
I0228 08:10:40.156322  7886 sgd_solver.cpp:170] Iteration 16100, lr = 0.513979, m = 0.9, wd = 0.0005, gs = 390.33
I0228 08:10:45.097440  7886 solver.cpp:347] Iteration 16200 (20.2381 iter/s, 4.94118s/100 iter), 25.9/90.9ep, loss = 2.37891
I0228 08:10:45.097965  7886 solver.cpp:371]     Train net output #0: loss = 2.37891 (* 1 = 2.37891 loss)
I0228 08:10:45.097980  7886 sgd_solver.cpp:170] Iteration 16200, lr = 0.511461, m = 0.9, wd = 0.0005, gs = 527.67
I0228 08:10:47.950522  7990 data_reader.cpp:178] Shuffling 1281167 records...
I0228 08:10:50.047849  7886 solver.cpp:347] Iteration 16300 (20.2004 iter/s, 4.95039s/100 iter), 26.1/90.9ep, loss = 1.97656
I0228 08:10:50.048069  7886 solver.cpp:371]     Train net output #0: loss = 1.97656 (* 1 = 1.97656 loss)
I0228 08:10:50.048121  7886 sgd_solver.cpp:170] Iteration 16300, lr = 0.508949, m = 0.9, wd = 0.0005, gs = 456.88
I0228 08:10:55.032063  7886 solver.cpp:347] Iteration 16400 (20.0636 iter/s, 4.98416s/100 iter), 26.2/90.9ep, loss = 2.28711
I0228 08:10:55.032227  7886 solver.cpp:371]     Train net output #0: loss = 2.28711 (* 1 = 2.28711 loss)
I0228 08:10:55.032238  7886 sgd_solver.cpp:170] Iteration 16400, lr = 0.506443, m = 0.9, wd = 0.0005, gs = 503.41
I0228 08:11:00.061892  7886 solver.cpp:347] Iteration 16500 (19.8818 iter/s, 5.02974s/100 iter), 26.4/90.9ep, loss = 2.56055
I0228 08:11:00.062063  7886 solver.cpp:371]     Train net output #0: loss = 2.56055 (* 1 = 2.56055 loss)
I0228 08:11:00.062093  7886 sgd_solver.cpp:170] Iteration 16500, lr = 0.503944, m = 0.9, wd = 0.0005, gs = 444.14
I0228 08:11:00.106254  7974 blocking_queue.cpp:40] Data layer prefetch queue empty
I0228 08:11:05.068893  7886 solver.cpp:347] Iteration 16600 (19.9724 iter/s, 5.0069s/100 iter), 26.5/90.9ep, loss = 2.23047
I0228 08:11:05.069043  7886 solver.cpp:371]     Train net output #0: loss = 2.23047 (* 1 = 2.23047 loss)
I0228 08:11:05.069057  7886 sgd_solver.cpp:170] Iteration 16600, lr = 0.501451, m = 0.9, wd = 0.0005, gs = 451.99
I0228 08:11:10.065538  7886 solver.cpp:347] Iteration 16700 (20.0137 iter/s, 4.99657s/100 iter), 26.7/90.9ep, loss = 2.54102
I0228 08:11:10.065714  7886 solver.cpp:371]     Train net output #0: loss = 2.54102 (* 1 = 2.54102 loss)
I0228 08:11:10.065726  7886 sgd_solver.cpp:170] Iteration 16700, lr = 0.498964, m = 0.9, wd = 0.0005, gs = 496.94
I0228 08:11:15.058650  7886 solver.cpp:347] Iteration 16800 (20.0279 iter/s, 4.99303s/100 iter), 26.9/90.9ep, loss = 2.63086
I0228 08:11:15.058820  7886 solver.cpp:371]     Train net output #0: loss = 2.63086 (* 1 = 2.63086 loss)
I0228 08:11:15.058832  7886 sgd_solver.cpp:170] Iteration 16800, lr = 0.496483, m = 0.9, wd = 0.0005, gs = 561.27
I0228 08:11:19.287001  7988 data_reader.cpp:178] Shuffling 1281167 records...
I0228 08:11:20.027776  7886 solver.cpp:347] Iteration 16900 (20.1246 iter/s, 4.96904s/100 iter), 27/90.9ep, loss = 2.11328
I0228 08:11:20.027990  7886 solver.cpp:371]     Train net output #0: loss = 2.11328 (* 1 = 2.11328 loss)
I0228 08:11:20.028004  7886 sgd_solver.cpp:170] Iteration 16900, lr = 0.494008, m = 0.9, wd = 0.0005, gs = 553.25
I0228 08:11:25.022169  7886 solver.cpp:347] Iteration 17000 (20.023 iter/s, 4.99425s/100 iter), 27.2/90.9ep, loss = 2.14258
I0228 08:11:25.022295  7886 solver.cpp:371]     Train net output #0: loss = 2.14258 (* 1 = 2.14258 loss)
I0228 08:11:25.022305  7886 sgd_solver.cpp:170] Iteration 17000, lr = 0.49154, m = 0.9, wd = 0.0005, gs = 390.37
I0228 08:11:30.029873  7886 solver.cpp:347] Iteration 17100 (19.9693 iter/s, 5.00768s/100 iter), 27.3/90.9ep, loss = 2.07227
I0228 08:11:30.029984  7886 solver.cpp:371]     Train net output #0: loss = 2.07227 (* 1 = 2.07227 loss)
I0228 08:11:30.030002  7886 sgd_solver.cpp:170] Iteration 17100, lr = 0.489077, m = 0.9, wd = 0.0005, gs = 484.06
I0228 08:11:35.042170  7886 solver.cpp:347] Iteration 17200 (19.9513 iter/s, 5.01222s/100 iter), 27.5/90.9ep, loss = 2.37109
I0228 08:11:35.042361  7886 solver.cpp:371]     Train net output #0: loss = 2.37109 (* 1 = 2.37109 loss)
I0228 08:11:35.042390  7886 sgd_solver.cpp:170] Iteration 17200, lr = 0.486621, m = 0.9, wd = 0.0005, gs = 401.21
I0228 08:11:40.047909  7886 solver.cpp:347] Iteration 17300 (19.9775 iter/s, 5.00563s/100 iter), 27.7/90.9ep, loss = 2.24609
I0228 08:11:40.048087  7886 solver.cpp:371]     Train net output #0: loss = 2.24609 (* 1 = 2.24609 loss)
I0228 08:11:40.048117  7886 sgd_solver.cpp:170] Iteration 17300, lr = 0.484171, m = 0.9, wd = 0.0005, gs = 577.67
I0228 08:11:45.055615  7886 solver.cpp:347] Iteration 17400 (19.9697 iter/s, 5.00759s/100 iter), 27.8/90.9ep, loss = 2.46484
I0228 08:11:45.055725  7886 solver.cpp:371]     Train net output #0: loss = 2.46484 (* 1 = 2.46484 loss)
I0228 08:11:45.055748  7886 sgd_solver.cpp:170] Iteration 17400, lr = 0.481728, m = 0.9, wd = 0.0005, gs = 449.56
I0228 08:11:50.029510  7886 solver.cpp:347] Iteration 17500 (20.1054 iter/s, 4.97378s/100 iter), 28/90.9ep, loss = 2.36719
I0228 08:11:50.029937  7886 solver.cpp:371]     Train net output #0: loss = 2.36719 (* 1 = 2.36719 loss)
I0228 08:11:50.029961  7886 sgd_solver.cpp:170] Iteration 17500, lr = 0.47929, m = 0.9, wd = 0.0005, gs = 443.93
I0228 08:11:50.478792  7988 data_reader.cpp:178] Shuffling 1281167 records...
I0228 08:11:55.029755  7886 solver.cpp:347] Iteration 17600 (19.9992 iter/s, 5.0002s/100 iter), 28.1/90.9ep, loss = 2.29492
I0228 08:11:55.029969  7886 solver.cpp:371]     Train net output #0: loss = 2.29492 (* 1 = 2.29492 loss)
I0228 08:11:55.030006  7886 sgd_solver.cpp:170] Iteration 17600, lr = 0.476859, m = 0.9, wd = 0.0005, gs = 439.15
I0228 08:12:00.001777  7886 solver.cpp:347] Iteration 17700 (20.1131 iter/s, 4.97189s/100 iter), 28.3/90.9ep, loss = 2.42969
I0228 08:12:00.001886  7886 solver.cpp:371]     Train net output #0: loss = 2.42969 (* 1 = 2.42969 loss)
I0228 08:12:00.001895  7886 sgd_solver.cpp:170] Iteration 17700, lr = 0.474433, m = 0.9, wd = 0.0005, gs = 480.21
I0228 08:12:05.008168  7886 solver.cpp:347] Iteration 17800 (19.9747 iter/s, 5.00634s/100 iter), 28.5/90.9ep, loss = 2.29102
I0228 08:12:05.008389  7886 solver.cpp:371]     Train net output #0: loss = 2.29102 (* 1 = 2.29102 loss)
I0228 08:12:05.008416  7886 sgd_solver.cpp:170] Iteration 17800, lr = 0.472014, m = 0.9, wd = 0.0005, gs = 401.78
I0228 08:12:10.001688  7886 solver.cpp:347] Iteration 17900 (20.0262 iter/s, 4.99345s/100 iter), 28.6/90.9ep, loss = 2.26953
I0228 08:12:10.001844  7886 solver.cpp:371]     Train net output #0: loss = 2.26953 (* 1 = 2.26953 loss)
I0228 08:12:10.001853  7886 sgd_solver.cpp:170] Iteration 17900, lr = 0.469601, m = 0.9, wd = 0.0005, gs = 470.04
I0228 08:12:15.013453  7886 solver.cpp:347] Iteration 18000 (19.9533 iter/s, 5.0117s/100 iter), 28.8/90.9ep, loss = 2.33203
I0228 08:12:15.013684  7886 solver.cpp:371]     Train net output #0: loss = 2.33203 (* 1 = 2.33203 loss)
I0228 08:12:15.013696  7886 sgd_solver.cpp:170] Iteration 18000, lr = 0.467195, m = 0.9, wd = 0.0005, gs = 387.97
I0228 08:12:20.004545  7886 solver.cpp:347] Iteration 18100 (20.0361 iter/s, 4.991s/100 iter), 28.9/90.9ep, loss = 2.26953
I0228 08:12:20.004674  7886 solver.cpp:371]     Train net output #0: loss = 2.26953 (* 1 = 2.26953 loss)
I0228 08:12:20.004684  7886 sgd_solver.cpp:170] Iteration 18100, lr = 0.464794, m = 0.9, wd = 0.0005, gs = 503.1
I0228 08:12:21.822834  7986 data_reader.cpp:178] Shuffling 1281167 records...
I0228 08:12:24.990726  7886 solver.cpp:347] Iteration 18200 (20.0557 iter/s, 4.98612s/100 iter), 29.1/90.9ep, loss = 2.20312
I0228 08:12:24.990944  7886 solver.cpp:371]     Train net output #0: loss = 2.20312 (* 1 = 2.20312 loss)
I0228 08:12:24.990967  7886 sgd_solver.cpp:170] Iteration 18200, lr = 0.4624, m = 0.9, wd = 0.0005, gs = 509.12
I0228 08:12:30.001045  7886 solver.cpp:347] Iteration 18300 (19.9592 iter/s, 5.01021s/100 iter), 29.3/90.9ep, loss = 2.20508
I0228 08:12:30.001159  7886 solver.cpp:371]     Train net output #0: loss = 2.20508 (* 1 = 2.20508 loss)
I0228 08:12:30.001173  7886 sgd_solver.cpp:170] Iteration 18300, lr = 0.460012, m = 0.9, wd = 0.0005, gs = 429.61
I0228 08:12:34.963104  7886 solver.cpp:347] Iteration 18400 (20.1535 iter/s, 4.96192s/100 iter), 29.4/90.9ep, loss = 2.33984
I0228 08:12:34.963284  7886 solver.cpp:371]     Train net output #0: loss = 2.33984 (* 1 = 2.33984 loss)
I0228 08:12:34.963300  7886 sgd_solver.cpp:170] Iteration 18400, lr = 0.45763, m = 0.9, wd = 0.0005, gs = 430.09
I0228 08:12:39.979954  7886 solver.cpp:347] Iteration 18500 (19.9331 iter/s, 5.01677s/100 iter), 29.6/90.9ep, loss = 2.48828
I0228 08:12:39.980075  7886 solver.cpp:371]     Train net output #0: loss = 2.48828 (* 1 = 2.48828 loss)
I0228 08:12:39.980084  7886 sgd_solver.cpp:170] Iteration 18500, lr = 0.455254, m = 0.9, wd = 0.0005, gs = 462.2
I0228 08:12:44.965229  7886 solver.cpp:347] Iteration 18600 (20.0592 iter/s, 4.98525s/100 iter), 29.7/90.9ep, loss = 2.42383
I0228 08:12:44.965359  7886 solver.cpp:371]     Train net output #0: loss = 2.42383 (* 1 = 2.42383 loss)
I0228 08:12:44.965373  7886 sgd_solver.cpp:170] Iteration 18600, lr = 0.452885, m = 0.9, wd = 0.0005, gs = 487.9
I0228 08:12:49.960556  7886 solver.cpp:347] Iteration 18700 (20.019 iter/s, 4.99526s/100 iter), 29.9/90.9ep, loss = 2.31641
I0228 08:12:49.960702  7886 solver.cpp:371]     Train net output #0: loss = 2.31641 (* 1 = 2.31641 loss)
I0228 08:12:49.960716  7886 sgd_solver.cpp:170] Iteration 18700, lr = 0.450521, m = 0.9, wd = 0.0005, gs = 480.03
I0228 08:12:52.972242  7984 data_reader.cpp:178] Shuffling 1281167 records...
I0228 08:12:54.924580  7886 solver.cpp:347] Iteration 18800 (20.1454 iter/s, 4.96392s/100 iter), 30.1/90.9ep, loss = 2.0293
I0228 08:12:54.924700  7886 solver.cpp:371]     Train net output #0: loss = 2.0293 (* 1 = 2.0293 loss)
I0228 08:12:54.924712  7886 sgd_solver.cpp:170] Iteration 18800, lr = 0.448164, m = 0.9, wd = 0.0005, gs = 402.94
I0228 08:12:59.915889  7886 solver.cpp:347] Iteration 18900 (20.0351 iter/s, 4.99124s/100 iter), 30.2/90.9ep, loss = 2.35742
I0228 08:12:59.916028  7886 solver.cpp:371]     Train net output #0: loss = 2.35742 (* 1 = 2.35742 loss)
I0228 08:12:59.916039  7886 sgd_solver.cpp:170] Iteration 18900, lr = 0.445813, m = 0.9, wd = 0.0005, gs = 459.67
I0228 08:13:04.911309  7886 solver.cpp:347] Iteration 19000 (20.0188 iter/s, 4.99532s/100 iter), 30.4/90.9ep, loss = 2.30273
I0228 08:13:04.911497  7886 solver.cpp:371]     Train net output #0: loss = 2.30273 (* 1 = 2.30273 loss)
I0228 08:13:04.911517  7886 sgd_solver.cpp:170] Iteration 19000, lr = 0.443468, m = 0.9, wd = 0.0005, gs = 378.55
I0228 08:13:09.907814  7886 solver.cpp:347] Iteration 19100 (20.0145 iter/s, 4.99638s/100 iter), 30.5/90.9ep, loss = 2.30664
I0228 08:13:09.907945  7886 solver.cpp:371]     Train net output #0: loss = 2.30664 (* 1 = 2.30664 loss)
I0228 08:13:09.907958  7886 sgd_solver.cpp:170] Iteration 19100, lr = 0.44113, m = 0.9, wd = 0.0005, gs = 411.79
I0228 08:13:14.921779  7886 solver.cpp:347] Iteration 19200 (19.9446 iter/s, 5.01389s/100 iter), 30.7/90.9ep, loss = 2.28906
I0228 08:13:14.921947  7886 solver.cpp:371]     Train net output #0: loss = 2.28906 (* 1 = 2.28906 loss)
I0228 08:13:14.921959  7886 sgd_solver.cpp:170] Iteration 19200, lr = 0.438797, m = 0.9, wd = 0.0005, gs = 484.57
I0228 08:13:19.895602  7886 solver.cpp:347] Iteration 19300 (20.1056 iter/s, 4.97375s/100 iter), 30.9/90.9ep, loss = 2.26758
I0228 08:13:19.895776  7886 solver.cpp:371]     Train net output #0: loss = 2.26758 (* 1 = 2.26758 loss)
I0228 08:13:19.895787  7886 sgd_solver.cpp:170] Iteration 19300, lr = 0.436471, m = 0.9, wd = 0.0005, gs = 415.87
I0228 08:13:24.133235  7990 data_reader.cpp:178] Shuffling 1281167 records...
I0228 08:13:24.846179  7886 solver.cpp:347] Iteration 19400 (20.2002 iter/s, 4.95045s/100 iter), 31/90.9ep, loss = 2.07422
I0228 08:13:24.846366  7886 solver.cpp:371]     Train net output #0: loss = 2.07422 (* 1 = 2.07422 loss)
I0228 08:13:24.846379  7886 sgd_solver.cpp:170] Iteration 19400, lr = 0.434151, m = 0.9, wd = 0.0005, gs = 451.03
I0228 08:13:29.833143  7886 solver.cpp:347] Iteration 19500 (20.0525 iter/s, 4.9869s/100 iter), 31.2/90.9ep, loss = 2.17773
I0228 08:13:29.833431  7886 solver.cpp:371]     Train net output #0: loss = 2.17773 (* 1 = 2.17773 loss)
I0228 08:13:29.833444  7886 sgd_solver.cpp:170] Iteration 19500, lr = 0.431837, m = 0.9, wd = 0.0005, gs = 553.72
I0228 08:13:34.857487  7886 solver.cpp:347] Iteration 19600 (19.9033 iter/s, 5.0243s/100 iter), 31.3/90.9ep, loss = 2.375
I0228 08:13:34.857678  7886 solver.cpp:371]     Train net output #0: loss = 2.375 (* 1 = 2.375 loss)
I0228 08:13:34.857692  7886 sgd_solver.cpp:170] Iteration 19600, lr = 0.429529, m = 0.9, wd = 0.0005, gs = 471.75
I0228 08:13:39.886554  7886 solver.cpp:347] Iteration 19700 (19.885 iter/s, 5.02893s/100 iter), 31.5/90.9ep, loss = 2.20508
I0228 08:13:39.886718  7886 solver.cpp:371]     Train net output #0: loss = 2.20508 (* 1 = 2.20508 loss)
I0228 08:13:39.886730  7886 sgd_solver.cpp:170] Iteration 19700, lr = 0.427227, m = 0.9, wd = 0.0005, gs = 572.71
I0228 08:13:44.908494  7886 solver.cpp:347] Iteration 19800 (19.9127 iter/s, 5.02191s/100 iter), 31.7/90.9ep, loss = 2.28711
I0228 08:13:44.908660  7886 solver.cpp:371]     Train net output #0: loss = 2.28711 (* 1 = 2.28711 loss)
I0228 08:13:44.908673  7886 sgd_solver.cpp:170] Iteration 19800, lr = 0.424932, m = 0.9, wd = 0.0005, gs = 549.16
I0228 08:13:49.946950  7886 solver.cpp:347] Iteration 19900 (19.8477 iter/s, 5.03838s/100 iter), 31.8/90.9ep, loss = 2.25781
I0228 08:13:49.947080  7886 solver.cpp:371]     Train net output #0: loss = 2.25781 (* 1 = 2.25781 loss)
I0228 08:13:49.947106  7886 sgd_solver.cpp:170] Iteration 19900, lr = 0.422643, m = 0.9, wd = 0.0005, gs = 441.49
I0228 08:13:51.450422  7974 blocking_queue.cpp:40] Data layer prefetch queue empty
I0228 08:13:54.950034  7886 solver.cpp:347] Iteration 20000 (19.988 iter/s, 5.003s/100 iter), 32/90.9ep, loss = 2.23242
I0228 08:13:54.950515  7886 solver.cpp:371]     Train net output #0: loss = 2.23242 (* 1 = 2.23242 loss)
I0228 08:13:54.950538  7886 sgd_solver.cpp:170] Iteration 20000, lr = 0.42036, m = 0.9, wd = 0.0005, gs = 457.44
I0228 08:13:55.602036  7991 data_reader.cpp:178] Shuffling 1281167 records...
I0228 08:13:59.969928  7886 solver.cpp:347] Iteration 20100 (19.9213 iter/s, 5.01976s/100 iter), 32.1/90.9ep, loss = 2.16797
I0228 08:13:59.970072  7886 solver.cpp:371]     Train net output #0: loss = 2.16797 (* 1 = 2.16797 loss)
I0228 08:13:59.970082  7886 sgd_solver.cpp:170] Iteration 20100, lr = 0.418083, m = 0.9, wd = 0.0005, gs = 495.21
I0228 08:14:05.001860  7886 solver.cpp:347] Iteration 20200 (19.8733 iter/s, 5.03187s/100 iter), 32.3/90.9ep, loss = 2.13281
I0228 08:14:05.001966  7886 solver.cpp:371]     Train net output #0: loss = 2.13281 (* 1 = 2.13281 loss)
I0228 08:14:05.002017  7886 sgd_solver.cpp:170] Iteration 20200, lr = 0.415812, m = 0.9, wd = 0.0005, gs = 435.83
I0228 08:14:10.034126  7886 solver.cpp:347] Iteration 20300 (19.872 iter/s, 5.03221s/100 iter), 32.5/90.9ep, loss = 2.08594
I0228 08:14:10.034247  7886 solver.cpp:371]     Train net output #0: loss = 2.08594 (* 1 = 2.08594 loss)
I0228 08:14:10.034274  7886 sgd_solver.cpp:170] Iteration 20300, lr = 0.413548, m = 0.9, wd = 0.0005, gs = 525.5
I0228 08:14:15.037031  7886 solver.cpp:347] Iteration 20400 (19.9888 iter/s, 5.00281s/100 iter), 32.6/90.9ep, loss = 2.35742
I0228 08:14:15.037161  7886 solver.cpp:371]     Train net output #0: loss = 2.35742 (* 1 = 2.35742 loss)
I0228 08:14:15.037171  7886 sgd_solver.cpp:170] Iteration 20400, lr = 0.41129, m = 0.9, wd = 0.0005, gs = 582.48
I0228 08:14:20.032557  7886 solver.cpp:347] Iteration 20500 (20.0185 iter/s, 4.99539s/100 iter), 32.8/90.9ep, loss = 2.10156
I0228 08:14:20.032819  7886 solver.cpp:371]     Train net output #0: loss = 2.10156 (* 1 = 2.10156 loss)
I0228 08:14:20.032830  7886 sgd_solver.cpp:170] Iteration 20500, lr = 0.409038, m = 0.9, wd = 0.0005, gs = 492.29
I0228 08:14:24.972208  7886 solver.cpp:347] Iteration 20600 (20.2449 iter/s, 4.93951s/100 iter), 32.9/90.9ep, loss = 2.4707
I0228 08:14:24.972745  7886 solver.cpp:371]     Train net output #0: loss = 2.4707 (* 1 = 2.4707 loss)
I0228 08:14:24.972769  7886 sgd_solver.cpp:170] Iteration 20600, lr = 0.406792, m = 0.9, wd = 0.0005, gs = 459.83
I0228 08:14:26.818188  7990 data_reader.cpp:178] Shuffling 1281167 records...
I0228 08:14:29.956779  7886 solver.cpp:347] Iteration 20700 (20.0619 iter/s, 4.98458s/100 iter), 33.1/90.9ep, loss = 2.35742
I0228 08:14:29.956940  7886 solver.cpp:371]     Train net output #0: loss = 2.35742 (* 1 = 2.35742 loss)
I0228 08:14:29.956979  7886 sgd_solver.cpp:170] Iteration 20700, lr = 0.404552, m = 0.9, wd = 0.0005, gs = 500.27
I0228 08:14:34.937090  7886 solver.cpp:347] Iteration 20800 (20.0795 iter/s, 4.98019s/100 iter), 33.2/90.9ep, loss = 2.3418
I0228 08:14:34.937273  7886 solver.cpp:371]     Train net output #0: loss = 2.3418 (* 1 = 2.3418 loss)
I0228 08:14:34.937285  7886 sgd_solver.cpp:170] Iteration 20800, lr = 0.402318, m = 0.9, wd = 0.0005, gs = 387.83
I0228 08:14:39.955870  7886 solver.cpp:347] Iteration 20900 (19.9255 iter/s, 5.01869s/100 iter), 33.4/90.9ep, loss = 2.20312
I0228 08:14:39.956027  7886 solver.cpp:371]     Train net output #0: loss = 2.20312 (* 1 = 2.20312 loss)
I0228 08:14:39.956046  7886 sgd_solver.cpp:170] Iteration 20900, lr = 0.400091, m = 0.9, wd = 0.0005, gs = 503.41
I0228 08:14:44.973212  7886 solver.cpp:347] Iteration 21000 (19.931 iter/s, 5.0173s/100 iter), 33.6/90.9ep, loss = 2.37109
I0228 08:14:44.973384  7886 solver.cpp:371]     Train net output #0: loss = 2.37109 (* 1 = 2.37109 loss)
I0228 08:14:44.973397  7886 sgd_solver.cpp:170] Iteration 21000, lr = 0.39787, m = 0.9, wd = 0.0005, gs = 477.9
I0228 08:14:49.972571  7886 solver.cpp:347] Iteration 21100 (20.003 iter/s, 4.99926s/100 iter), 33.7/90.9ep, loss = 2.02734
I0228 08:14:49.972694  7886 solver.cpp:371]     Train net output #0: loss = 2.02734 (* 1 = 2.02734 loss)
I0228 08:14:49.972724  7886 sgd_solver.cpp:170] Iteration 21100, lr = 0.395655, m = 0.9, wd = 0.0005, gs = 486.36
I0228 08:14:54.954723  7886 solver.cpp:347] Iteration 21200 (20.0719 iter/s, 4.98209s/100 iter), 33.9/90.9ep, loss = 2.26562
I0228 08:14:54.954833  7886 solver.cpp:371]     Train net output #0: loss = 2.26562 (* 1 = 2.26562 loss)
I0228 08:14:54.954845  7886 sgd_solver.cpp:170] Iteration 21200, lr = 0.393446, m = 0.9, wd = 0.0005, gs = 413.72
I0228 08:14:58.189405  7984 data_reader.cpp:178] Shuffling 1281167 records...
I0228 08:14:59.933980  7886 solver.cpp:347] Iteration 21300 (20.0839 iter/s, 4.97912s/100 iter), 34/90.9ep, loss = 2.26172
I0228 08:14:59.934165  7886 solver.cpp:371]     Train net output #0: loss = 2.26172 (* 1 = 2.26172 loss)
I0228 08:14:59.934177  7886 sgd_solver.cpp:170] Iteration 21300, lr = 0.391243, m = 0.9, wd = 0.0005, gs = 447.4
I0228 08:15:04.923986  7886 solver.cpp:347] Iteration 21400 (20.0402 iter/s, 4.98997s/100 iter), 34.2/90.9ep, loss = 2.38672
I0228 08:15:04.924110  7886 solver.cpp:371]     Train net output #0: loss = 2.38672 (* 1 = 2.38672 loss)
I0228 08:15:04.924119  7886 sgd_solver.cpp:170] Iteration 21400, lr = 0.389047, m = 0.9, wd = 0.0005, gs = 443.89
I0228 08:15:09.924067  7886 solver.cpp:347] Iteration 21500 (20 iter/s, 4.99999s/100 iter), 34.4/90.9ep, loss = 2.55078
I0228 08:15:09.924190  7886 solver.cpp:371]     Train net output #0: loss = 2.55078 (* 1 = 2.55078 loss)
I0228 08:15:09.924202  7886 sgd_solver.cpp:170] Iteration 21500, lr = 0.386857, m = 0.9, wd = 0.0005, gs = 510.89
I0228 08:15:14.918730  7886 solver.cpp:347] Iteration 21600 (20.0217 iter/s, 4.99459s/100 iter), 34.5/90.9ep, loss = 2.24805
I0228 08:15:14.918916  7886 solver.cpp:371]     Train net output #0: loss = 2.24805 (* 1 = 2.24805 loss)
I0228 08:15:14.918929  7886 sgd_solver.cpp:170] Iteration 21600, lr = 0.384673, m = 0.9, wd = 0.0005, gs = 548.5
I0228 08:15:19.922719  7886 solver.cpp:347] Iteration 21700 (19.9843 iter/s, 5.00393s/100 iter), 34.7/90.9ep, loss = 2.26172
I0228 08:15:19.922859  7886 solver.cpp:371]     Train net output #0: loss = 2.26172 (* 1 = 2.26172 loss)
I0228 08:15:19.922871  7886 sgd_solver.cpp:170] Iteration 21700, lr = 0.382495, m = 0.9, wd = 0.0005, gs = 540.63
I0228 08:15:24.873914  7886 solver.cpp:347] Iteration 21800 (20.1975 iter/s, 4.9511s/100 iter), 34.8/90.9ep, loss = 2.48242
I0228 08:15:24.874096  7886 solver.cpp:371]     Train net output #0: loss = 2.48242 (* 1 = 2.48242 loss)
I0228 08:15:24.874136  7886 sgd_solver.cpp:170] Iteration 21800, lr = 0.380323, m = 0.9, wd = 0.0005, gs = 431.63
I0228 08:15:29.292573  7988 data_reader.cpp:178] Shuffling 1281167 records...
I0228 08:15:29.841591  7886 solver.cpp:347] Iteration 21900 (20.1304 iter/s, 4.96762s/100 iter), 35/90.9ep, loss = 2.16406
I0228 08:15:29.841800  7886 solver.cpp:371]     Train net output #0: loss = 2.16406 (* 1 = 2.16406 loss)
I0228 08:15:29.841812  7886 sgd_solver.cpp:170] Iteration 21900, lr = 0.378157, m = 0.9, wd = 0.0005, gs = 444.14
I0228 08:15:34.839684  7886 solver.cpp:347] Iteration 22000 (20.0079 iter/s, 4.99802s/100 iter), 35.2/90.9ep, loss = 2.05859
I0228 08:15:34.839821  7886 solver.cpp:371]     Train net output #0: loss = 2.05859 (* 1 = 2.05859 loss)
I0228 08:15:34.839833  7886 sgd_solver.cpp:170] Iteration 22000, lr = 0.375998, m = 0.9, wd = 0.0005, gs = 378.67
I0228 08:15:39.865193  7886 solver.cpp:347] Iteration 22100 (19.8989 iter/s, 5.02541s/100 iter), 35.3/90.9ep, loss = 2.12305
I0228 08:15:39.865327  7886 solver.cpp:371]     Train net output #0: loss = 2.12305 (* 1 = 2.12305 loss)
I0228 08:15:39.865339  7886 sgd_solver.cpp:170] Iteration 22100, lr = 0.373845, m = 0.9, wd = 0.0005, gs = 459.09
I0228 08:15:44.886689  7886 solver.cpp:347] Iteration 22200 (19.9149 iter/s, 5.02137s/100 iter), 35.5/90.9ep, loss = 2.2793
I0228 08:15:44.886791  7886 solver.cpp:371]     Train net output #0: loss = 2.2793 (* 1 = 2.2793 loss)
I0228 08:15:44.886804  7886 sgd_solver.cpp:170] Iteration 22200, lr = 0.371698, m = 0.9, wd = 0.0005, gs = 399.88
I0228 08:15:49.866300  7886 solver.cpp:347] Iteration 22300 (20.0823 iter/s, 4.97952s/100 iter), 35.6/90.9ep, loss = 2.36328
I0228 08:15:49.866463  7886 solver.cpp:371]     Train net output #0: loss = 2.36328 (* 1 = 2.36328 loss)
I0228 08:15:49.866494  7886 sgd_solver.cpp:170] Iteration 22300, lr = 0.369557, m = 0.9, wd = 0.0005, gs = 379.74
I0228 08:15:54.840486  7886 solver.cpp:347] Iteration 22400 (20.104 iter/s, 4.97415s/100 iter), 35.8/90.9ep, loss = 2.49414
I0228 08:15:54.840646  7886 solver.cpp:371]     Train net output #0: loss = 2.49414 (* 1 = 2.49414 loss)
I0228 08:15:54.840658  7886 sgd_solver.cpp:170] Iteration 22400, lr = 0.367422, m = 0.9, wd = 0.0005, gs = 419.5
I0228 08:15:59.839768  7886 solver.cpp:347] Iteration 22500 (20.0032 iter/s, 4.99921s/100 iter), 36/90.9ep, loss = 2.23633
I0228 08:15:59.840752  7886 solver.cpp:371]     Train net output #0: loss = 2.23633 (* 1 = 2.23633 loss)
I0228 08:15:59.840766  7886 sgd_solver.cpp:170] Iteration 22500, lr = 0.365294, m = 0.9, wd = 0.0005, gs = 398.19
I0228 08:16:00.525547  7989 data_reader.cpp:178] Shuffling 1281167 records...
I0228 08:16:04.876904  7886 solver.cpp:347] Iteration 22600 (19.8532 iter/s, 5.03698s/100 iter), 36.1/90.9ep, loss = 2.06641
I0228 08:16:04.877032  7886 solver.cpp:371]     Train net output #0: loss = 2.06641 (* 1 = 2.06641 loss)
I0228 08:16:04.877045  7886 sgd_solver.cpp:170] Iteration 22600, lr = 0.363172, m = 0.9, wd = 0.0005, gs = 491.84
I0228 08:16:09.851361  7886 solver.cpp:347] Iteration 22700 (20.103 iter/s, 4.97438s/100 iter), 36.3/90.9ep, loss = 2.30859
I0228 08:16:09.851613  7886 solver.cpp:371]     Train net output #0: loss = 2.30859 (* 1 = 2.30859 loss)
I0228 08:16:09.851627  7886 sgd_solver.cpp:170] Iteration 22700, lr = 0.361056, m = 0.9, wd = 0.0005, gs = 413.61
I0228 08:16:14.808464  7886 solver.cpp:347] Iteration 22800 (20.1733 iter/s, 4.95704s/100 iter), 36.4/90.9ep, loss = 2.20898
I0228 08:16:14.808578  7886 solver.cpp:371]     Train net output #0: loss = 2.20898 (* 1 = 2.20898 loss)
I0228 08:16:14.808590  7886 sgd_solver.cpp:170] Iteration 22800, lr = 0.358946, m = 0.9, wd = 0.0005, gs = 410.69
I0228 08:16:19.821154  7886 solver.cpp:347] Iteration 22900 (19.9496 iter/s, 5.01263s/100 iter), 36.6/90.9ep, loss = 2.27344
I0228 08:16:19.821347  7886 solver.cpp:371]     Train net output #0: loss = 2.27344 (* 1 = 2.27344 loss)
I0228 08:16:19.821383  7886 sgd_solver.cpp:170] Iteration 22900, lr = 0.356842, m = 0.9, wd = 0.0005, gs = 560.8
I0228 08:16:24.825323  7886 solver.cpp:347] Iteration 23000 (19.9838 iter/s, 5.00406s/100 iter), 36.8/90.9ep, loss = 2.06445
I0228 08:16:24.825511  7886 solver.cpp:371]     Train net output #0: loss = 2.06445 (* 1 = 2.06445 loss)
I0228 08:16:24.825541  7886 sgd_solver.cpp:170] Iteration 23000, lr = 0.354745, m = 0.9, wd = 0.0005, gs = 466.54
I0228 08:16:29.813591  7886 solver.cpp:347] Iteration 23100 (20.0473 iter/s, 4.9882s/100 iter), 36.9/90.9ep, loss = 2.24609
I0228 08:16:29.813804  7886 solver.cpp:371]     Train net output #0: loss = 2.24609 (* 1 = 2.24609 loss)
I0228 08:16:29.813815  7886 sgd_solver.cpp:170] Iteration 23100, lr = 0.352653, m = 0.9, wd = 0.0005, gs = 653.97
I0228 08:16:31.851227  7987 data_reader.cpp:178] Shuffling 1281167 records...
I0228 08:16:34.813236  7886 solver.cpp:347] Iteration 23200 (20.002 iter/s, 4.9995s/100 iter), 37.1/90.9ep, loss = 2.19727
I0228 08:16:34.813361  7886 solver.cpp:371]     Train net output #0: loss = 2.19727 (* 1 = 2.19727 loss)
I0228 08:16:34.813380  7886 sgd_solver.cpp:170] Iteration 23200, lr = 0.350568, m = 0.9, wd = 0.0005, gs = 514.61
I0228 08:16:39.826019  7886 solver.cpp:347] Iteration 23300 (19.9492 iter/s, 5.01274s/100 iter), 37.2/90.9ep, loss = 2.04297
I0228 08:16:39.826144  7886 solver.cpp:371]     Train net output #0: loss = 2.04297 (* 1 = 2.04297 loss)
I0228 08:16:39.826159  7886 sgd_solver.cpp:170] Iteration 23300, lr = 0.348489, m = 0.9, wd = 0.0005, gs = 412.28
I0228 08:16:43.888687  7983 blocking_queue.cpp:40] Data layer prefetch queue empty
I0228 08:16:44.841496  7886 solver.cpp:347] Iteration 23400 (19.9387 iter/s, 5.01537s/100 iter), 37.4/90.9ep, loss = 2.14648
I0228 08:16:44.841696  7886 solver.cpp:371]     Train net output #0: loss = 2.14648 (* 1 = 2.14648 loss)
I0228 08:16:44.841784  7886 sgd_solver.cpp:170] Iteration 23400, lr = 0.346416, m = 0.9, wd = 0.0005, gs = 423.05
I0228 08:16:49.861227  7886 solver.cpp:347] Iteration 23500 (19.922 iter/s, 5.01957s/100 iter), 37.6/90.9ep, loss = 2.31055
I0228 08:16:49.861312  7886 solver.cpp:371]     Train net output #0: loss = 2.31055 (* 1 = 2.31055 loss)
I0228 08:16:49.861331  7886 sgd_solver.cpp:170] Iteration 23500, lr = 0.34435, m = 0.9, wd = 0.0005, gs = 451.16
I0228 08:16:54.895414  7886 solver.cpp:347] Iteration 23600 (19.8644 iter/s, 5.03414s/100 iter), 37.7/90.9ep, loss = 2.10156
I0228 08:16:54.895679  7886 solver.cpp:371]     Train net output #0: loss = 2.10156 (* 1 = 2.10156 loss)
I0228 08:16:54.895702  7886 sgd_solver.cpp:170] Iteration 23600, lr = 0.342289, m = 0.9, wd = 0.0005, gs = 437.13
I0228 08:16:59.891185  7886 solver.cpp:347] Iteration 23700 (20.0172 iter/s, 4.99571s/100 iter), 37.9/90.9ep, loss = 2.19531
I0228 08:16:59.891386  7886 solver.cpp:371]     Train net output #0: loss = 2.19531 (* 1 = 2.19531 loss)
I0228 08:16:59.891398  7886 sgd_solver.cpp:170] Iteration 23700, lr = 0.340235, m = 0.9, wd = 0.0005, gs = 362.29
I0228 08:17:03.103278  7985 data_reader.cpp:178] Shuffling 1281167 records...
I0228 08:17:04.846987  7886 solver.cpp:347] Iteration 23800 (20.1787 iter/s, 4.95571s/100 iter), 38/90.9ep, loss = 2.03906
I0228 08:17:04.847106  7886 solver.cpp:371]     Train net output #0: loss = 2.03906 (* 1 = 2.03906 loss)
I0228 08:17:04.847115  7886 sgd_solver.cpp:170] Iteration 23800, lr = 0.338187, m = 0.9, wd = 0.0005, gs = 432.94
I0228 08:17:09.841656  7886 solver.cpp:347] Iteration 23900 (20.0217 iter/s, 4.99457s/100 iter), 38.2/90.9ep, loss = 2.21875
I0228 08:17:09.841797  7886 solver.cpp:371]     Train net output #0: loss = 2.21875 (* 1 = 2.21875 loss)
I0228 08:17:09.841807  7886 sgd_solver.cpp:170] Iteration 23900, lr = 0.336145, m = 0.9, wd = 0.0005, gs = 469.77
I0228 08:17:14.866394  7886 solver.cpp:347] Iteration 24000 (19.9019 iter/s, 5.02465s/100 iter), 38.4/90.9ep, loss = 2.4082
I0228 08:17:14.866549  7886 solver.cpp:371]     Train net output #0: loss = 2.4082 (* 1 = 2.4082 loss)
I0228 08:17:14.866578  7886 sgd_solver.cpp:170] Iteration 24000, lr = 0.334109, m = 0.9, wd = 0.0005, gs = 489.37
I0228 08:17:19.874835  7886 solver.cpp:347] Iteration 24100 (19.9665 iter/s, 5.00839s/100 iter), 38.5/90.9ep, loss = 2.26562
I0228 08:17:19.874994  7886 solver.cpp:371]     Train net output #0: loss = 2.26562 (* 1 = 2.26562 loss)
I0228 08:17:19.875005  7886 sgd_solver.cpp:170] Iteration 24100, lr = 0.33208, m = 0.9, wd = 0.0005, gs = 436.77
I0228 08:17:24.823071  7886 solver.cpp:347] Iteration 24200 (20.2095 iter/s, 4.94816s/100 iter), 38.7/90.9ep, loss = 2.03711
I0228 08:17:24.823199  7886 solver.cpp:371]     Train net output #0: loss = 2.03711 (* 1 = 2.03711 loss)
I0228 08:17:24.823211  7886 sgd_solver.cpp:170] Iteration 24200, lr = 0.330057, m = 0.9, wd = 0.0005, gs = 371.68
I0228 08:17:29.812357  7886 solver.cpp:347] Iteration 24300 (20.0433 iter/s, 4.98919s/100 iter), 38.8/90.9ep, loss = 2.23438
I0228 08:17:29.812563  7886 solver.cpp:371]     Train net output #0: loss = 2.23438 (* 1 = 2.23438 loss)
I0228 08:17:29.812575  7886 sgd_solver.cpp:170] Iteration 24300, lr = 0.328039, m = 0.9, wd = 0.0005, gs = 437.46
I0228 08:17:34.429860  7991 data_reader.cpp:178] Shuffling 1281167 records...
I0228 08:17:34.780019  7886 solver.cpp:347] Iteration 24400 (20.1307 iter/s, 4.96754s/100 iter), 39/90.9ep, loss = 1.95117
I0228 08:17:34.780128  7886 solver.cpp:371]     Train net output #0: loss = 1.95117 (* 1 = 1.95117 loss)
I0228 08:17:34.780139  7886 sgd_solver.cpp:170] Iteration 24400, lr = 0.326028, m = 0.9, wd = 0.0005, gs = 438
I0228 08:17:39.803371  7886 solver.cpp:347] Iteration 24500 (19.9073 iter/s, 5.02328s/100 iter), 39.2/90.9ep, loss = 2.02539
I0228 08:17:39.803561  7886 solver.cpp:371]     Train net output #0: loss = 2.02539 (* 1 = 2.02539 loss)
I0228 08:17:39.803578  7886 sgd_solver.cpp:170] Iteration 24500, lr = 0.324024, m = 0.9, wd = 0.0005, gs = 478.07
I0228 08:17:44.830509  7886 solver.cpp:347] Iteration 24600 (19.8926 iter/s, 5.027s/100 iter), 39.3/90.9ep, loss = 2.01562
I0228 08:17:44.830633  7886 solver.cpp:371]     Train net output #0: loss = 2.01562 (* 1 = 2.01562 loss)
I0228 08:17:44.830657  7886 sgd_solver.cpp:170] Iteration 24600, lr = 0.322025, m = 0.9, wd = 0.0005, gs = 517.29
I0228 08:17:49.866469  7886 solver.cpp:347] Iteration 24700 (19.8574 iter/s, 5.03591s/100 iter), 39.5/90.9ep, loss = 1.99414
I0228 08:17:49.866623  7886 solver.cpp:371]     Train net output #0: loss = 1.99414 (* 1 = 1.99414 loss)
I0228 08:17:49.866636  7886 sgd_solver.cpp:170] Iteration 24700, lr = 0.320033, m = 0.9, wd = 0.0005, gs = 443.69
I0228 08:17:54.848973  7886 solver.cpp:347] Iteration 24800 (20.0706 iter/s, 4.98242s/100 iter), 39.6/90.9ep, loss = 2.07812
I0228 08:17:54.849126  7886 solver.cpp:371]     Train net output #0: loss = 2.07812 (* 1 = 2.07812 loss)
I0228 08:17:54.849143  7886 sgd_solver.cpp:170] Iteration 24800, lr = 0.318046, m = 0.9, wd = 0.0005, gs = 472.8
I0228 08:17:59.812626  7886 solver.cpp:347] Iteration 24900 (20.1471 iter/s, 4.9635s/100 iter), 39.8/90.9ep, loss = 2.45703
I0228 08:17:59.812834  7886 solver.cpp:371]     Train net output #0: loss = 2.45703 (* 1 = 2.45703 loss)
I0228 08:17:59.812844  7886 sgd_solver.cpp:170] Iteration 24900, lr = 0.316066, m = 0.9, wd = 0.0005, gs = 539.99
I0228 08:18:04.764837  7886 solver.cpp:347] Iteration 25000 (20.1934 iter/s, 4.95211s/100 iter), 40/90.9ep, loss = 2.29883
I0228 08:18:04.765349  7886 solver.cpp:371]     Train net output #0: loss = 2.29883 (* 1 = 2.29883 loss)
I0228 08:18:04.765372  7886 sgd_solver.cpp:170] Iteration 25000, lr = 0.314093, m = 0.9, wd = 0.0005, gs = 463.39
I0228 08:18:05.601786  7989 data_reader.cpp:178] Shuffling 1281167 records...
I0228 08:18:09.737988  7886 solver.cpp:347] Iteration 25100 (20.1081 iter/s, 4.97312s/100 iter), 40.1/90.9ep, loss = 2.02344
I0228 08:18:09.738154  7886 solver.cpp:371]     Train net output #0: loss = 2.02344 (* 1 = 2.02344 loss)
I0228 08:18:09.738164  7886 sgd_solver.cpp:170] Iteration 25100, lr = 0.312125, m = 0.9, wd = 0.0005, gs = 441.81
I0228 08:18:14.730793  7886 solver.cpp:347] Iteration 25200 (20.0292 iter/s, 4.99272s/100 iter), 40.3/90.9ep, loss = 2.23828
I0228 08:18:14.730967  7886 solver.cpp:371]     Train net output #0: loss = 2.23828 (* 1 = 2.23828 loss)
I0228 08:18:14.730979  7886 sgd_solver.cpp:170] Iteration 25200, lr = 0.310163, m = 0.9, wd = 0.0005, gs = 405.55
I0228 08:18:19.733220  7886 solver.cpp:347] Iteration 25300 (19.9907 iter/s, 5.00232s/100 iter), 40.4/90.9ep, loss = 2.17383
I0228 08:18:19.733345  7886 solver.cpp:371]     Train net output #0: loss = 2.17383 (* 1 = 2.17383 loss)
I0228 08:18:19.733355  7886 sgd_solver.cpp:170] Iteration 25300, lr = 0.308208, m = 0.9, wd = 0.0005, gs = 394.73
I0228 08:18:24.702344  7886 solver.cpp:347] Iteration 25400 (20.1245 iter/s, 4.96906s/100 iter), 40.6/90.9ep, loss = 2.39453
I0228 08:18:24.702461  7886 solver.cpp:371]     Train net output #0: loss = 2.39453 (* 1 = 2.39453 loss)
I0228 08:18:24.702471  7886 sgd_solver.cpp:170] Iteration 25400, lr = 0.306259, m = 0.9, wd = 0.0005, gs = 440.68
I0228 08:18:29.669955  7886 solver.cpp:347] Iteration 25500 (20.1311 iter/s, 4.96745s/100 iter), 40.8/90.9ep, loss = 2.4668
I0228 08:18:29.670095  7886 solver.cpp:371]     Train net output #0: loss = 2.4668 (* 1 = 2.4668 loss)
I0228 08:18:29.670107  7886 sgd_solver.cpp:170] Iteration 25500, lr = 0.304316, m = 0.9, wd = 0.0005, gs = 419.17
I0228 08:18:34.624001  7886 solver.cpp:347] Iteration 25600 (20.1856 iter/s, 4.95403s/100 iter), 40.9/90.9ep, loss = 2.39453
I0228 08:18:34.624125  7886 solver.cpp:371]     Train net output #0: loss = 2.39453 (* 1 = 2.39453 loss)
I0228 08:18:34.624151  7886 sgd_solver.cpp:170] Iteration 25600, lr = 0.302379, m = 0.9, wd = 0.0005, gs = 396.58
I0228 08:18:36.678156  7991 data_reader.cpp:178] Shuffling 1281167 records...
I0228 08:18:39.619009  7886 solver.cpp:347] Iteration 25700 (20.0203 iter/s, 4.99492s/100 iter), 41.1/90.9ep, loss = 1.94434
I0228 08:18:39.619161  7886 solver.cpp:371]     Train net output #0: loss = 1.94434 (* 1 = 1.94434 loss)
I0228 08:18:39.619185  7886 sgd_solver.cpp:170] Iteration 25700, lr = 0.300449, m = 0.9, wd = 0.0005, gs = 602.31
I0228 08:18:44.606377  7886 solver.cpp:347] Iteration 25800 (20.051 iter/s, 4.98728s/100 iter), 41.2/90.9ep, loss = 2.33594
I0228 08:18:44.606499  7886 solver.cpp:371]     Train net output #0: loss = 2.33594 (* 1 = 2.33594 loss)
I0228 08:18:44.606526  7886 sgd_solver.cpp:170] Iteration 25800, lr = 0.298524, m = 0.9, wd = 0.0005, gs = 449.49
I0228 08:18:49.583498  7886 solver.cpp:347] Iteration 25900 (20.0924 iter/s, 4.97701s/100 iter), 41.4/90.9ep, loss = 2.22852
I0228 08:18:49.583681  7886 solver.cpp:371]     Train net output #0: loss = 2.22852 (* 1 = 2.22852 loss)
I0228 08:18:49.583693  7886 sgd_solver.cpp:170] Iteration 25900, lr = 0.296606, m = 0.9, wd = 0.0005, gs = 402.1
I0228 08:18:54.614964  7886 solver.cpp:347] Iteration 26000 (19.8753 iter/s, 5.03137s/100 iter), 41.6/90.9ep, loss = 2.1543
I0228 08:18:54.615089  7886 solver.cpp:371]     Train net output #0: loss = 2.1543 (* 1 = 2.1543 loss)
I0228 08:18:54.615101  7886 sgd_solver.cpp:170] Iteration 26000, lr = 0.294694, m = 0.9, wd = 0.0005, gs = 444.24
I0228 08:18:59.632838  7886 solver.cpp:347] Iteration 26100 (19.929 iter/s, 5.0178s/100 iter), 41.7/90.9ep, loss = 2.06836
I0228 08:18:59.632974  7886 solver.cpp:371]     Train net output #0: loss = 2.06836 (* 1 = 2.06836 loss)
I0228 08:18:59.632987  7886 sgd_solver.cpp:170] Iteration 26100, lr = 0.292788, m = 0.9, wd = 0.0005, gs = 377.66
I0228 08:19:04.597666  7886 solver.cpp:347] Iteration 26200 (20.142 iter/s, 4.96475s/100 iter), 41.9/90.9ep, loss = 2.22656
I0228 08:19:04.597841  7886 solver.cpp:371]     Train net output #0: loss = 2.22656 (* 1 = 2.22656 loss)
I0228 08:19:04.597851  7886 sgd_solver.cpp:170] Iteration 26200, lr = 0.290888, m = 0.9, wd = 0.0005, gs = 408.47
I0228 08:19:08.032083  7987 data_reader.cpp:178] Shuffling 1281167 records...
I0228 08:19:09.579059  7886 solver.cpp:347] Iteration 26300 (20.0751 iter/s, 4.98131s/100 iter), 42/90.9ep, loss = 2.08008
I0228 08:19:09.579202  7886 solver.cpp:371]     Train net output #0: loss = 2.08008 (* 1 = 2.08008 loss)
I0228 08:19:09.579211  7886 sgd_solver.cpp:170] Iteration 26300, lr = 0.288995, m = 0.9, wd = 0.0005, gs = 438.11
I0228 08:19:14.592411  7886 solver.cpp:347] Iteration 26400 (19.9473 iter/s, 5.01321s/100 iter), 42.2/90.9ep, loss = 2.1582
I0228 08:19:14.592607  7886 solver.cpp:371]     Train net output #0: loss = 2.1582 (* 1 = 2.1582 loss)
I0228 08:19:14.592638  7886 sgd_solver.cpp:170] Iteration 26400, lr = 0.287108, m = 0.9, wd = 0.0005, gs = 382.47
I0228 08:19:19.618939  7886 solver.cpp:347] Iteration 26500 (19.8945 iter/s, 5.02652s/100 iter), 42.4/90.9ep, loss = 2.06445
I0228 08:19:19.619081  7886 solver.cpp:371]     Train net output #0: loss = 2.06445 (* 1 = 2.06445 loss)
I0228 08:19:19.619091  7886 sgd_solver.cpp:170] Iteration 26500, lr = 0.285226, m = 0.9, wd = 0.0005, gs = 463.04
I0228 08:19:24.656954  7886 solver.cpp:347] Iteration 26600 (19.8494 iter/s, 5.03794s/100 iter), 42.5/90.9ep, loss = 2.19141
I0228 08:19:24.657090  7886 solver.cpp:371]     Train net output #0: loss = 2.19141 (* 1 = 2.19141 loss)
I0228 08:19:24.657115  7886 sgd_solver.cpp:170] Iteration 26600, lr = 0.283351, m = 0.9, wd = 0.0005, gs = 408.86
I0228 08:19:29.652940  7886 solver.cpp:347] Iteration 26700 (20.0166 iter/s, 4.99586s/100 iter), 42.7/90.9ep, loss = 2.22852
I0228 08:19:29.653067  7886 solver.cpp:371]     Train net output #0: loss = 2.22852 (* 1 = 2.22852 loss)
I0228 08:19:29.653080  7886 sgd_solver.cpp:170] Iteration 26700, lr = 0.281483, m = 0.9, wd = 0.0005, gs = 406.98
I0228 08:19:31.297576  7981 blocking_queue.cpp:40] Data layer prefetch queue empty
I0228 08:19:34.666268  7886 solver.cpp:347] Iteration 26800 (19.947 iter/s, 5.0133s/100 iter), 42.8/90.9ep, loss = 2.16992
I0228 08:19:34.666407  7886 solver.cpp:371]     Train net output #0: loss = 2.16992 (* 1 = 2.16992 loss)
I0228 08:19:34.666420  7886 sgd_solver.cpp:170] Iteration 26800, lr = 0.27962, m = 0.9, wd = 0.0005, gs = 397.5
I0228 08:19:39.329735  7990 data_reader.cpp:178] Shuffling 1281167 records...
I0228 08:19:39.683285  7886 solver.cpp:347] Iteration 26900 (19.9327 iter/s, 5.01689s/100 iter), 43/90.9ep, loss = 2.20117
I0228 08:19:39.683490  7886 solver.cpp:371]     Train net output #0: loss = 2.20117 (* 1 = 2.20117 loss)
I0228 08:19:39.683502  7886 sgd_solver.cpp:170] Iteration 26900, lr = 0.277764, m = 0.9, wd = 0.0005, gs = 375.92
I0228 08:19:44.687708  7886 solver.cpp:347] Iteration 27000 (19.9826 iter/s, 5.00436s/100 iter), 43.2/90.9ep, loss = 1.96191
I0228 08:19:44.687835  7886 solver.cpp:371]     Train net output #0: loss = 1.96191 (* 1 = 1.96191 loss)
I0228 08:19:44.687860  7886 sgd_solver.cpp:170] Iteration 27000, lr = 0.275914, m = 0.9, wd = 0.0005, gs = 444.65
I0228 08:19:49.629870  7886 solver.cpp:347] Iteration 27100 (20.2344 iter/s, 4.94209s/100 iter), 43.3/90.9ep, loss = 2.01953
I0228 08:19:49.630020  7886 solver.cpp:371]     Train net output #0: loss = 2.01953 (* 1 = 2.01953 loss)
I0228 08:19:49.630044  7886 sgd_solver.cpp:170] Iteration 27100, lr = 0.274069, m = 0.9, wd = 0.0005, gs = 374.45
I0228 08:19:54.630811  7886 solver.cpp:347] Iteration 27200 (19.9967 iter/s, 5.00083s/100 iter), 43.5/90.9ep, loss = 1.9834
I0228 08:19:54.631129  7886 solver.cpp:371]     Train net output #0: loss = 1.9834 (* 1 = 1.9834 loss)
I0228 08:19:54.631142  7886 sgd_solver.cpp:170] Iteration 27200, lr = 0.272232, m = 0.9, wd = 0.0005, gs = 470.99
I0228 08:19:59.649006  7886 solver.cpp:347] Iteration 27300 (19.9278 iter/s, 5.01811s/100 iter), 43.6/90.9ep, loss = 2.25195
I0228 08:19:59.649129  7886 solver.cpp:371]     Train net output #0: loss = 2.25195 (* 1 = 2.25195 loss)
I0228 08:19:59.649152  7886 sgd_solver.cpp:170] Iteration 27300, lr = 0.2704, m = 0.9, wd = 0.0005, gs = 412.13
I0228 08:20:04.642985  7886 solver.cpp:347] Iteration 27400 (20.0246 iter/s, 4.99387s/100 iter), 43.8/90.9ep, loss = 2.02148
I0228 08:20:04.643276  7886 solver.cpp:371]     Train net output #0: loss = 2.02148 (* 1 = 2.02148 loss)
I0228 08:20:04.643301  7886 sgd_solver.cpp:170] Iteration 27400, lr = 0.268575, m = 0.9, wd = 0.0005, gs = 379.07
I0228 08:20:09.623466  7886 solver.cpp:347] Iteration 27500 (20.0787 iter/s, 4.98041s/100 iter), 44/90.9ep, loss = 2.34766
I0228 08:20:09.623950  7886 solver.cpp:371]     Train net output #0: loss = 2.34766 (* 1 = 2.34766 loss)
I0228 08:20:09.623973  7886 sgd_solver.cpp:170] Iteration 27500, lr = 0.266755, m = 0.9, wd = 0.0005, gs = 413.87
I0228 08:20:10.661149  7985 data_reader.cpp:178] Shuffling 1281167 records...
I0228 08:20:14.599493  7886 solver.cpp:347] Iteration 27600 (20.0969 iter/s, 4.97589s/100 iter), 44.1/90.9ep, loss = 2.31445
I0228 08:20:14.599589  7886 solver.cpp:371]     Train net output #0: loss = 2.31445 (* 1 = 2.31445 loss)
I0228 08:20:14.599599  7886 sgd_solver.cpp:170] Iteration 27600, lr = 0.264942, m = 0.9, wd = 0.0005, gs = 449.53
I0228 08:20:19.590803  7886 solver.cpp:347] Iteration 27700 (20.0351 iter/s, 4.99124s/100 iter), 44.3/90.9ep, loss = 2.29492
I0228 08:20:19.590932  7886 solver.cpp:371]     Train net output #0: loss = 2.29492 (* 1 = 2.29492 loss)
I0228 08:20:19.590945  7886 sgd_solver.cpp:170] Iteration 27700, lr = 0.263135, m = 0.9, wd = 0.0005, gs = 458.57
I0228 08:20:24.617022  7886 solver.cpp:347] Iteration 27800 (19.8959 iter/s, 5.02616s/100 iter), 44.4/90.9ep, loss = 2.17773
I0228 08:20:24.617158  7886 solver.cpp:371]     Train net output #0: loss = 2.17773 (* 1 = 2.17773 loss)
I0228 08:20:24.617169  7886 sgd_solver.cpp:170] Iteration 27800, lr = 0.261334, m = 0.9, wd = 0.0005, gs = 417.9
I0228 08:20:29.621745  7886 solver.cpp:347] Iteration 27900 (19.9813 iter/s, 5.00467s/100 iter), 44.6/90.9ep, loss = 1.89551
I0228 08:20:29.621924  7886 solver.cpp:371]     Train net output #0: loss = 1.89551 (* 1 = 1.89551 loss)
I0228 08:20:29.621937  7886 sgd_solver.cpp:170] Iteration 27900, lr = 0.25954, m = 0.9, wd = 0.0005, gs = 439.78
I0228 08:20:34.616242  7886 solver.cpp:347] Iteration 28000 (20.0224 iter/s, 4.99442s/100 iter), 44.8/90.9ep, loss = 2.26367
I0228 08:20:34.616377  7886 solver.cpp:371]     Train net output #0: loss = 2.26367 (* 1 = 2.26367 loss)
I0228 08:20:34.616389  7886 sgd_solver.cpp:170] Iteration 28000, lr = 0.257751, m = 0.9, wd = 0.0005, gs = 382.71
I0228 08:20:39.597064  7886 solver.cpp:347] Iteration 28100 (20.0773 iter/s, 4.98075s/100 iter), 44.9/90.9ep, loss = 2.19531
I0228 08:20:39.597195  7886 solver.cpp:371]     Train net output #0: loss = 2.19531 (* 1 = 2.19531 loss)
I0228 08:20:39.597266  7886 sgd_solver.cpp:170] Iteration 28100, lr = 0.255969, m = 0.9, wd = 0.0005, gs = 384.13
I0228 08:20:41.832243  7987 data_reader.cpp:178] Shuffling 1281167 records...
I0228 08:20:44.571718  7886 solver.cpp:347] Iteration 28200 (20.1022 iter/s, 4.97458s/100 iter), 45.1/90.9ep, loss = 1.89355
I0228 08:20:44.571882  7886 solver.cpp:371]     Train net output #0: loss = 1.89355 (* 1 = 1.89355 loss)
I0228 08:20:44.571915  7886 sgd_solver.cpp:170] Iteration 28200, lr = 0.254193, m = 0.9, wd = 0.0005, gs = 400.58
I0228 08:20:49.531164  7886 solver.cpp:347] Iteration 28300 (20.1639 iter/s, 4.95936s/100 iter), 45.2/90.9ep, loss = 2.25586
I0228 08:20:49.531363  7886 solver.cpp:371]     Train net output #0: loss = 2.25586 (* 1 = 2.25586 loss)
I0228 08:20:49.531374  7886 sgd_solver.cpp:170] Iteration 28300, lr = 0.252423, m = 0.9, wd = 0.0005, gs = 419.64
I0228 08:20:54.507933  7886 solver.cpp:347] Iteration 28400 (20.094 iter/s, 4.97662s/100 iter), 45.4/90.9ep, loss = 2.4707
I0228 08:20:54.508078  7886 solver.cpp:371]     Train net output #0: loss = 2.4707 (* 1 = 2.4707 loss)
I0228 08:20:54.508106  7886 sgd_solver.cpp:170] Iteration 28400, lr = 0.25066, m = 0.9, wd = 0.0005, gs = 435.51
I0228 08:20:59.503913  7886 solver.cpp:347] Iteration 28500 (20.0162 iter/s, 4.99595s/100 iter), 45.6/90.9ep, loss = 1.89062
I0228 08:20:59.504040  7886 solver.cpp:371]     Train net output #0: loss = 1.89062 (* 1 = 1.89062 loss)
I0228 08:20:59.504061  7886 sgd_solver.cpp:170] Iteration 28500, lr = 0.248902, m = 0.9, wd = 0.0005, gs = 451.81
I0228 08:21:04.468175  7886 solver.cpp:347] Iteration 28600 (20.1444 iter/s, 4.96415s/100 iter), 45.7/90.9ep, loss = 2.23047
I0228 08:21:04.468327  7886 solver.cpp:371]     Train net output #0: loss = 2.23047 (* 1 = 2.23047 loss)
I0228 08:21:04.468343  7886 sgd_solver.cpp:170] Iteration 28600, lr = 0.247151, m = 0.9, wd = 0.0005, gs = 378.1
I0228 08:21:09.449098  7886 solver.cpp:347] Iteration 28700 (20.0768 iter/s, 4.98086s/100 iter), 45.9/90.9ep, loss = 2.21875
I0228 08:21:09.449223  7886 solver.cpp:371]     Train net output #0: loss = 2.21875 (* 1 = 2.21875 loss)
I0228 08:21:09.449235  7886 sgd_solver.cpp:170] Iteration 28700, lr = 0.245406, m = 0.9, wd = 0.0005, gs = 440.76
I0228 08:21:12.898317  7987 data_reader.cpp:178] Shuffling 1281167 records...
I0228 08:21:14.430481  7886 solver.cpp:347] Iteration 28800 (20.0751 iter/s, 4.9813s/100 iter), 46/90.9ep, loss = 2.10938
I0228 08:21:14.430594  7886 solver.cpp:371]     Train net output #0: loss = 2.10938 (* 1 = 2.10938 loss)
I0228 08:21:14.430635  7886 sgd_solver.cpp:170] Iteration 28800, lr = 0.243667, m = 0.9, wd = 0.0005, gs = 409.67
I0228 08:21:19.442894  7886 solver.cpp:347] Iteration 28900 (19.9509 iter/s, 5.01231s/100 iter), 46.2/90.9ep, loss = 2.13867
I0228 08:21:19.443076  7886 solver.cpp:371]     Train net output #0: loss = 2.13867 (* 1 = 2.13867 loss)
I0228 08:21:19.443102  7886 sgd_solver.cpp:170] Iteration 28900, lr = 0.241934, m = 0.9, wd = 0.0005, gs = 454.42
I0228 08:21:24.468474  7886 solver.cpp:347] Iteration 29000 (19.8986 iter/s, 5.02548s/100 iter), 46.4/90.9ep, loss = 2.11328
I0228 08:21:24.468602  7886 solver.cpp:371]     Train net output #0: loss = 2.11328 (* 1 = 2.11328 loss)
I0228 08:21:24.468631  7886 sgd_solver.cpp:170] Iteration 29000, lr = 0.240208, m = 0.9, wd = 0.0005, gs = 389.37
I0228 08:21:29.491061  7886 solver.cpp:347] Iteration 29100 (19.9105 iter/s, 5.02247s/100 iter), 46.5/90.9ep, loss = 2.15625
I0228 08:21:29.491178  7886 solver.cpp:371]     Train net output #0: loss = 2.15625 (* 1 = 2.15625 loss)
I0228 08:21:29.491202  7886 sgd_solver.cpp:170] Iteration 29100, lr = 0.238487, m = 0.9, wd = 0.0005, gs = 428.15
I0228 08:21:34.542191  7886 solver.cpp:347] Iteration 29200 (19.7976 iter/s, 5.05112s/100 iter), 46.7/90.9ep, loss = 2.23438
I0228 08:21:34.542304  7886 solver.cpp:371]     Train net output #0: loss = 2.23438 (* 1 = 2.23438 loss)
I0228 08:21:34.542315  7886 sgd_solver.cpp:170] Iteration 29200, lr = 0.236773, m = 0.9, wd = 0.0005, gs = 412.72
I0228 08:21:39.465734  7886 solver.cpp:347] Iteration 29300 (20.311 iter/s, 4.92343s/100 iter), 46.8/90.9ep, loss = 1.87695
I0228 08:21:39.466032  7886 solver.cpp:371]     Train net output #0: loss = 1.87695 (* 1 = 1.87695 loss)
I0228 08:21:39.466063  7886 sgd_solver.cpp:170] Iteration 29300, lr = 0.235065, m = 0.9, wd = 0.0005, gs = 399.71
I0228 08:21:44.275151  7988 data_reader.cpp:178] Shuffling 1281167 records...
I0228 08:21:44.425236  7886 solver.cpp:347] Iteration 29400 (20.1635 iter/s, 4.95945s/100 iter), 47/90.9ep, loss = 2.04297
I0228 08:21:44.425390  7886 solver.cpp:371]     Train net output #0: loss = 2.04297 (* 1 = 2.04297 loss)
I0228 08:21:44.425401  7886 sgd_solver.cpp:170] Iteration 29400, lr = 0.233363, m = 0.9, wd = 0.0005, gs = 418.2
I0228 08:21:49.393797  7886 solver.cpp:347] Iteration 29500 (20.1269 iter/s, 4.96848s/100 iter), 47.2/90.9ep, loss = 1.86719
I0228 08:21:49.393949  7886 solver.cpp:371]     Train net output #0: loss = 1.86719 (* 1 = 1.86719 loss)
I0228 08:21:49.393961  7886 sgd_solver.cpp:170] Iteration 29500, lr = 0.231668, m = 0.9, wd = 0.0005, gs = 389.12
I0228 08:21:54.385515  7886 solver.cpp:347] Iteration 29600 (20.0335 iter/s, 4.99163s/100 iter), 47.3/90.9ep, loss = 2.39648
I0228 08:21:54.385641  7886 solver.cpp:371]     Train net output #0: loss = 2.39648 (* 1 = 2.39648 loss)
I0228 08:21:54.385651  7886 sgd_solver.cpp:170] Iteration 29600, lr = 0.229978, m = 0.9, wd = 0.0005, gs = 443.48
I0228 08:21:59.382439  7886 solver.cpp:347] Iteration 29700 (20.0129 iter/s, 4.99679s/100 iter), 47.5/90.9ep, loss = 2.16211
I0228 08:21:59.382591  7886 solver.cpp:371]     Train net output #0: loss = 2.16211 (* 1 = 2.16211 loss)
I0228 08:21:59.382602  7886 sgd_solver.cpp:170] Iteration 29700, lr = 0.228295, m = 0.9, wd = 0.0005, gs = 365.61
I0228 08:22:04.377430  7886 solver.cpp:347] Iteration 29800 (20.0203 iter/s, 4.99493s/100 iter), 47.6/90.9ep, loss = 2.04297
I0228 08:22:04.377629  7886 solver.cpp:371]     Train net output #0: loss = 2.04297 (* 1 = 2.04297 loss)
I0228 08:22:04.377653  7886 sgd_solver.cpp:170] Iteration 29800, lr = 0.226618, m = 0.9, wd = 0.0005, gs = 385.31
I0228 08:22:09.358444  7886 solver.cpp:347] Iteration 29900 (20.0765 iter/s, 4.98096s/100 iter), 47.8/90.9ep, loss = 2.27344
I0228 08:22:09.358577  7886 solver.cpp:371]     Train net output #0: loss = 2.27344 (* 1 = 2.27344 loss)
I0228 08:22:09.358587  7886 sgd_solver.cpp:170] Iteration 29900, lr = 0.224947, m = 0.9, wd = 0.0005, gs = 448.03
I0228 08:22:14.352550  7886 solver.cpp:347] Iteration 30000 (20.0242 iter/s, 4.99396s/100 iter), 48/90.9ep, loss = 2.29297
I0228 08:22:14.352977  7886 solver.cpp:371]     Train net output #0: loss = 2.29297 (* 1 = 2.29297 loss)
I0228 08:22:14.352991  7886 sgd_solver.cpp:170] Iteration 30000, lr = 0.223282, m = 0.9, wd = 0.0005, gs = 389.95
I0228 08:22:15.399577  7988 data_reader.cpp:178] Shuffling 1281167 records...
I0228 08:22:19.341454  7886 solver.cpp:347] Iteration 30100 (20.0448 iter/s, 4.98882s/100 iter), 48.1/90.9ep, loss = 2.09961
I0228 08:22:19.341574  7886 solver.cpp:371]     Train net output #0: loss = 2.09961 (* 1 = 2.09961 loss)
I0228 08:22:19.341600  7886 sgd_solver.cpp:170] Iteration 30100, lr = 0.221624, m = 0.9, wd = 0.0005, gs = 414.09
I0228 08:22:21.404399  7982 blocking_queue.cpp:40] Data layer prefetch queue empty
I0228 08:22:24.368350  7886 solver.cpp:347] Iteration 30200 (19.8933 iter/s, 5.02683s/100 iter), 48.3/90.9ep, loss = 2.17383
I0228 08:22:24.368477  7886 solver.cpp:371]     Train net output #0: loss = 2.17383 (* 1 = 2.17383 loss)
I0228 08:22:24.368506  7886 sgd_solver.cpp:170] Iteration 30200, lr = 0.219971, m = 0.9, wd = 0.0005, gs = 436.58
I0228 08:22:29.407110  7886 solver.cpp:347] Iteration 30300 (19.8465 iter/s, 5.03868s/100 iter), 48.4/90.9ep, loss = 2.16602
I0228 08:22:29.407275  7886 solver.cpp:371]     Train net output #0: loss = 2.16602 (* 1 = 2.16602 loss)
I0228 08:22:29.407285  7886 sgd_solver.cpp:170] Iteration 30300, lr = 0.218325, m = 0.9, wd = 0.0005, gs = 437.73
I0228 08:22:34.413905  7886 solver.cpp:347] Iteration 30400 (19.9734 iter/s, 5.00667s/100 iter), 48.6/90.9ep, loss = 2.41602
I0228 08:22:34.414108  7886 solver.cpp:371]     Train net output #0: loss = 2.41602 (* 1 = 2.41602 loss)
I0228 08:22:34.414131  7886 sgd_solver.cpp:170] Iteration 30400, lr = 0.216685, m = 0.9, wd = 0.0005, gs = 405.66
I0228 08:22:39.391880  7886 solver.cpp:347] Iteration 30500 (20.0889 iter/s, 4.97787s/100 iter), 48.8/90.9ep, loss = 2.24414
I0228 08:22:39.392045  7886 solver.cpp:371]     Train net output #0: loss = 2.24414 (* 1 = 2.24414 loss)
I0228 08:22:39.392087  7886 sgd_solver.cpp:170] Iteration 30500, lr = 0.215051, m = 0.9, wd = 0.0005, gs = 477.9
I0228 08:22:44.372197  7886 solver.cpp:347] Iteration 30600 (20.0792 iter/s, 4.98027s/100 iter), 48.9/90.9ep, loss = 2.08984
I0228 08:22:44.372788  7886 solver.cpp:371]     Train net output #0: loss = 2.08984 (* 1 = 2.08984 loss)
I0228 08:22:44.372812  7886 sgd_solver.cpp:170] Iteration 30600, lr = 0.213424, m = 0.9, wd = 0.0005, gs = 390.5
I0228 08:22:46.658526  7988 data_reader.cpp:178] Shuffling 1281167 records...
I0228 08:22:49.356120  7886 solver.cpp:347] Iteration 30700 (20.0648 iter/s, 4.98385s/100 iter), 49.1/90.9ep, loss = 2.18359
I0228 08:22:49.356223  7886 solver.cpp:371]     Train net output #0: loss = 2.18359 (* 1 = 2.18359 loss)
I0228 08:22:49.356233  7886 sgd_solver.cpp:170] Iteration 30700, lr = 0.211802, m = 0.9, wd = 0.0005, gs = 383.72
I0228 08:22:54.339114  7886 solver.cpp:347] Iteration 30800 (20.0688 iter/s, 4.98287s/100 iter), 49.2/90.9ep, loss = 2.01172
I0228 08:22:54.339263  7886 solver.cpp:371]     Train net output #0: loss = 2.01172 (* 1 = 2.01172 loss)
I0228 08:22:54.339319  7886 sgd_solver.cpp:170] Iteration 30800, lr = 0.210187, m = 0.9, wd = 0.0005, gs = 403.01
I0228 08:22:59.373126  7886 solver.cpp:347] Iteration 30900 (19.8652 iter/s, 5.03392s/100 iter), 49.4/90.9ep, loss = 2.11328
I0228 08:22:59.373258  7886 solver.cpp:371]     Train net output #0: loss = 2.11328 (* 1 = 2.11328 loss)
I0228 08:22:59.373270  7886 sgd_solver.cpp:170] Iteration 30900, lr = 0.208578, m = 0.9, wd = 0.0005, gs = 434.91
I0228 08:23:04.383126  7886 solver.cpp:347] Iteration 31000 (19.9604 iter/s, 5.00993s/100 iter), 49.6/90.9ep, loss = 2.03125
I0228 08:23:04.383252  7886 solver.cpp:371]     Train net output #0: loss = 2.03125 (* 1 = 2.03125 loss)
I0228 08:23:04.383263  7886 sgd_solver.cpp:170] Iteration 31000, lr = 0.206975, m = 0.9, wd = 0.0005, gs = 407.44
I0228 08:23:09.404395  7886 solver.cpp:347] Iteration 31100 (19.9156 iter/s, 5.02119s/100 iter), 49.7/90.9ep, loss = 2.08398
I0228 08:23:09.404507  7886 solver.cpp:371]     Train net output #0: loss = 2.08398 (* 1 = 2.08398 loss)
I0228 08:23:09.404517  7886 sgd_solver.cpp:170] Iteration 31100, lr = 0.205378, m = 0.9, wd = 0.0005, gs = 348.57
I0228 08:23:14.394080  7886 solver.cpp:347] Iteration 31200 (20.042 iter/s, 4.98952s/100 iter), 49.9/90.9ep, loss = 2.10547
I0228 08:23:14.394587  7886 solver.cpp:371]     Train net output #0: loss = 2.10547 (* 1 = 2.10547 loss)
I0228 08:23:14.394609  7886 sgd_solver.cpp:170] Iteration 31200, lr = 0.203788, m = 0.9, wd = 0.0005, gs = 359.34
I0228 08:23:18.006860  7985 data_reader.cpp:178] Shuffling 1281167 records...
I0228 08:23:19.365135  7886 solver.cpp:347] Iteration 31300 (20.1166 iter/s, 4.97102s/100 iter), 50/90.9ep, loss = 2.1582
I0228 08:23:19.365283  7886 solver.cpp:371]     Train net output #0: loss = 2.1582 (* 1 = 2.1582 loss)
I0228 08:23:19.365294  7886 sgd_solver.cpp:170] Iteration 31300, lr = 0.202203, m = 0.9, wd = 0.0005, gs = 391.43
I0228 08:23:24.393841  7886 solver.cpp:347] Iteration 31400 (19.8863 iter/s, 5.02858s/100 iter), 50.2/90.9ep, loss = 2.2168
I0228 08:23:24.393983  7886 solver.cpp:371]     Train net output #0: loss = 2.2168 (* 1 = 2.2168 loss)
I0228 08:23:24.394038  7886 sgd_solver.cpp:170] Iteration 31400, lr = 0.200625, m = 0.9, wd = 0.0005, gs = 397.3
I0228 08:23:29.351219  7886 solver.cpp:347] Iteration 31500 (20.1722 iter/s, 4.95733s/100 iter), 50.4/90.9ep, loss = 2.24219
I0228 08:23:29.351490  7886 solver.cpp:371]     Train net output #0: loss = 2.24219 (* 1 = 2.24219 loss)
I0228 08:23:29.351503  7886 sgd_solver.cpp:170] Iteration 31500, lr = 0.199053, m = 0.9, wd = 0.0005, gs = 374.33
I0228 08:23:34.324856  7886 solver.cpp:347] Iteration 31600 (20.1064 iter/s, 4.97354s/100 iter), 50.5/90.9ep, loss = 2.23438
I0228 08:23:34.325047  7886 solver.cpp:371]     Train net output #0: loss = 2.23438 (* 1 = 2.23438 loss)
I0228 08:23:34.325063  7886 sgd_solver.cpp:170] Iteration 31600, lr = 0.197487, m = 0.9, wd = 0.0005, gs = 392.42
I0228 08:23:39.328891  7886 solver.cpp:347] Iteration 31700 (19.9842 iter/s, 5.00395s/100 iter), 50.7/90.9ep, loss = 2.22461
I0228 08:23:39.329031  7886 solver.cpp:371]     Train net output #0: loss = 2.22461 (* 1 = 2.22461 loss)
I0228 08:23:39.329041  7886 sgd_solver.cpp:170] Iteration 31700, lr = 0.195928, m = 0.9, wd = 0.0005, gs = 423.41
I0228 08:23:44.334584  7886 solver.cpp:347] Iteration 31800 (19.9776 iter/s, 5.00562s/100 iter), 50.8/90.9ep, loss = 2.20508
I0228 08:23:44.334775  7886 solver.cpp:371]     Train net output #0: loss = 2.20508 (* 1 = 2.20508 loss)
I0228 08:23:44.334800  7886 sgd_solver.cpp:170] Iteration 31800, lr = 0.194374, m = 0.9, wd = 0.0005, gs = 404.88
I0228 08:23:49.173892  7988 data_reader.cpp:178] Shuffling 1281167 records...
I0228 08:23:49.322541  7886 solver.cpp:347] Iteration 31900 (20.0489 iter/s, 4.98779s/100 iter), 51/90.9ep, loss = 2.16406
I0228 08:23:49.322680  7886 solver.cpp:371]     Train net output #0: loss = 2.16406 (* 1 = 2.16406 loss)
I0228 08:23:49.322734  7886 sgd_solver.cpp:170] Iteration 31900, lr = 0.192827, m = 0.9, wd = 0.0005, gs = 461.48
I0228 08:23:54.294793  7886 solver.cpp:347] Iteration 32000 (20.1119 iter/s, 4.97218s/100 iter), 51.2/90.9ep, loss = 2.14258
I0228 08:23:54.294915  7886 solver.cpp:371]     Train net output #0: loss = 2.14258 (* 1 = 2.14258 loss)
I0228 08:23:54.294926  7886 sgd_solver.cpp:170] Iteration 32000, lr = 0.191286, m = 0.9, wd = 0.0005, gs = 405.36
I0228 08:23:59.281361  7886 solver.cpp:347] Iteration 32100 (20.0543 iter/s, 4.98646s/100 iter), 51.3/90.9ep, loss = 2.09961
I0228 08:23:59.281497  7886 solver.cpp:371]     Train net output #0: loss = 2.09961 (* 1 = 2.09961 loss)
I0228 08:23:59.281509  7886 sgd_solver.cpp:170] Iteration 32100, lr = 0.189751, m = 0.9, wd = 0.0005, gs = 487.04
I0228 08:24:04.283908  7886 solver.cpp:347] Iteration 32200 (19.9902 iter/s, 5.00244s/100 iter), 51.5/90.9ep, loss = 1.98535
I0228 08:24:04.284045  7886 solver.cpp:371]     Train net output #0: loss = 1.98535 (* 1 = 1.98535 loss)
I0228 08:24:04.284057  7886 sgd_solver.cpp:170] Iteration 32200, lr = 0.188222, m = 0.9, wd = 0.0005, gs = 423.21
I0228 08:24:09.239270  7886 solver.cpp:347] Iteration 32300 (20.1803 iter/s, 4.95533s/100 iter), 51.6/90.9ep, loss = 2.24414
I0228 08:24:09.239477  7886 solver.cpp:371]     Train net output #0: loss = 2.24414 (* 1 = 2.24414 loss)
I0228 08:24:09.239488  7886 sgd_solver.cpp:170] Iteration 32300, lr = 0.1867, m = 0.9, wd = 0.0005, gs = 375.58
I0228 08:24:14.192811  7886 solver.cpp:347] Iteration 32400 (20.1881 iter/s, 4.95341s/100 iter), 51.8/90.9ep, loss = 2.23242
I0228 08:24:14.193012  7886 solver.cpp:371]     Train net output #0: loss = 2.23242 (* 1 = 2.23242 loss)
I0228 08:24:14.193025  7886 sgd_solver.cpp:170] Iteration 32400, lr = 0.185184, m = 0.9, wd = 0.0005, gs = 464.5
I0228 08:24:19.155079  7886 solver.cpp:347] Iteration 32500 (20.1523 iter/s, 4.96221s/100 iter), 52/90.9ep, loss = 1.92285
I0228 08:24:19.155225  7886 solver.cpp:371]     Train net output #0: loss = 1.92285 (* 1 = 1.92285 loss)
I0228 08:24:19.155237  7886 sgd_solver.cpp:170] Iteration 32500, lr = 0.183673, m = 0.9, wd = 0.0005, gs = 449.45
I0228 08:24:20.403560  7990 data_reader.cpp:178] Shuffling 1281167 records...
I0228 08:24:24.140394  7886 solver.cpp:347] Iteration 32600 (20.0591 iter/s, 4.98526s/100 iter), 52.1/90.9ep, loss = 1.96582
I0228 08:24:24.140508  7886 solver.cpp:371]     Train net output #0: loss = 1.96582 (* 1 = 1.96582 loss)
I0228 08:24:24.140565  7886 sgd_solver.cpp:170] Iteration 32600, lr = 0.182169, m = 0.9, wd = 0.0005, gs = 385.88
I0228 08:24:29.133064  7886 solver.cpp:347] Iteration 32700 (20.0297 iter/s, 4.99259s/100 iter), 52.3/90.9ep, loss = 1.86816
I0228 08:24:29.133165  7886 solver.cpp:371]     Train net output #0: loss = 1.86816 (* 1 = 1.86816 loss)
I0228 08:24:29.133194  7886 sgd_solver.cpp:170] Iteration 32700, lr = 0.180672, m = 0.9, wd = 0.0005, gs = 348.03
I0228 08:24:34.154227  7886 solver.cpp:347] Iteration 32800 (19.9161 iter/s, 5.02106s/100 iter), 52.4/90.9ep, loss = 2.30859
I0228 08:24:34.154366  7886 solver.cpp:371]     Train net output #0: loss = 2.30859 (* 1 = 2.30859 loss)
I0228 08:24:34.154400  7886 sgd_solver.cpp:170] Iteration 32800, lr = 0.17918, m = 0.9, wd = 0.0005, gs = 430.13
I0228 08:24:39.179996  7886 solver.cpp:347] Iteration 32900 (19.898 iter/s, 5.02563s/100 iter), 52.6/90.9ep, loss = 1.80859
I0228 08:24:39.180187  7886 solver.cpp:371]     Train net output #0: loss = 1.80859 (* 1 = 1.80859 loss)
I0228 08:24:39.180214  7886 sgd_solver.cpp:170] Iteration 32900, lr = 0.177695, m = 0.9, wd = 0.0005, gs = 377.86
I0228 08:24:44.180807  7886 solver.cpp:347] Iteration 33000 (19.997 iter/s, 5.00075s/100 iter), 52.8/90.9ep, loss = 2.22461
I0228 08:24:44.180961  7886 solver.cpp:371]     Train net output #0: loss = 2.22461 (* 1 = 2.22461 loss)
I0228 08:24:44.180974  7886 sgd_solver.cpp:170] Iteration 33000, lr = 0.176215, m = 0.9, wd = 0.0005, gs = 379.55
I0228 08:24:49.145604  7886 solver.cpp:347] Iteration 33100 (20.1424 iter/s, 4.96466s/100 iter), 52.9/90.9ep, loss = 2.10352
I0228 08:24:49.145757  7886 solver.cpp:371]     Train net output #0: loss = 2.10352 (* 1 = 2.10352 loss)
I0228 08:24:49.145769  7886 sgd_solver.cpp:170] Iteration 33100, lr = 0.174742, m = 0.9, wd = 0.0005, gs = 408.96
I0228 08:24:51.587551  7986 data_reader.cpp:178] Shuffling 1281167 records...
I0228 08:24:54.110502  7886 solver.cpp:347] Iteration 33200 (20.1416 iter/s, 4.96485s/100 iter), 53.1/90.9ep, loss = 2.15234
I0228 08:24:54.110640  7886 solver.cpp:371]     Train net output #0: loss = 2.15234 (* 1 = 2.15234 loss)
I0228 08:24:54.110653  7886 sgd_solver.cpp:170] Iteration 33200, lr = 0.173276, m = 0.9, wd = 0.0005, gs = 416.88
I0228 08:24:59.112112  7886 solver.cpp:347] Iteration 33300 (19.9939 iter/s, 5.00153s/100 iter), 53.2/90.9ep, loss = 2.08594
I0228 08:24:59.112318  7886 solver.cpp:371]     Train net output #0: loss = 2.08594 (* 1 = 2.08594 loss)
I0228 08:24:59.112331  7886 sgd_solver.cpp:170] Iteration 33300, lr = 0.171815, m = 0.9, wd = 0.0005, gs = 412.42
I0228 08:25:04.153214  7886 solver.cpp:347] Iteration 33400 (19.8373 iter/s, 5.04101s/100 iter), 53.4/90.9ep, loss = 2.2207
I0228 08:25:04.153385  7886 solver.cpp:371]     Train net output #0: loss = 2.2207 (* 1 = 2.2207 loss)
I0228 08:25:04.153424  7886 sgd_solver.cpp:170] Iteration 33400, lr = 0.17036, m = 0.9, wd = 0.0005, gs = 371.28
I0228 08:25:09.185106  7886 solver.cpp:347] Iteration 33500 (19.8735 iter/s, 5.03182s/100 iter), 53.6/90.9ep, loss = 2.13086
I0228 08:25:09.185262  7886 solver.cpp:371]     Train net output #0: loss = 2.13086 (* 1 = 2.13086 loss)
I0228 08:25:09.185271  7886 sgd_solver.cpp:170] Iteration 33500, lr = 0.168912, m = 0.9, wd = 0.0005, gs = 562.64
I0228 08:25:11.846295  7966 blocking_queue.cpp:40] Data layer prefetch queue empty
I0228 08:25:14.222137  7886 solver.cpp:347] Iteration 33600 (19.8533 iter/s, 5.03693s/100 iter), 53.7/90.9ep, loss = 2.52344
I0228 08:25:14.222363  7886 solver.cpp:371]     Train net output #0: loss = 2.52344 (* 1 = 2.52344 loss)
I0228 08:25:14.222379  7886 sgd_solver.cpp:170] Iteration 33600, lr = 0.16747, m = 0.9, wd = 0.0005, gs = 394.62
I0228 08:25:19.154320  7886 solver.cpp:347] Iteration 33700 (20.2753 iter/s, 4.93211s/100 iter), 53.9/90.9ep, loss = 2.25977
I0228 08:25:19.154475  7886 solver.cpp:371]     Train net output #0: loss = 2.25977 (* 1 = 2.25977 loss)
I0228 08:25:19.154487  7886 sgd_solver.cpp:170] Iteration 33700, lr = 0.166034, m = 0.9, wd = 0.0005, gs = 362.03
I0228 08:25:22.822944  7990 data_reader.cpp:178] Shuffling 1281167 records...
I0228 08:25:24.114269  7886 solver.cpp:347] Iteration 33800 (20.1621 iter/s, 4.95981s/100 iter), 54/90.9ep, loss = 1.99512
I0228 08:25:24.114403  7886 solver.cpp:371]     Train net output #0: loss = 1.99512 (* 1 = 1.99512 loss)
I0228 08:25:24.114435  7886 sgd_solver.cpp:170] Iteration 33800, lr = 0.164604, m = 0.9, wd = 0.0005, gs = 368.19
I0228 08:25:29.107281  7886 solver.cpp:347] Iteration 33900 (20.0282 iter/s, 4.99295s/100 iter), 54.2/90.9ep, loss = 2.31641
I0228 08:25:29.107411  7886 solver.cpp:371]     Train net output #0: loss = 2.31641 (* 1 = 2.31641 loss)
I0228 08:25:29.107432  7886 sgd_solver.cpp:170] Iteration 33900, lr = 0.163181, m = 0.9, wd = 0.0005, gs = 370.9
I0228 08:25:34.119588  7886 solver.cpp:347] Iteration 34000 (19.9516 iter/s, 5.01212s/100 iter), 54.4/90.9ep, loss = 2.27539
I0228 08:25:34.119709  7886 solver.cpp:371]     Train net output #0: loss = 2.27539 (* 1 = 2.27539 loss)
I0228 08:25:34.119729  7886 sgd_solver.cpp:170] Iteration 34000, lr = 0.161763, m = 0.9, wd = 0.0005, gs = 370.7
I0228 08:25:39.083794  7886 solver.cpp:347] Iteration 34100 (20.1443 iter/s, 4.96419s/100 iter), 54.5/90.9ep, loss = 2.06055
I0228 08:25:39.083904  7886 solver.cpp:371]     Train net output #0: loss = 2.06055 (* 1 = 2.06055 loss)
I0228 08:25:39.083925  7886 sgd_solver.cpp:170] Iteration 34100, lr = 0.160352, m = 0.9, wd = 0.0005, gs = 435.34
I0228 08:25:44.051414  7886 solver.cpp:347] Iteration 34200 (20.1308 iter/s, 4.96752s/100 iter), 54.7/90.9ep, loss = 2.41016
I0228 08:25:44.051545  7886 solver.cpp:371]     Train net output #0: loss = 2.41016 (* 1 = 2.41016 loss)
I0228 08:25:44.051575  7886 sgd_solver.cpp:170] Iteration 34200, lr = 0.158947, m = 0.9, wd = 0.0005, gs = 408.23
I0228 08:25:49.061117  7886 solver.cpp:347] Iteration 34300 (19.9618 iter/s, 5.00957s/100 iter), 54.8/90.9ep, loss = 2.39062
I0228 08:25:49.061200  7886 solver.cpp:371]     Train net output #0: loss = 2.39062 (* 1 = 2.39062 loss)
I0228 08:25:49.061213  7886 sgd_solver.cpp:170] Iteration 34300, lr = 0.157548, m = 0.9, wd = 0.0005, gs = 336.63
I0228 08:25:54.027354  7886 solver.cpp:347] Iteration 34400 (20.1361 iter/s, 4.9662s/100 iter), 55/90.9ep, loss = 2.10352
I0228 08:25:54.027876  7886 solver.cpp:371]     Train net output #0: loss = 2.10352 (* 1 = 2.10352 loss)
I0228 08:25:54.027899  7886 sgd_solver.cpp:170] Iteration 34400, lr = 0.156155, m = 0.9, wd = 0.0005, gs = 351.4
I0228 08:25:54.073729  7990 data_reader.cpp:178] Shuffling 1281167 records...
I0228 08:25:59.000572  7886 solver.cpp:347] Iteration 34500 (20.1081 iter/s, 4.97311s/100 iter), 55.1/90.9ep, loss = 2.05273
I0228 08:25:59.000732  7886 solver.cpp:371]     Train net output #0: loss = 2.05273 (* 1 = 2.05273 loss)
I0228 08:25:59.000771  7886 sgd_solver.cpp:170] Iteration 34500, lr = 0.154769, m = 0.9, wd = 0.0005, gs = 394.15
I0228 08:26:03.998232  7886 solver.cpp:347] Iteration 34600 (20.01 iter/s, 4.99751s/100 iter), 55.3/90.9ep, loss = 2.10547
I0228 08:26:03.998404  7886 solver.cpp:371]     Train net output #0: loss = 2.10547 (* 1 = 2.10547 loss)
I0228 08:26:03.998415  7886 sgd_solver.cpp:170] Iteration 34600, lr = 0.153388, m = 0.9, wd = 0.0005, gs = 447.46
I0228 08:26:09.008404  7886 solver.cpp:347] Iteration 34700 (19.9595 iter/s, 5.01014s/100 iter), 55.5/90.9ep, loss = 1.85742
I0228 08:26:09.008519  7886 solver.cpp:371]     Train net output #0: loss = 1.85742 (* 1 = 1.85742 loss)
I0228 08:26:09.008529  7886 sgd_solver.cpp:170] Iteration 34700, lr = 0.152014, m = 0.9, wd = 0.0005, gs = 388.67
I0228 08:26:14.002732  7886 solver.cpp:347] Iteration 34800 (20.0231 iter/s, 4.99424s/100 iter), 55.6/90.9ep, loss = 2.19922
I0228 08:26:14.002858  7886 solver.cpp:371]     Train net output #0: loss = 2.19922 (* 1 = 2.19922 loss)
I0228 08:26:14.002868  7886 sgd_solver.cpp:170] Iteration 34800, lr = 0.150646, m = 0.9, wd = 0.0005, gs = 383.79
I0228 08:26:19.021797  7886 solver.cpp:347] Iteration 34900 (19.9243 iter/s, 5.019s/100 iter), 55.8/90.9ep, loss = 2.01953
I0228 08:26:19.021965  7886 solver.cpp:371]     Train net output #0: loss = 2.01953 (* 1 = 2.01953 loss)
I0228 08:26:19.022011  7886 sgd_solver.cpp:170] Iteration 34900, lr = 0.149285, m = 0.9, wd = 0.0005, gs = 483.51
I0228 08:26:23.978926  7886 solver.cpp:347] Iteration 35000 (20.1733 iter/s, 4.95706s/100 iter), 55.9/90.9ep, loss = 2.17773
I0228 08:26:23.979028  7886 solver.cpp:371]     Train net output #0: loss = 2.17773 (* 1 = 2.17773 loss)
I0228 08:26:23.979041  7886 sgd_solver.cpp:170] Iteration 35000, lr = 0.147929, m = 0.9, wd = 0.0005, gs = 426.74
I0228 08:26:25.219153  7989 data_reader.cpp:178] Shuffling 1281167 records...
I0228 08:26:28.975901  7886 solver.cpp:347] Iteration 35100 (20.0125 iter/s, 4.99688s/100 iter), 56.1/90.9ep, loss = 2.11133
I0228 08:26:28.976047  7886 solver.cpp:371]     Train net output #0: loss = 2.11133 (* 1 = 2.11133 loss)
I0228 08:26:28.976058  7886 sgd_solver.cpp:170] Iteration 35100, lr = 0.14658, m = 0.9, wd = 0.0005, gs = 386.55
I0228 08:26:33.989336  7886 solver.cpp:347] Iteration 35200 (19.9467 iter/s, 5.01336s/100 iter), 56.3/90.9ep, loss = 2.08398
I0228 08:26:33.989516  7886 solver.cpp:371]     Train net output #0: loss = 2.08398 (* 1 = 2.08398 loss)
I0228 08:26:33.989528  7886 sgd_solver.cpp:170] Iteration 35200, lr = 0.145236, m = 0.9, wd = 0.0005, gs = 478.67
I0228 08:26:39.039665  7886 solver.cpp:347] Iteration 35300 (19.8012 iter/s, 5.0502s/100 iter), 56.4/90.9ep, loss = 2.25391
I0228 08:26:39.039791  7886 solver.cpp:371]     Train net output #0: loss = 2.25391 (* 1 = 2.25391 loss)
I0228 08:26:39.039805  7886 sgd_solver.cpp:170] Iteration 35300, lr = 0.143899, m = 0.9, wd = 0.0005, gs = 366.56
I0228 08:26:44.095576  7886 solver.cpp:347] Iteration 35400 (19.7794 iter/s, 5.05577s/100 iter), 56.6/90.9ep, loss = 2.13086
I0228 08:26:44.095683  7886 solver.cpp:371]     Train net output #0: loss = 2.13086 (* 1 = 2.13086 loss)
I0228 08:26:44.095695  7886 sgd_solver.cpp:170] Iteration 35400, lr = 0.142568, m = 0.9, wd = 0.0005, gs = 389.2
I0228 08:26:49.102434  7886 solver.cpp:347] Iteration 35500 (19.9727 iter/s, 5.00682s/100 iter), 56.7/90.9ep, loss = 2.30273
I0228 08:26:49.102537  7886 solver.cpp:371]     Train net output #0: loss = 2.30273 (* 1 = 2.30273 loss)
I0228 08:26:49.102557  7886 sgd_solver.cpp:170] Iteration 35500, lr = 0.141244, m = 0.9, wd = 0.0005, gs = 357.25
I0228 08:26:54.118043  7886 solver.cpp:347] Iteration 35600 (19.9383 iter/s, 5.01548s/100 iter), 56.9/90.9ep, loss = 2.20312
I0228 08:26:54.118230  7886 solver.cpp:371]     Train net output #0: loss = 2.20312 (* 1 = 2.20312 loss)
I0228 08:26:54.118263  7886 sgd_solver.cpp:170] Iteration 35600, lr = 0.139925, m = 0.9, wd = 0.0005, gs = 514.75
I0228 08:26:56.747262  7984 data_reader.cpp:178] Shuffling 1281167 records...
I0228 08:26:59.101042  7886 solver.cpp:347] Iteration 35700 (20.0684 iter/s, 4.98297s/100 iter), 57.1/90.9ep, loss = 1.96777
I0228 08:26:59.101228  7886 solver.cpp:371]     Train net output #0: loss = 1.96777 (* 1 = 1.96777 loss)
I0228 08:26:59.101248  7886 sgd_solver.cpp:170] Iteration 35700, lr = 0.138613, m = 0.9, wd = 0.0005, gs = 380.88
I0228 08:27:04.087839  7886 solver.cpp:347] Iteration 35800 (20.0533 iter/s, 4.98671s/100 iter), 57.2/90.9ep, loss = 1.96777
I0228 08:27:04.088106  7886 solver.cpp:371]     Train net output #0: loss = 1.96777 (* 1 = 1.96777 loss)
I0228 08:27:04.088145  7886 sgd_solver.cpp:170] Iteration 35800, lr = 0.137307, m = 0.9, wd = 0.0005, gs = 415.07
I0228 08:27:09.062193  7886 solver.cpp:347] Iteration 35900 (20.1038 iter/s, 4.97419s/100 iter), 57.4/90.9ep, loss = 2.10156
I0228 08:27:09.062394  7886 solver.cpp:371]     Train net output #0: loss = 2.10156 (* 1 = 2.10156 loss)
I0228 08:27:09.062410  7886 sgd_solver.cpp:170] Iteration 35900, lr = 0.136007, m = 0.9, wd = 0.0005, gs = 475.46
I0228 08:27:14.075498  7886 solver.cpp:347] Iteration 36000 (19.9469 iter/s, 5.01331s/100 iter), 57.5/90.9ep, loss = 2.11914
I0228 08:27:14.075621  7886 solver.cpp:371]     Train net output #0: loss = 2.11914 (* 1 = 2.11914 loss)
I0228 08:27:14.075637  7886 sgd_solver.cpp:170] Iteration 36000, lr = 0.134713, m = 0.9, wd = 0.0005, gs = 368.84
I0228 08:27:19.057195  7886 solver.cpp:347] Iteration 36100 (20.0738 iter/s, 4.98162s/100 iter), 57.7/90.9ep, loss = 2.08984
I0228 08:27:19.057453  7886 solver.cpp:371]     Train net output #0: loss = 2.08984 (* 1 = 2.08984 loss)
I0228 08:27:19.057484  7886 sgd_solver.cpp:170] Iteration 36100, lr = 0.133426, m = 0.9, wd = 0.0005, gs = 368.03
I0228 08:27:24.039799  7886 solver.cpp:347] Iteration 36200 (20.0701 iter/s, 4.98253s/100 iter), 57.9/90.9ep, loss = 2.20703
I0228 08:27:24.039958  7886 solver.cpp:371]     Train net output #0: loss = 2.20703 (* 1 = 2.20703 loss)
I0228 08:27:24.039983  7886 sgd_solver.cpp:170] Iteration 36200, lr = 0.132144, m = 0.9, wd = 0.0005, gs = 393.8
I0228 08:27:27.877246  7986 data_reader.cpp:178] Shuffling 1281167 records...
I0228 08:27:29.013957  7886 solver.cpp:347] Iteration 36300 (20.1042 iter/s, 4.97408s/100 iter), 58/90.9ep, loss = 2.06055
I0228 08:27:29.014045  7886 solver.cpp:371]     Train net output #0: loss = 2.06055 (* 1 = 2.06055 loss)
I0228 08:27:29.014055  7886 sgd_solver.cpp:170] Iteration 36300, lr = 0.130869, m = 0.9, wd = 0.0005, gs = 442.34
I0228 08:27:33.974372  7886 solver.cpp:347] Iteration 36400 (20.1599 iter/s, 4.96033s/100 iter), 58.2/90.9ep, loss = 2.23242
I0228 08:27:33.974510  7886 solver.cpp:371]     Train net output #0: loss = 2.23242 (* 1 = 2.23242 loss)
I0228 08:27:33.974521  7886 sgd_solver.cpp:170] Iteration 36400, lr = 0.1296, m = 0.9, wd = 0.0005, gs = 425.11
I0228 08:27:38.982972  7886 solver.cpp:347] Iteration 36500 (19.966 iter/s, 5.00851s/100 iter), 58.3/90.9ep, loss = 2.04883
I0228 08:27:38.983161  7886 solver.cpp:371]     Train net output #0: loss = 2.04883 (* 1 = 2.04883 loss)
I0228 08:27:38.983197  7886 sgd_solver.cpp:170] Iteration 36500, lr = 0.128337, m = 0.9, wd = 0.0005, gs = 427.52
I0228 08:27:43.992092  7886 solver.cpp:347] Iteration 36600 (19.9639 iter/s, 5.00904s/100 iter), 58.5/90.9ep, loss = 2.04883
I0228 08:27:43.992259  7886 solver.cpp:371]     Train net output #0: loss = 2.04883 (* 1 = 2.04883 loss)
I0228 08:27:43.992269  7886 sgd_solver.cpp:170] Iteration 36600, lr = 0.127081, m = 0.9, wd = 0.0005, gs = 348.66
I0228 08:27:48.991559  7886 solver.cpp:347] Iteration 36700 (20.0025 iter/s, 4.99937s/100 iter), 58.7/90.9ep, loss = 2.02539
I0228 08:27:48.991674  7886 solver.cpp:371]     Train net output #0: loss = 2.02539 (* 1 = 2.02539 loss)
I0228 08:27:48.991684  7886 sgd_solver.cpp:170] Iteration 36700, lr = 0.12583, m = 0.9, wd = 0.0005, gs = 344.23
I0228 08:27:53.983853  7886 solver.cpp:347] Iteration 36800 (20.0311 iter/s, 4.99223s/100 iter), 58.8/90.9ep, loss = 2.05664
I0228 08:27:53.983938  7886 solver.cpp:371]     Train net output #0: loss = 2.05664 (* 1 = 2.05664 loss)
I0228 08:27:53.983947  7886 sgd_solver.cpp:170] Iteration 36800, lr = 0.124586, m = 0.9, wd = 0.0005, gs = 380.63
I0228 08:27:58.945547  7886 solver.cpp:347] Iteration 36900 (20.1547 iter/s, 4.96161s/100 iter), 59/90.9ep, loss = 2.0293
I0228 08:27:58.946015  7886 solver.cpp:371]     Train net output #0: loss = 2.0293 (* 1 = 2.0293 loss)
I0228 08:27:58.946038  7886 sgd_solver.cpp:170] Iteration 36900, lr = 0.123348, m = 0.9, wd = 0.0005, gs = 393.06
I0228 08:27:59.033823  7988 data_reader.cpp:178] Shuffling 1281167 records...
I0228 08:28:03.922044  7886 solver.cpp:347] Iteration 37000 (20.0949 iter/s, 4.97638s/100 iter), 59.1/90.9ep, loss = 2.15234
I0228 08:28:03.922220  7886 solver.cpp:371]     Train net output #0: loss = 2.15234 (* 1 = 2.15234 loss)
I0228 08:28:03.922232  7886 sgd_solver.cpp:170] Iteration 37000, lr = 0.122116, m = 0.9, wd = 0.0005, gs = 451.15
I0228 08:28:04.975457  7971 blocking_queue.cpp:40] Data layer prefetch queue empty
I0228 08:28:08.926196  7886 solver.cpp:347] Iteration 37100 (19.9838 iter/s, 5.00406s/100 iter), 59.3/90.9ep, loss = 2.36133
I0228 08:28:08.926398  7886 solver.cpp:371]     Train net output #0: loss = 2.36133 (* 1 = 2.36133 loss)
I0228 08:28:08.926435  7886 sgd_solver.cpp:170] Iteration 37100, lr = 0.12089, m = 0.9, wd = 0.0005, gs = 386.89
I0228 08:28:13.953011  7886 solver.cpp:347] Iteration 37200 (19.8935 iter/s, 5.02677s/100 iter), 59.5/90.9ep, loss = 2.00781
I0228 08:28:13.953155  7886 solver.cpp:371]     Train net output #0: loss = 2.00781 (* 1 = 2.00781 loss)
I0228 08:28:13.953177  7886 sgd_solver.cpp:170] Iteration 37200, lr = 0.11967, m = 0.9, wd = 0.0005, gs = 374.04
I0228 08:28:18.987473  7886 solver.cpp:347] Iteration 37300 (19.8637 iter/s, 5.0343s/100 iter), 59.6/90.9ep, loss = 2.10352
I0228 08:28:18.987663  7886 solver.cpp:371]     Train net output #0: loss = 2.10352 (* 1 = 2.10352 loss)
I0228 08:28:18.987675  7886 sgd_solver.cpp:170] Iteration 37300, lr = 0.118457, m = 0.9, wd = 0.0005, gs = 433.07
I0228 08:28:23.993955  7886 solver.cpp:347] Iteration 37400 (19.9743 iter/s, 5.00643s/100 iter), 59.8/90.9ep, loss = 2.08984
I0228 08:28:23.994149  7886 solver.cpp:371]     Train net output #0: loss = 2.08984 (* 1 = 2.08984 loss)
I0228 08:28:23.994160  7886 sgd_solver.cpp:170] Iteration 37400, lr = 0.11725, m = 0.9, wd = 0.0005, gs = 409.65
I0228 08:28:29.000689  7886 solver.cpp:347] Iteration 37500 (19.9734 iter/s, 5.00667s/100 iter), 59.9/90.9ep, loss = 2.2168
I0228 08:28:29.001158  7886 solver.cpp:371]     Train net output #0: loss = 2.2168 (* 1 = 2.2168 loss)
I0228 08:28:29.001180  7886 sgd_solver.cpp:170] Iteration 37500, lr = 0.116049, m = 0.9, wd = 0.0005, gs = 408.91
I0228 08:28:30.427835  7988 data_reader.cpp:178] Shuffling 1281167 records...
I0228 08:28:34.034508  7886 solver.cpp:347] Iteration 37600 (19.8662 iter/s, 5.03368s/100 iter), 60.1/90.9ep, loss = 2.16602
I0228 08:28:34.034677  7886 solver.cpp:371]     Train net output #0: loss = 2.16602 (* 1 = 2.16602 loss)
I0228 08:28:34.034689  7886 sgd_solver.cpp:170] Iteration 37600, lr = 0.114854, m = 0.9, wd = 0.0005, gs = 487.62
I0228 08:28:39.018549  7886 solver.cpp:347] Iteration 37700 (20.0642 iter/s, 4.98399s/100 iter), 60.3/90.9ep, loss = 2.23242
I0228 08:28:39.018667  7886 solver.cpp:371]     Train net output #0: loss = 2.23242 (* 1 = 2.23242 loss)
I0228 08:28:39.018678  7886 sgd_solver.cpp:170] Iteration 37700, lr = 0.113665, m = 0.9, wd = 0.0005, gs = 378.18
I0228 08:28:44.049330  7886 solver.cpp:347] Iteration 37800 (19.8782 iter/s, 5.03064s/100 iter), 60.4/90.9ep, loss = 2.22461
I0228 08:28:44.049477  7886 solver.cpp:371]     Train net output #0: loss = 2.22461 (* 1 = 2.22461 loss)
I0228 08:28:44.049487  7886 sgd_solver.cpp:170] Iteration 37800, lr = 0.112483, m = 0.9, wd = 0.0005, gs = 380.48
I0228 08:28:49.061936  7886 solver.cpp:347] Iteration 37900 (19.9499 iter/s, 5.01256s/100 iter), 60.6/90.9ep, loss = 2.04883
I0228 08:28:49.062126  7886 solver.cpp:371]     Train net output #0: loss = 2.04883 (* 1 = 2.04883 loss)
I0228 08:28:49.062139  7886 sgd_solver.cpp:170] Iteration 37900, lr = 0.111307, m = 0.9, wd = 0.0005, gs = 361.63
I0228 08:28:54.038322  7886 solver.cpp:347] Iteration 38000 (20.0953 iter/s, 4.97629s/100 iter), 60.7/90.9ep, loss = 2.13867
I0228 08:28:54.038588  7886 solver.cpp:371]     Train net output #0: loss = 2.13867 (* 1 = 2.13867 loss)
I0228 08:28:54.038616  7886 sgd_solver.cpp:170] Iteration 38000, lr = 0.110136, m = 0.9, wd = 0.0005, gs = 402.23
I0228 08:28:58.972368  7886 solver.cpp:347] Iteration 38100 (20.2677 iter/s, 4.93395s/100 iter), 60.9/90.9ep, loss = 2.15625
I0228 08:28:58.972554  7886 solver.cpp:371]     Train net output #0: loss = 2.15625 (* 1 = 2.15625 loss)
I0228 08:28:58.972584  7886 sgd_solver.cpp:170] Iteration 38100, lr = 0.108973, m = 0.9, wd = 0.0005, gs = 377.15
I0228 08:29:01.602066  7986 data_reader.cpp:178] Shuffling 1281167 records...
I0228 08:29:03.929821  7886 solver.cpp:347] Iteration 38200 (20.172 iter/s, 4.95736s/100 iter), 61.1/90.9ep, loss = 1.87207
I0228 08:29:03.929981  7886 solver.cpp:371]     Train net output #0: loss = 1.87207 (* 1 = 1.87207 loss)
I0228 08:29:03.929994  7886 sgd_solver.cpp:170] Iteration 38200, lr = 0.107815, m = 0.9, wd = 0.0005, gs = 403.31
I0228 08:29:08.937188  7886 solver.cpp:347] Iteration 38300 (19.9711 iter/s, 5.00724s/100 iter), 61.2/90.9ep, loss = 1.93457
I0228 08:29:08.937306  7886 solver.cpp:371]     Train net output #0: loss = 1.93457 (* 1 = 1.93457 loss)
I0228 08:29:08.937319  7886 sgd_solver.cpp:170] Iteration 38300, lr = 0.106663, m = 0.9, wd = 0.0005, gs = 437.47
I0228 08:29:13.964776  7886 solver.cpp:347] Iteration 38400 (19.8903 iter/s, 5.02757s/100 iter), 61.4/90.9ep, loss = 2.14258
I0228 08:29:13.964876  7886 solver.cpp:371]     Train net output #0: loss = 2.14258 (* 1 = 2.14258 loss)
I0228 08:29:13.964885  7886 sgd_solver.cpp:170] Iteration 38400, lr = 0.105518, m = 0.9, wd = 0.0005, gs = 351.08
I0228 08:29:18.941175  7886 solver.cpp:347] Iteration 38500 (20.0952 iter/s, 4.97632s/100 iter), 61.5/90.9ep, loss = 2.30859
I0228 08:29:18.941325  7886 solver.cpp:371]     Train net output #0: loss = 2.30859 (* 1 = 2.30859 loss)
I0228 08:29:18.941339  7886 sgd_solver.cpp:170] Iteration 38500, lr = 0.104379, m = 0.9, wd = 0.0005, gs = 410.29
I0228 08:29:23.939039  7886 solver.cpp:347] Iteration 38600 (20.009 iter/s, 4.99774s/100 iter), 61.7/90.9ep, loss = 2.29297
I0228 08:29:23.939210  7886 solver.cpp:371]     Train net output #0: loss = 2.29297 (* 1 = 2.29297 loss)
I0228 08:29:23.939220  7886 sgd_solver.cpp:170] Iteration 38600, lr = 0.103246, m = 0.9, wd = 0.0005, gs = 381.34
I0228 08:29:28.952041  7886 solver.cpp:347] Iteration 38700 (19.9484 iter/s, 5.01294s/100 iter), 61.9/90.9ep, loss = 2.24805
I0228 08:29:28.952184  7886 solver.cpp:371]     Train net output #0: loss = 2.24805 (* 1 = 2.24805 loss)
I0228 08:29:28.952210  7886 sgd_solver.cpp:170] Iteration 38700, lr = 0.102119, m = 0.9, wd = 0.0005, gs = 391.28
I0228 08:29:32.984745  7984 data_reader.cpp:178] Shuffling 1281167 records...
I0228 08:29:33.934442  7886 solver.cpp:347] Iteration 38800 (20.071 iter/s, 4.9823s/100 iter), 62/90.9ep, loss = 2.15234
I0228 08:29:33.934584  7886 solver.cpp:371]     Train net output #0: loss = 2.15234 (* 1 = 2.15234 loss)
I0228 08:29:33.934594  7886 sgd_solver.cpp:170] Iteration 38800, lr = 0.100998, m = 0.9, wd = 0.0005, gs = 409.6
I0228 08:29:38.919904  7886 solver.cpp:347] Iteration 38900 (20.0587 iter/s, 4.98538s/100 iter), 62.2/90.9ep, loss = 1.84766
I0228 08:29:38.920069  7886 solver.cpp:371]     Train net output #0: loss = 1.84766 (* 1 = 1.84766 loss)
I0228 08:29:38.920083  7886 sgd_solver.cpp:170] Iteration 38900, lr = 0.0998838, m = 0.9, wd = 0.0005, gs = 388.2
I0228 08:29:43.943336  7886 solver.cpp:347] Iteration 39000 (19.907 iter/s, 5.02335s/100 iter), 62.3/90.9ep, loss = 2.25586
I0228 08:29:43.943498  7886 solver.cpp:371]     Train net output #0: loss = 2.25586 (* 1 = 2.25586 loss)
I0228 08:29:43.943523  7886 sgd_solver.cpp:170] Iteration 39000, lr = 0.0987755, m = 0.9, wd = 0.0005, gs = 359.6
I0228 08:29:48.948369  7886 solver.cpp:347] Iteration 39100 (19.9805 iter/s, 5.00488s/100 iter), 62.5/90.9ep, loss = 2.00977
I0228 08:29:48.948501  7886 solver.cpp:371]     Train net output #0: loss = 2.00977 (* 1 = 2.00977 loss)
I0228 08:29:48.948525  7886 sgd_solver.cpp:170] Iteration 39100, lr = 0.0976734, m = 0.9, wd = 0.0005, gs = 368.08
I0228 08:29:53.952213  7886 solver.cpp:347] Iteration 39200 (19.9851 iter/s, 5.00373s/100 iter), 62.7/90.9ep, loss = 2.05078
I0228 08:29:53.952314  7886 solver.cpp:371]     Train net output #0: loss = 2.05078 (* 1 = 2.05078 loss)
I0228 08:29:53.952324  7886 sgd_solver.cpp:170] Iteration 39200, lr = 0.0965775, m = 0.9, wd = 0.0005, gs = 435.82
I0228 08:29:58.946918  7886 solver.cpp:347] Iteration 39300 (20.0213 iter/s, 4.99468s/100 iter), 62.8/90.9ep, loss = 2.20117
I0228 08:29:58.947043  7886 solver.cpp:371]     Train net output #0: loss = 2.20117 (* 1 = 2.20117 loss)
I0228 08:29:58.947057  7886 sgd_solver.cpp:170] Iteration 39300, lr = 0.0954878, m = 0.9, wd = 0.0005, gs = 417.78
I0228 08:30:03.941926  7886 solver.cpp:347] Iteration 39400 (20.0203 iter/s, 4.99492s/100 iter), 63/90.9ep, loss = 2.22461
I0228 08:30:03.942426  7886 solver.cpp:371]     Train net output #0: loss = 2.22461 (* 1 = 2.22461 loss)
I0228 08:30:03.942443  7886 sgd_solver.cpp:170] Iteration 39400, lr = 0.0944043, m = 0.9, wd = 0.0005, gs = 366.89
I0228 08:30:04.189446  7987 data_reader.cpp:178] Shuffling 1281167 records...
I0228 08:30:08.953778  7886 solver.cpp:347] Iteration 39500 (19.9531 iter/s, 5.01174s/100 iter), 63.1/90.9ep, loss = 2.0957
I0228 08:30:08.953950  7886 solver.cpp:371]     Train net output #0: loss = 2.0957 (* 1 = 2.0957 loss)
I0228 08:30:08.953963  7886 sgd_solver.cpp:170] Iteration 39500, lr = 0.0933269, m = 0.9, wd = 0.0005, gs = 408.27
I0228 08:30:13.936399  7886 solver.cpp:347] Iteration 39600 (20.0701 iter/s, 4.98254s/100 iter), 63.3/90.9ep, loss = 2.14453
I0228 08:30:13.936524  7886 solver.cpp:371]     Train net output #0: loss = 2.14453 (* 1 = 2.14453 loss)
I0228 08:30:13.936547  7886 sgd_solver.cpp:170] Iteration 39600, lr = 0.0922557, m = 0.9, wd = 0.0005, gs = 381.9
I0228 08:30:18.966734  7886 solver.cpp:347] Iteration 39700 (19.8796 iter/s, 5.03028s/100 iter), 63.5/90.9ep, loss = 2.13672
I0228 08:30:18.966883  7886 solver.cpp:371]     Train net output #0: loss = 2.13672 (* 1 = 2.13672 loss)
I0228 08:30:18.966892  7886 sgd_solver.cpp:170] Iteration 39700, lr = 0.0911907, m = 0.9, wd = 0.0005, gs = 367.11
I0228 08:30:23.975682  7886 solver.cpp:347] Iteration 39800 (19.9647 iter/s, 5.00884s/100 iter), 63.6/90.9ep, loss = 2.16992
I0228 08:30:23.975800  7886 solver.cpp:371]     Train net output #0: loss = 2.16992 (* 1 = 2.16992 loss)
I0228 08:30:23.975808  7886 sgd_solver.cpp:170] Iteration 39800, lr = 0.0901319, m = 0.9, wd = 0.0005, gs = 451.48
I0228 08:30:28.978730  7886 solver.cpp:347] Iteration 39900 (19.9881 iter/s, 5.00297s/100 iter), 63.8/90.9ep, loss = 2.14453
I0228 08:30:28.978895  7886 solver.cpp:371]     Train net output #0: loss = 2.14453 (* 1 = 2.14453 loss)
I0228 08:30:28.978919  7886 sgd_solver.cpp:170] Iteration 39900, lr = 0.0890793, m = 0.9, wd = 0.0005, gs = 436.56
I0228 08:30:33.968327  7886 solver.cpp:347] Iteration 40000 (20.0421 iter/s, 4.98949s/100 iter), 63.9/90.9ep, loss = 2.45703
I0228 08:30:33.968783  7886 solver.cpp:371]     Train net output #0: loss = 2.45703 (* 1 = 2.45703 loss)
I0228 08:30:33.968799  7886 sgd_solver.cpp:170] Iteration 40000, lr = 0.0880328, m = 0.9, wd = 0.0005, gs = 423.37
I0228 08:30:35.443739  7991 data_reader.cpp:178] Shuffling 1281167 records...
I0228 08:30:39.027921  7886 solver.cpp:347] Iteration 40100 (19.7646 iter/s, 5.05956s/100 iter), 64.1/90.9ep, loss = 1.76367
I0228 08:30:39.028117  7886 solver.cpp:371]     Train net output #0: loss = 1.76367 (* 1 = 1.76367 loss)
I0228 08:30:39.028129  7886 sgd_solver.cpp:170] Iteration 40100, lr = 0.0869926, m = 0.9, wd = 0.0005, gs = 460.78
I0228 08:30:44.028292  7886 solver.cpp:347] Iteration 40200 (19.9993 iter/s, 5.00017s/100 iter), 64.3/90.9ep, loss = 2.07617
I0228 08:30:44.028475  7886 solver.cpp:371]     Train net output #0: loss = 2.07617 (* 1 = 2.07617 loss)
I0228 08:30:44.028489  7886 sgd_solver.cpp:170] Iteration 40200, lr = 0.0859585, m = 0.9, wd = 0.0005, gs = 508.35
I0228 08:30:48.997634  7886 solver.cpp:347] Iteration 40300 (20.1233 iter/s, 4.96937s/100 iter), 64.4/90.9ep, loss = 2.24023
I0228 08:30:48.997870  7886 solver.cpp:371]     Train net output #0: loss = 2.24023 (* 1 = 2.24023 loss)
I0228 08:30:48.997882  7886 sgd_solver.cpp:170] Iteration 40300, lr = 0.0849306, m = 0.9, wd = 0.0005, gs = 360.58
I0228 08:30:53.999007  7886 solver.cpp:347] Iteration 40400 (19.9949 iter/s, 5.00128s/100 iter), 64.6/90.9ep, loss = 2.13867
I0228 08:30:53.999192  7886 solver.cpp:371]     Train net output #0: loss = 2.13867 (* 1 = 2.13867 loss)
I0228 08:30:53.999202  7886 sgd_solver.cpp:170] Iteration 40400, lr = 0.0839089, m = 0.9, wd = 0.0005, gs = 425.25
I0228 08:30:54.697455  7983 blocking_queue.cpp:40] Data layer prefetch queue empty
I0228 08:30:58.975306  7886 solver.cpp:347] Iteration 40500 (20.0956 iter/s, 4.97621s/100 iter), 64.7/90.9ep, loss = 2.2832
I0228 08:30:58.975447  7886 solver.cpp:371]     Train net output #0: loss = 2.2832 (* 1 = 2.2832 loss)
I0228 08:30:58.975461  7886 sgd_solver.cpp:170] Iteration 40500, lr = 0.0828934, m = 0.9, wd = 0.0005, gs = 339.86
I0228 08:31:03.981688  7886 solver.cpp:347] Iteration 40600 (19.9748 iter/s, 5.00632s/100 iter), 64.9/90.9ep, loss = 2.15234
I0228 08:31:03.982288  7886 solver.cpp:371]     Train net output #0: loss = 2.15234 (* 1 = 2.15234 loss)
I0228 08:31:03.982305  7886 sgd_solver.cpp:170] Iteration 40600, lr = 0.081884, m = 0.9, wd = 0.0005, gs = 411.84
I0228 08:31:06.819876  7985 data_reader.cpp:178] Shuffling 1281167 records...
I0228 08:31:08.985612  7886 solver.cpp:347] Iteration 40700 (19.9847 iter/s, 5.00383s/100 iter), 65.1/90.9ep, loss = 2.10742
I0228 08:31:08.985846  7886 solver.cpp:371]     Train net output #0: loss = 2.10742 (* 1 = 2.10742 loss)
I0228 08:31:08.985857  7886 sgd_solver.cpp:170] Iteration 40700, lr = 0.0808808, m = 0.9, wd = 0.0005, gs = 436.89
I0228 08:31:13.994691  7886 solver.cpp:347] Iteration 40800 (19.9642 iter/s, 5.00897s/100 iter), 65.2/90.9ep, loss = 2.15234
I0228 08:31:13.994818  7886 solver.cpp:371]     Train net output #0: loss = 2.15234 (* 1 = 2.15234 loss)
I0228 08:31:13.994848  7886 sgd_solver.cpp:170] Iteration 40800, lr = 0.0798839, m = 0.9, wd = 0.0005, gs = 381.25
I0228 08:31:19.000231  7886 solver.cpp:347] Iteration 40900 (19.9782 iter/s, 5.00546s/100 iter), 65.4/90.9ep, loss = 2.00586
I0228 08:31:19.000368  7886 solver.cpp:371]     Train net output #0: loss = 2.00586 (* 1 = 2.00586 loss)
I0228 08:31:19.000378  7886 sgd_solver.cpp:170] Iteration 40900, lr = 0.0788931, m = 0.9, wd = 0.0005, gs = 377.36
I0228 08:31:24.035753  7886 solver.cpp:347] Iteration 41000 (19.8594 iter/s, 5.0354s/100 iter), 65.5/90.9ep, loss = 2.12695
I0228 08:31:24.035928  7886 solver.cpp:371]     Train net output #0: loss = 2.12695 (* 1 = 2.12695 loss)
I0228 08:31:24.035953  7886 sgd_solver.cpp:170] Iteration 41000, lr = 0.0779085, m = 0.9, wd = 0.0005, gs = 437.59
I0228 08:31:29.041246  7886 solver.cpp:347] Iteration 41100 (19.9782 iter/s, 5.00545s/100 iter), 65.7/90.9ep, loss = 2.10938
I0228 08:31:29.041424  7886 solver.cpp:371]     Train net output #0: loss = 2.10938 (* 1 = 2.10938 loss)
I0228 08:31:29.041438  7886 sgd_solver.cpp:170] Iteration 41100, lr = 0.07693, m = 0.9, wd = 0.0005, gs = 387.04
I0228 08:31:34.068888  7886 solver.cpp:347] Iteration 41200 (19.8903 iter/s, 5.02757s/100 iter), 65.9/90.9ep, loss = 2.10352
I0228 08:31:34.069301  7886 solver.cpp:371]     Train net output #0: loss = 2.10352 (* 1 = 2.10352 loss)
I0228 08:31:34.069324  7886 sgd_solver.cpp:170] Iteration 41200, lr = 0.0759578, m = 0.9, wd = 0.0005, gs = 362.27
I0228 08:31:38.095028  7989 data_reader.cpp:178] Shuffling 1281167 records...
I0228 08:31:39.037838  7886 solver.cpp:347] Iteration 41300 (20.1253 iter/s, 4.96887s/100 iter), 66/90.9ep, loss = 2.08789
I0228 08:31:39.037983  7886 solver.cpp:371]     Train net output #0: loss = 2.08789 (* 1 = 2.08789 loss)
I0228 08:31:39.038008  7886 sgd_solver.cpp:170] Iteration 41300, lr = 0.0749917, m = 0.9, wd = 0.0005, gs = 429.52
I0228 08:31:44.040864  7886 solver.cpp:347] Iteration 41400 (19.9882 iter/s, 5.00295s/100 iter), 66.2/90.9ep, loss = 1.89844
I0228 08:31:44.041100  7886 solver.cpp:371]     Train net output #0: loss = 1.89844 (* 1 = 1.89844 loss)
I0228 08:31:44.041138  7886 sgd_solver.cpp:170] Iteration 41400, lr = 0.0740318, m = 0.9, wd = 0.0005, gs = 452.06
I0228 08:31:49.028467  7886 solver.cpp:347] Iteration 41500 (20.0502 iter/s, 4.98747s/100 iter), 66.3/90.9ep, loss = 2.34766
I0228 08:31:49.028595  7886 solver.cpp:371]     Train net output #0: loss = 2.34766 (* 1 = 2.34766 loss)
I0228 08:31:49.028609  7886 sgd_solver.cpp:170] Iteration 41500, lr = 0.0730781, m = 0.9, wd = 0.0005, gs = 350.7
I0228 08:31:54.035809  7886 solver.cpp:347] Iteration 41600 (19.9712 iter/s, 5.00722s/100 iter), 66.5/90.9ep, loss = 2.08984
I0228 08:31:54.035931  7886 solver.cpp:371]     Train net output #0: loss = 2.08984 (* 1 = 2.08984 loss)
I0228 08:31:54.035953  7886 sgd_solver.cpp:170] Iteration 41600, lr = 0.0721306, m = 0.9, wd = 0.0005, gs = 417.54
I0228 08:31:59.042719  7886 solver.cpp:347] Iteration 41700 (19.9726 iter/s, 5.00686s/100 iter), 66.7/90.9ep, loss = 2.09766
I0228 08:31:59.042847  7886 solver.cpp:371]     Train net output #0: loss = 2.09766 (* 1 = 2.09766 loss)
I0228 08:31:59.042857  7886 sgd_solver.cpp:170] Iteration 41700, lr = 0.0711893, m = 0.9, wd = 0.0005, gs = 400.45
I0228 08:32:04.026125  7886 solver.cpp:347] Iteration 41800 (20.067 iter/s, 4.98331s/100 iter), 66.8/90.9ep, loss = 2.13867
I0228 08:32:04.026264  7886 solver.cpp:371]     Train net output #0: loss = 2.13867 (* 1 = 2.13867 loss)
I0228 08:32:04.026276  7886 sgd_solver.cpp:170] Iteration 41800, lr = 0.0702541, m = 0.9, wd = 0.0005, gs = 377.96
I0228 08:32:09.028309  7886 solver.cpp:347] Iteration 41900 (19.9916 iter/s, 5.00209s/100 iter), 67/90.9ep, loss = 2.39062
I0228 08:32:09.028880  7886 solver.cpp:371]     Train net output #0: loss = 2.39062 (* 1 = 2.39062 loss)
I0228 08:32:09.028904  7886 sgd_solver.cpp:170] Iteration 41900, lr = 0.0693252, m = 0.9, wd = 0.0005, gs = 382.46
I0228 08:32:09.472206  7988 data_reader.cpp:178] Shuffling 1281167 records...
I0228 08:32:14.049895  7886 solver.cpp:347] Iteration 42000 (19.9144 iter/s, 5.02149s/100 iter), 67.1/90.9ep, loss = 1.77539
I0228 08:32:14.050122  7886 solver.cpp:371]     Train net output #0: loss = 1.77539 (* 1 = 1.77539 loss)
I0228 08:32:14.050134  7886 sgd_solver.cpp:170] Iteration 42000, lr = 0.0684024, m = 0.9, wd = 0.0005, gs = 376.17
I0228 08:32:19.079696  7886 solver.cpp:347] Iteration 42100 (19.8818 iter/s, 5.02973s/100 iter), 67.3/90.9ep, loss = 1.91504
I0228 08:32:19.079843  7886 solver.cpp:371]     Train net output #0: loss = 1.91504 (* 1 = 1.91504 loss)
I0228 08:32:19.079854  7886 sgd_solver.cpp:170] Iteration 42100, lr = 0.0674858, m = 0.9, wd = 0.0005, gs = 390.72
I0228 08:32:24.096941  7886 solver.cpp:347] Iteration 42200 (19.9317 iter/s, 5.01714s/100 iter), 67.5/90.9ep, loss = 2.0625
I0228 08:32:24.097075  7886 solver.cpp:371]     Train net output #0: loss = 2.0625 (* 1 = 2.0625 loss)
I0228 08:32:24.097087  7886 sgd_solver.cpp:170] Iteration 42200, lr = 0.0665753, m = 0.9, wd = 0.0005, gs = 430.47
I0228 08:32:29.100895  7886 solver.cpp:347] Iteration 42300 (19.9844 iter/s, 5.00389s/100 iter), 67.6/90.9ep, loss = 2.04102
I0228 08:32:29.101088  7886 solver.cpp:371]     Train net output #0: loss = 2.04102 (* 1 = 2.04102 loss)
I0228 08:32:29.101097  7886 sgd_solver.cpp:170] Iteration 42300, lr = 0.0656711, m = 0.9, wd = 0.0005, gs = 342.4
I0228 08:32:34.044312  7886 solver.cpp:347] Iteration 42400 (20.2294 iter/s, 4.9433s/100 iter), 67.8/90.9ep, loss = 2.16797
I0228 08:32:34.044476  7886 solver.cpp:371]     Train net output #0: loss = 2.16797 (* 1 = 2.16797 loss)
I0228 08:32:34.044523  7886 sgd_solver.cpp:170] Iteration 42400, lr = 0.0647731, m = 0.9, wd = 0.0005, gs = 380.1
I0228 08:32:39.005108  7886 solver.cpp:347] Iteration 42500 (20.1584 iter/s, 4.96072s/100 iter), 67.9/90.9ep, loss = 2.06055
I0228 08:32:39.005275  7886 solver.cpp:371]     Train net output #0: loss = 2.06055 (* 1 = 2.06055 loss)
I0228 08:32:39.005291  7886 sgd_solver.cpp:170] Iteration 42500, lr = 0.0638812, m = 0.9, wd = 0.0005, gs = 434.83
I0228 08:32:40.627826  7988 data_reader.cpp:178] Shuffling 1281167 records...
I0228 08:32:43.959550  7886 solver.cpp:347] Iteration 42600 (20.1842 iter/s, 4.95437s/100 iter), 68.1/90.9ep, loss = 2.18164
I0228 08:32:43.959676  7886 solver.cpp:371]     Train net output #0: loss = 2.18164 (* 1 = 2.18164 loss)
I0228 08:32:43.959687  7886 sgd_solver.cpp:170] Iteration 42600, lr = 0.0629955, m = 0.9, wd = 0.0005, gs = 412.82
I0228 08:32:48.944669  7886 solver.cpp:347] Iteration 42700 (20.0601 iter/s, 4.98503s/100 iter), 68.3/90.9ep, loss = 2.02734
I0228 08:32:48.944869  7886 solver.cpp:371]     Train net output #0: loss = 2.02734 (* 1 = 2.02734 loss)
I0228 08:32:48.944895  7886 sgd_solver.cpp:170] Iteration 42700, lr = 0.062116, m = 0.9, wd = 0.0005, gs = 350.15
I0228 08:32:53.950549  7886 solver.cpp:347] Iteration 42800 (19.9769 iter/s, 5.00578s/100 iter), 68.4/90.9ep, loss = 1.90625
I0228 08:32:53.950651  7886 solver.cpp:371]     Train net output #0: loss = 1.90625 (* 1 = 1.90625 loss)
I0228 08:32:53.950690  7886 sgd_solver.cpp:170] Iteration 42800, lr = 0.0612427, m = 0.9, wd = 0.0005, gs = 351.48
I0228 08:32:58.935763  7886 solver.cpp:347] Iteration 42900 (20.0597 iter/s, 4.98511s/100 iter), 68.6/90.9ep, loss = 2.02148
I0228 08:32:58.935874  7886 solver.cpp:371]     Train net output #0: loss = 2.02148 (* 1 = 2.02148 loss)
I0228 08:32:58.935887  7886 sgd_solver.cpp:170] Iteration 42900, lr = 0.0603755, m = 0.9, wd = 0.0005, gs = 390.32
I0228 08:33:03.901515  7886 solver.cpp:347] Iteration 43000 (20.1385 iter/s, 4.96561s/100 iter), 68.7/90.9ep, loss = 2.02734
I0228 08:33:03.901644  7886 solver.cpp:371]     Train net output #0: loss = 2.02734 (* 1 = 2.02734 loss)
I0228 08:33:03.901657  7886 sgd_solver.cpp:170] Iteration 43000, lr = 0.0595145, m = 0.9, wd = 0.0005, gs = 440.33
I0228 08:33:08.901100  7886 solver.cpp:347] Iteration 43100 (20.0018 iter/s, 4.99956s/100 iter), 68.9/90.9ep, loss = 2.10156
I0228 08:33:08.901252  7886 solver.cpp:371]     Train net output #0: loss = 2.10156 (* 1 = 2.10156 loss)
I0228 08:33:08.901263  7886 sgd_solver.cpp:170] Iteration 43100, lr = 0.0586598, m = 0.9, wd = 0.0005, gs = 468.38
I0228 08:33:11.761746  7984 data_reader.cpp:178] Shuffling 1281167 records...
I0228 08:33:13.880252  7886 solver.cpp:347] Iteration 43200 (20.0844 iter/s, 4.97898s/100 iter), 69.1/90.9ep, loss = 2.24805
I0228 08:33:13.880427  7886 solver.cpp:371]     Train net output #0: loss = 2.24805 (* 1 = 2.24805 loss)
I0228 08:33:13.880437  7886 sgd_solver.cpp:170] Iteration 43200, lr = 0.0578112, m = 0.9, wd = 0.0005, gs = 385.16
I0228 08:33:18.850047  7886 solver.cpp:347] Iteration 43300 (20.1219 iter/s, 4.9697s/100 iter), 69.2/90.9ep, loss = 1.80859
I0228 08:33:18.850194  7886 solver.cpp:371]     Train net output #0: loss = 1.80859 (* 1 = 1.80859 loss)
I0228 08:33:18.850208  7886 sgd_solver.cpp:170] Iteration 43300, lr = 0.0569688, m = 0.9, wd = 0.0005, gs = 378.83
I0228 08:33:23.827819  7886 solver.cpp:347] Iteration 43400 (20.0896 iter/s, 4.97771s/100 iter), 69.4/90.9ep, loss = 2.10547
I0228 08:33:23.827944  7886 solver.cpp:371]     Train net output #0: loss = 2.10547 (* 1 = 2.10547 loss)
I0228 08:33:23.827957  7886 sgd_solver.cpp:170] Iteration 43400, lr = 0.0561326, m = 0.9, wd = 0.0005, gs = 387.22
I0228 08:33:28.829201  7886 solver.cpp:347] Iteration 43500 (19.995 iter/s, 5.00124s/100 iter), 69.5/90.9ep, loss = 2.22852
I0228 08:33:28.829314  7886 solver.cpp:371]     Train net output #0: loss = 2.22852 (* 1 = 2.22852 loss)
I0228 08:33:28.829340  7886 sgd_solver.cpp:170] Iteration 43500, lr = 0.0553025, m = 0.9, wd = 0.0005, gs = 460.32
I0228 08:33:33.862290  7886 solver.cpp:347] Iteration 43600 (19.8688 iter/s, 5.03303s/100 iter), 69.7/90.9ep, loss = 2.15039
I0228 08:33:33.862458  7886 solver.cpp:371]     Train net output #0: loss = 2.15039 (* 1 = 2.15039 loss)
I0228 08:33:33.862493  7886 sgd_solver.cpp:170] Iteration 43600, lr = 0.0544786, m = 0.9, wd = 0.0005, gs = 409.38
I0228 08:33:38.844925  7886 solver.cpp:347] Iteration 43700 (20.0699 iter/s, 4.98258s/100 iter), 69.9/90.9ep, loss = 2.07422
I0228 08:33:38.845038  7886 solver.cpp:371]     Train net output #0: loss = 2.07422 (* 1 = 2.07422 loss)
I0228 08:33:38.845072  7886 sgd_solver.cpp:170] Iteration 43700, lr = 0.0536609, m = 0.9, wd = 0.0005, gs = 357.45
I0228 08:33:43.042309  7984 data_reader.cpp:178] Shuffling 1281167 records...
I0228 08:33:43.421416  7966 blocking_queue.cpp:40] Data layer prefetch queue empty
I0228 08:33:43.777528  7886 solver.cpp:347] Iteration 43800 (20.2738 iter/s, 4.93248s/100 iter), 70/90.9ep, loss = 1.82227
I0228 08:33:43.777676  7886 solver.cpp:371]     Train net output #0: loss = 1.82227 (* 1 = 1.82227 loss)
I0228 08:33:43.777765  7886 sgd_solver.cpp:170] Iteration 43800, lr = 0.0528495, m = 0.9, wd = 0.0005, gs = 433.34
I0228 08:33:48.756814  7886 solver.cpp:347] Iteration 43900 (20.0837 iter/s, 4.97915s/100 iter), 70.2/90.9ep, loss = 2.04297
I0228 08:33:48.756981  7886 solver.cpp:371]     Train net output #0: loss = 2.04297 (* 1 = 2.04297 loss)
I0228 08:33:48.757009  7886 sgd_solver.cpp:170] Iteration 43900, lr = 0.0520442, m = 0.9, wd = 0.0005, gs = 337.28
I0228 08:33:53.782037  7886 solver.cpp:347] Iteration 44000 (19.8998 iter/s, 5.02519s/100 iter), 70.3/90.9ep, loss = 1.9668
I0228 08:33:53.782253  7886 solver.cpp:371]     Train net output #0: loss = 1.9668 (* 1 = 1.9668 loss)
I0228 08:33:53.782265  7886 sgd_solver.cpp:170] Iteration 44000, lr = 0.051245, m = 0.9, wd = 0.0005, gs = 377.64
I0228 08:33:58.779598  7886 solver.cpp:347] Iteration 44100 (20.0101 iter/s, 4.99748s/100 iter), 70.5/90.9ep, loss = 1.88867
I0228 08:33:58.779733  7886 solver.cpp:371]     Train net output #0: loss = 1.88867 (* 1 = 1.88867 loss)
I0228 08:33:58.779745  7886 sgd_solver.cpp:170] Iteration 44100, lr = 0.0504521, m = 0.9, wd = 0.0005, gs = 407.72
I0228 08:34:03.784389  7886 solver.cpp:347] Iteration 44200 (19.9812 iter/s, 5.00471s/100 iter), 70.7/90.9ep, loss = 2.24023
I0228 08:34:03.784528  7886 solver.cpp:371]     Train net output #0: loss = 2.24023 (* 1 = 2.24023 loss)
I0228 08:34:03.784538  7886 sgd_solver.cpp:170] Iteration 44200, lr = 0.0496653, m = 0.9, wd = 0.0005, gs = 364.92
I0228 08:34:08.740914  7886 solver.cpp:347] Iteration 44300 (20.1759 iter/s, 4.95641s/100 iter), 70.8/90.9ep, loss = 2.18164
I0228 08:34:08.741096  7886 solver.cpp:371]     Train net output #0: loss = 2.18164 (* 1 = 2.18164 loss)
I0228 08:34:08.741108  7886 sgd_solver.cpp:170] Iteration 44300, lr = 0.0488847, m = 0.9, wd = 0.0005, gs = 397.15
I0228 08:34:13.705667  7886 solver.cpp:347] Iteration 44400 (20.1422 iter/s, 4.96469s/100 iter), 71/90.9ep, loss = 1.98438
I0228 08:34:13.706149  7886 solver.cpp:371]     Train net output #0: loss = 1.98438 (* 1 = 1.98438 loss)
I0228 08:34:13.706176  7886 sgd_solver.cpp:170] Iteration 44400, lr = 0.0481103, m = 0.9, wd = 0.0005, gs = 405.43
I0228 08:34:14.152009  7984 data_reader.cpp:178] Shuffling 1281167 records...
I0228 08:34:18.711176  7886 solver.cpp:347] Iteration 44500 (19.9784 iter/s, 5.00541s/100 iter), 71.1/90.9ep, loss = 2.16992
I0228 08:34:18.711310  7886 solver.cpp:371]     Train net output #0: loss = 2.16992 (* 1 = 2.16992 loss)
I0228 08:34:18.711323  7886 sgd_solver.cpp:170] Iteration 44500, lr = 0.0473421, m = 0.9, wd = 0.0005, gs = 388.18
I0228 08:34:23.702544  7886 solver.cpp:347] Iteration 44600 (20.0349 iter/s, 4.99129s/100 iter), 71.3/90.9ep, loss = 2.1875
I0228 08:34:23.702888  7886 solver.cpp:371]     Train net output #0: loss = 2.1875 (* 1 = 2.1875 loss)
I0228 08:34:23.702934  7886 sgd_solver.cpp:170] Iteration 44600, lr = 0.0465801, m = 0.9, wd = 0.0005, gs = 396.28
I0228 08:34:28.684607  7886 solver.cpp:347] Iteration 44700 (20.0723 iter/s, 4.98199s/100 iter), 71.5/90.9ep, loss = 2.23242
I0228 08:34:28.684792  7886 solver.cpp:371]     Train net output #0: loss = 2.23242 (* 1 = 2.23242 loss)
I0228 08:34:28.684801  7886 sgd_solver.cpp:170] Iteration 44700, lr = 0.0458242, m = 0.9, wd = 0.0005, gs = 410.54
I0228 08:34:33.691665  7886 solver.cpp:347] Iteration 44800 (19.9721 iter/s, 5.00698s/100 iter), 71.6/90.9ep, loss = 2.04102
I0228 08:34:33.691800  7886 solver.cpp:371]     Train net output #0: loss = 2.04102 (* 1 = 2.04102 loss)
I0228 08:34:33.691809  7886 sgd_solver.cpp:170] Iteration 44800, lr = 0.0450746, m = 0.9, wd = 0.0005, gs = 396.16
I0228 08:34:38.685336  7886 solver.cpp:347] Iteration 44900 (20.0258 iter/s, 4.99357s/100 iter), 71.8/90.9ep, loss = 2.14844
I0228 08:34:38.685448  7886 solver.cpp:371]     Train net output #0: loss = 2.14844 (* 1 = 2.14844 loss)
I0228 08:34:38.685472  7886 sgd_solver.cpp:170] Iteration 44900, lr = 0.0443311, m = 0.9, wd = 0.0005, gs = 414.65
I0228 08:34:43.685447  7886 solver.cpp:347] Iteration 45000 (20 iter/s, 4.99999s/100 iter), 71.9/90.9ep, loss = 2.11719
I0228 08:34:43.685678  7886 solver.cpp:371]     Train net output #0: loss = 2.11719 (* 1 = 2.11719 loss)
I0228 08:34:43.685689  7886 sgd_solver.cpp:170] Iteration 45000, lr = 0.0435938, m = 0.9, wd = 0.0005, gs = 397.86
I0228 08:34:45.522936  7988 data_reader.cpp:178] Shuffling 1281167 records...
I0228 08:34:48.685009  7886 solver.cpp:347] Iteration 45100 (20.0021 iter/s, 4.99947s/100 iter), 72.1/90.9ep, loss = 2.04883
I0228 08:34:48.685153  7886 solver.cpp:371]     Train net output #0: loss = 2.04883 (* 1 = 2.04883 loss)
I0228 08:34:48.685163  7886 sgd_solver.cpp:170] Iteration 45100, lr = 0.0428627, m = 0.9, wd = 0.0005, gs = 412.01
I0228 08:34:53.681005  7886 solver.cpp:347] Iteration 45200 (20.0163 iter/s, 4.99593s/100 iter), 72.3/90.9ep, loss = 1.99023
I0228 08:34:53.681162  7886 solver.cpp:371]     Train net output #0: loss = 1.99023 (* 1 = 1.99023 loss)
I0228 08:34:53.681174  7886 sgd_solver.cpp:170] Iteration 45200, lr = 0.0421377, m = 0.9, wd = 0.0005, gs = 392.52
I0228 08:34:58.690824  7886 solver.cpp:347] Iteration 45300 (19.9612 iter/s, 5.00972s/100 iter), 72.4/90.9ep, loss = 2.04883
I0228 08:34:58.691002  7886 solver.cpp:371]     Train net output #0: loss = 2.04883 (* 1 = 2.04883 loss)
I0228 08:34:58.691028  7886 sgd_solver.cpp:170] Iteration 45300, lr = 0.041419, m = 0.9, wd = 0.0005, gs = 436.77
I0228 08:35:03.692457  7886 solver.cpp:347] Iteration 45400 (19.994 iter/s, 5.00149s/100 iter), 72.6/90.9ep, loss = 2.07617
I0228 08:35:03.692592  7886 solver.cpp:371]     Train net output #0: loss = 2.07617 (* 1 = 2.07617 loss)
I0228 08:35:03.692602  7886 sgd_solver.cpp:170] Iteration 45400, lr = 0.0407064, m = 0.9, wd = 0.0005, gs = 382.83
I0228 08:35:08.669782  7886 solver.cpp:347] Iteration 45500 (20.0913 iter/s, 4.97727s/100 iter), 72.7/90.9ep, loss = 1.91016
I0228 08:35:08.669948  7886 solver.cpp:371]     Train net output #0: loss = 1.91016 (* 1 = 1.91016 loss)
I0228 08:35:08.669963  7886 sgd_solver.cpp:170] Iteration 45500, lr = 0.04, m = 0.9, wd = 0.0005, gs = 387.4
I0228 08:35:13.645964  7886 solver.cpp:347] Iteration 45600 (20.096 iter/s, 4.97611s/100 iter), 72.9/90.9ep, loss = 2.17969
I0228 08:35:13.646121  7886 solver.cpp:371]     Train net output #0: loss = 2.17969 (* 1 = 2.17969 loss)
I0228 08:35:13.646132  7886 sgd_solver.cpp:170] Iteration 45600, lr = 0.0392998, m = 0.9, wd = 0.0005, gs = 396.05
I0228 08:35:16.663352  7989 data_reader.cpp:178] Shuffling 1281167 records...
I0228 08:35:18.640496  7886 solver.cpp:347] Iteration 45700 (20.0224 iter/s, 4.9944s/100 iter), 73.1/90.9ep, loss = 1.88965
I0228 08:35:18.640600  7886 solver.cpp:371]     Train net output #0: loss = 1.88965 (* 1 = 1.88965 loss)
I0228 08:35:18.640614  7886 sgd_solver.cpp:170] Iteration 45700, lr = 0.0386058, m = 0.9, wd = 0.0005, gs = 384.43
I0228 08:35:23.686767  7886 solver.cpp:347] Iteration 45800 (19.8169 iter/s, 5.0462s/100 iter), 73.2/90.9ep, loss = 2.18555
I0228 08:35:23.686981  7886 solver.cpp:371]     Train net output #0: loss = 2.18555 (* 1 = 2.18555 loss)
I0228 08:35:23.687016  7886 sgd_solver.cpp:170] Iteration 45800, lr = 0.0379179, m = 0.9, wd = 0.0005, gs = 414.45
I0228 08:35:28.697587  7886 solver.cpp:347] Iteration 45900 (19.9572 iter/s, 5.01073s/100 iter), 73.4/90.9ep, loss = 1.93848
I0228 08:35:28.697796  7886 solver.cpp:371]     Train net output #0: loss = 1.93848 (* 1 = 1.93848 loss)
I0228 08:35:28.697854  7886 sgd_solver.cpp:170] Iteration 45900, lr = 0.0372363, m = 0.9, wd = 0.0005, gs = 389.27
I0228 08:35:33.733031  7886 solver.cpp:347] Iteration 46000 (19.8598 iter/s, 5.0353s/100 iter), 73.5/90.9ep, loss = 1.75781
I0228 08:35:33.733175  7886 solver.cpp:371]     Train net output #0: loss = 1.75781 (* 1 = 1.75781 loss)
I0228 08:35:33.733184  7886 sgd_solver.cpp:170] Iteration 46000, lr = 0.0365608, m = 0.9, wd = 0.0005, gs = 412.31
I0228 08:35:38.759789  7886 solver.cpp:347] Iteration 46100 (19.8936 iter/s, 5.02673s/100 iter), 73.7/90.9ep, loss = 1.96191
I0228 08:35:38.759924  7886 solver.cpp:371]     Train net output #0: loss = 1.96191 (* 1 = 1.96191 loss)
I0228 08:35:38.759938  7886 sgd_solver.cpp:170] Iteration 46100, lr = 0.0358915, m = 0.9, wd = 0.0005, gs = 370.97
I0228 08:35:43.793752  7886 solver.cpp:347] Iteration 46200 (19.8656 iter/s, 5.03384s/100 iter), 73.9/90.9ep, loss = 2.07422
I0228 08:35:43.793915  7886 solver.cpp:371]     Train net output #0: loss = 2.07422 (* 1 = 2.07422 loss)
I0228 08:35:43.793928  7886 sgd_solver.cpp:170] Iteration 46200, lr = 0.0352284, m = 0.9, wd = 0.0005, gs = 431.56
I0228 08:35:48.067270  7987 data_reader.cpp:178] Shuffling 1281167 records...
I0228 08:35:48.811939  7886 solver.cpp:347] Iteration 46300 (19.9277 iter/s, 5.01813s/100 iter), 74/90.9ep, loss = 2.1543
I0228 08:35:48.812072  7886 solver.cpp:371]     Train net output #0: loss = 2.1543 (* 1 = 2.1543 loss)
I0228 08:35:48.812084  7886 sgd_solver.cpp:170] Iteration 46300, lr = 0.0345715, m = 0.9, wd = 0.0005, gs = 448.11
I0228 08:35:53.854120  7886 solver.cpp:347] Iteration 46400 (19.833 iter/s, 5.0421s/100 iter), 74.2/90.9ep, loss = 1.92871
I0228 08:35:53.854276  7886 solver.cpp:371]     Train net output #0: loss = 1.92871 (* 1 = 1.92871 loss)
I0228 08:35:53.854296  7886 sgd_solver.cpp:170] Iteration 46400, lr = 0.0339207, m = 0.9, wd = 0.0005, gs = 348.07
I0228 08:35:58.900871  7886 solver.cpp:347] Iteration 46500 (19.8152 iter/s, 5.04664s/100 iter), 74.3/90.9ep, loss = 1.7959
I0228 08:35:58.900985  7886 solver.cpp:371]     Train net output #0: loss = 1.7959 (* 1 = 1.7959 loss)
I0228 08:35:58.900997  7886 sgd_solver.cpp:170] Iteration 46500, lr = 0.0332762, m = 0.9, wd = 0.0005, gs = 385.43
I0228 08:36:03.914644  7886 solver.cpp:347] Iteration 46600 (19.9453 iter/s, 5.01371s/100 iter), 74.5/90.9ep, loss = 2.03906
I0228 08:36:03.914788  7886 solver.cpp:371]     Train net output #0: loss = 2.03906 (* 1 = 2.03906 loss)
I0228 08:36:03.914811  7886 sgd_solver.cpp:170] Iteration 46600, lr = 0.0326378, m = 0.9, wd = 0.0005, gs = 377.92
I0228 08:36:08.957065  7886 solver.cpp:347] Iteration 46700 (19.8321 iter/s, 5.04233s/100 iter), 74.7/90.9ep, loss = 2.00977
I0228 08:36:08.957206  7886 solver.cpp:371]     Train net output #0: loss = 2.00977 (* 1 = 2.00977 loss)
I0228 08:36:08.957216  7886 sgd_solver.cpp:170] Iteration 46700, lr = 0.0320056, m = 0.9, wd = 0.0005, gs = 434.57
I0228 08:36:13.897305  7886 solver.cpp:347] Iteration 46800 (20.2426 iter/s, 4.94008s/100 iter), 74.8/90.9ep, loss = 1.94141
I0228 08:36:13.897626  7886 solver.cpp:371]     Train net output #0: loss = 1.94141 (* 1 = 1.94141 loss)
I0228 08:36:13.897640  7886 sgd_solver.cpp:170] Iteration 46800, lr = 0.0313796, m = 0.9, wd = 0.0005, gs = 348.51
I0228 08:36:18.847461  7886 solver.cpp:347] Iteration 46900 (20.2016 iter/s, 4.95009s/100 iter), 75/90.9ep, loss = 1.96094
I0228 08:36:18.847985  7886 solver.cpp:371]     Train net output #0: loss = 1.96094 (* 1 = 1.96094 loss)
I0228 08:36:18.848008  7886 sgd_solver.cpp:170] Iteration 46900, lr = 0.0307598, m = 0.9, wd = 0.0005, gs = 373.19
I0228 08:36:19.495452  7991 data_reader.cpp:178] Shuffling 1281167 records...
I0228 08:36:23.855604  7886 solver.cpp:347] Iteration 47000 (19.968 iter/s, 5.00802s/100 iter), 75.1/90.9ep, loss = 1.79199
I0228 08:36:23.855778  7886 solver.cpp:371]     Train net output #0: loss = 1.79199 (* 1 = 1.79199 loss)
I0228 08:36:23.855819  7886 sgd_solver.cpp:170] Iteration 47000, lr = 0.0301461, m = 0.9, wd = 0.0005, gs = 445.34
I0228 08:36:28.871306  7886 solver.cpp:347] Iteration 47100 (19.9374 iter/s, 5.01569s/100 iter), 75.3/90.9ep, loss = 1.96387
I0228 08:36:28.871448  7886 solver.cpp:371]     Train net output #0: loss = 1.96387 (* 1 = 1.96387 loss)
I0228 08:36:28.871457  7886 sgd_solver.cpp:170] Iteration 47100, lr = 0.0295387, m = 0.9, wd = 0.0005, gs = 390.87
I0228 08:36:33.891558  7886 solver.cpp:347] Iteration 47200 (19.9198 iter/s, 5.02012s/100 iter), 75.5/90.9ep, loss = 1.8623
I0228 08:36:33.891695  7886 solver.cpp:371]     Train net output #0: loss = 1.8623 (* 1 = 1.8623 loss)
I0228 08:36:33.891707  7886 sgd_solver.cpp:170] Iteration 47200, lr = 0.0289374, m = 0.9, wd = 0.0005, gs = 377.78
I0228 08:36:35.518975  7982 blocking_queue.cpp:40] Data layer prefetch queue empty
I0228 08:36:38.854528  7886 solver.cpp:347] Iteration 47300 (20.1494 iter/s, 4.96292s/100 iter), 75.6/90.9ep, loss = 1.80566
I0228 08:36:38.854687  7886 solver.cpp:371]     Train net output #0: loss = 1.80566 (* 1 = 1.80566 loss)
I0228 08:36:38.854715  7886 sgd_solver.cpp:170] Iteration 47300, lr = 0.0283423, m = 0.9, wd = 0.0005, gs = 378.59
I0228 08:36:43.844429  7886 solver.cpp:347] Iteration 47400 (20.0412 iter/s, 4.98973s/100 iter), 75.8/90.9ep, loss = 2.01562
I0228 08:36:43.844607  7886 solver.cpp:371]     Train net output #0: loss = 2.01562 (* 1 = 2.01562 loss)
I0228 08:36:43.844632  7886 sgd_solver.cpp:170] Iteration 47400, lr = 0.0277534, m = 0.9, wd = 0.0005, gs = 435.44
I0228 08:36:48.886447  7886 solver.cpp:347] Iteration 47500 (19.8335 iter/s, 5.04197s/100 iter), 75.9/90.9ep, loss = 2.10547
I0228 08:36:48.887001  7886 solver.cpp:371]     Train net output #0: loss = 2.10547 (* 1 = 2.10547 loss)
I0228 08:36:48.887023  7886 sgd_solver.cpp:170] Iteration 47500, lr = 0.0271706, m = 0.9, wd = 0.0005, gs = 414.3
I0228 08:36:50.745055  7987 data_reader.cpp:178] Shuffling 1281167 records...
I0228 08:36:53.909070  7886 solver.cpp:347] Iteration 47600 (19.9103 iter/s, 5.02253s/100 iter), 76.1/90.9ep, loss = 1.75488
I0228 08:36:53.909227  7886 solver.cpp:371]     Train net output #0: loss = 1.75488 (* 1 = 1.75488 loss)
I0228 08:36:53.909238  7886 sgd_solver.cpp:170] Iteration 47600, lr = 0.0265941, m = 0.9, wd = 0.0005, gs = 418.72
I0228 08:36:58.917134  7886 solver.cpp:347] Iteration 47700 (19.968 iter/s, 5.00801s/100 iter), 76.3/90.9ep, loss = 1.95508
I0228 08:36:58.917253  7886 solver.cpp:371]     Train net output #0: loss = 1.95508 (* 1 = 1.95508 loss)
I0228 08:36:58.917264  7886 sgd_solver.cpp:170] Iteration 47700, lr = 0.0260237, m = 0.9, wd = 0.0005, gs = 422.93
I0228 08:37:03.956878  7886 solver.cpp:347] Iteration 47800 (19.8426 iter/s, 5.03966s/100 iter), 76.4/90.9ep, loss = 1.63281
I0228 08:37:03.957095  7886 solver.cpp:371]     Train net output #0: loss = 1.63281 (* 1 = 1.63281 loss)
I0228 08:37:03.957105  7886 sgd_solver.cpp:170] Iteration 47800, lr = 0.0254595, m = 0.9, wd = 0.0005, gs = 358.93
I0228 08:37:08.990834  7886 solver.cpp:347] Iteration 47900 (19.8655 iter/s, 5.03385s/100 iter), 76.6/90.9ep, loss = 1.83984
I0228 08:37:08.990975  7886 solver.cpp:371]     Train net output #0: loss = 1.83984 (* 1 = 1.83984 loss)
I0228 08:37:08.991001  7886 sgd_solver.cpp:170] Iteration 47900, lr = 0.0249015, m = 0.9, wd = 0.0005, gs = 389.4
I0228 08:37:13.981433  7886 solver.cpp:347] Iteration 48000 (20.0381 iter/s, 4.9905s/100 iter), 76.7/90.9ep, loss = 1.78516
I0228 08:37:13.981541  7886 solver.cpp:371]     Train net output #0: loss = 1.78516 (* 1 = 1.78516 loss)
I0228 08:37:13.981585  7886 sgd_solver.cpp:170] Iteration 48000, lr = 0.0243497, m = 0.9, wd = 0.0005, gs = 427.86
I0228 08:37:18.965934  7886 solver.cpp:347] Iteration 48100 (20.0626 iter/s, 4.98439s/100 iter), 76.9/90.9ep, loss = 2.05469
I0228 08:37:18.966425  7886 solver.cpp:371]     Train net output #0: loss = 2.05469 (* 1 = 2.05469 loss)
I0228 08:37:18.966447  7886 sgd_solver.cpp:170] Iteration 48100, lr = 0.0238041, m = 0.9, wd = 0.0005, gs = 380.54
I0228 08:37:22.019596  7985 data_reader.cpp:178] Shuffling 1281167 records...
I0228 08:37:23.929061  7886 solver.cpp:347] Iteration 48200 (20.1488 iter/s, 4.96308s/100 iter), 77/90.9ep, loss = 1.81445
I0228 08:37:23.929193  7886 solver.cpp:371]     Train net output #0: loss = 1.81445 (* 1 = 1.81445 loss)
I0228 08:37:23.929204  7886 sgd_solver.cpp:170] Iteration 48200, lr = 0.0232646, m = 0.9, wd = 0.0005, gs = 389.43
I0228 08:37:28.945593  7886 solver.cpp:347] Iteration 48300 (19.9344 iter/s, 5.01645s/100 iter), 77.2/90.9ep, loss = 2.01758
I0228 08:37:28.945734  7886 solver.cpp:371]     Train net output #0: loss = 2.01758 (* 1 = 2.01758 loss)
I0228 08:37:28.945747  7886 sgd_solver.cpp:170] Iteration 48300, lr = 0.0227314, m = 0.9, wd = 0.0005, gs = 392.92
I0228 08:37:33.983116  7886 solver.cpp:347] Iteration 48400 (19.8513 iter/s, 5.03744s/100 iter), 77.4/90.9ep, loss = 1.64453
I0228 08:37:33.983248  7886 solver.cpp:371]     Train net output #0: loss = 1.64453 (* 1 = 1.64453 loss)
I0228 08:37:33.983258  7886 sgd_solver.cpp:170] Iteration 48400, lr = 0.0222043, m = 0.9, wd = 0.0005, gs = 435.59
I0228 08:37:39.009145  7886 solver.cpp:347] Iteration 48500 (19.8969 iter/s, 5.02592s/100 iter), 77.5/90.9ep, loss = 1.86621
I0228 08:37:39.009286  7886 solver.cpp:371]     Train net output #0: loss = 1.86621 (* 1 = 1.86621 loss)
I0228 08:37:39.009299  7886 sgd_solver.cpp:170] Iteration 48500, lr = 0.0216834, m = 0.9, wd = 0.0005, gs = 407.87
I0228 08:37:44.063735  7886 solver.cpp:347] Iteration 48600 (19.7843 iter/s, 5.05452s/100 iter), 77.7/90.9ep, loss = 1.77246
I0228 08:37:44.063870  7886 solver.cpp:371]     Train net output #0: loss = 1.77246 (* 1 = 1.77246 loss)
I0228 08:37:44.063879  7886 sgd_solver.cpp:170] Iteration 48600, lr = 0.0211687, m = 0.9, wd = 0.0005, gs = 423.28
I0228 08:37:49.080093  7886 solver.cpp:347] Iteration 48700 (19.9351 iter/s, 5.01629s/100 iter), 77.8/90.9ep, loss = 1.72168
I0228 08:37:49.080597  7886 solver.cpp:371]     Train net output #0: loss = 1.72168 (* 1 = 1.72168 loss)
I0228 08:37:49.080613  7886 sgd_solver.cpp:170] Iteration 48700, lr = 0.0206601, m = 0.9, wd = 0.0005, gs = 411.26
I0228 08:37:53.523197  7989 data_reader.cpp:178] Shuffling 1281167 records...
I0228 08:37:54.064275  7886 solver.cpp:347] Iteration 48800 (20.0638 iter/s, 4.98411s/100 iter), 78/90.9ep, loss = 1.80762
I0228 08:37:54.064406  7886 solver.cpp:371]     Train net output #0: loss = 1.80762 (* 1 = 1.80762 loss)
I0228 08:37:54.064425  7886 sgd_solver.cpp:170] Iteration 48800, lr = 0.0201578, m = 0.9, wd = 0.0005, gs = 414.34
I0228 08:37:59.051723  7886 solver.cpp:347] Iteration 48900 (20.0508 iter/s, 4.98733s/100 iter), 78.2/90.9ep, loss = 1.66602
I0228 08:37:59.051882  7886 solver.cpp:371]     Train net output #0: loss = 1.66602 (* 1 = 1.66602 loss)
I0228 08:37:59.051893  7886 sgd_solver.cpp:170] Iteration 48900, lr = 0.0196616, m = 0.9, wd = 0.0005, gs = 393.2
I0228 08:38:04.013710  7886 solver.cpp:347] Iteration 49000 (20.1535 iter/s, 4.96192s/100 iter), 78.3/90.9ep, loss = 1.65234
I0228 08:38:04.013851  7886 solver.cpp:371]     Train net output #0: loss = 1.65234 (* 1 = 1.65234 loss)
I0228 08:38:04.013864  7886 sgd_solver.cpp:170] Iteration 49000, lr = 0.0191716, m = 0.9, wd = 0.0005, gs = 454.08
I0228 08:38:09.016333  7886 solver.cpp:347] Iteration 49100 (19.99 iter/s, 5.00251s/100 iter), 78.5/90.9ep, loss = 1.77832
I0228 08:38:09.016482  7886 solver.cpp:371]     Train net output #0: loss = 1.77832 (* 1 = 1.77832 loss)
I0228 08:38:09.016494  7886 sgd_solver.cpp:170] Iteration 49100, lr = 0.0186878, m = 0.9, wd = 0.0005, gs = 409.72
I0228 08:38:14.023468  7886 solver.cpp:347] Iteration 49200 (19.9721 iter/s, 5.00698s/100 iter), 78.6/90.9ep, loss = 1.69629
I0228 08:38:14.023591  7886 solver.cpp:371]     Train net output #0: loss = 1.69629 (* 1 = 1.69629 loss)
I0228 08:38:14.023613  7886 sgd_solver.cpp:170] Iteration 49200, lr = 0.0182102, m = 0.9, wd = 0.0005, gs = 431.6
I0228 08:38:18.992364  7886 solver.cpp:347] Iteration 49300 (20.1256 iter/s, 4.96879s/100 iter), 78.8/90.9ep, loss = 1.76562
I0228 08:38:18.992549  7886 solver.cpp:371]     Train net output #0: loss = 1.76562 (* 1 = 1.76562 loss)
I0228 08:38:18.992561  7886 sgd_solver.cpp:170] Iteration 49300, lr = 0.0177387, m = 0.9, wd = 0.0005, gs = 380.66
I0228 08:38:23.961385  7886 solver.cpp:347] Iteration 49400 (20.1249 iter/s, 4.96897s/100 iter), 79/90.9ep, loss = 1.56152
I0228 08:38:23.961781  7886 solver.cpp:371]     Train net output #0: loss = 1.56152 (* 1 = 1.56152 loss)
I0228 08:38:23.961804  7886 sgd_solver.cpp:170] Iteration 49400, lr = 0.0172735, m = 0.9, wd = 0.0005, gs = 391.54
I0228 08:38:24.614136  7991 data_reader.cpp:178] Shuffling 1281167 records...
I0228 08:38:28.978969  7886 solver.cpp:347] Iteration 49500 (19.9302 iter/s, 5.01751s/100 iter), 79.1/90.9ep, loss = 1.53516
I0228 08:38:28.979095  7886 solver.cpp:371]     Train net output #0: loss = 1.53516 (* 1 = 1.53516 loss)
I0228 08:38:28.979109  7886 sgd_solver.cpp:170] Iteration 49500, lr = 0.0168144, m = 0.9, wd = 0.0005, gs = 416.21
I0228 08:38:33.950754  7886 solver.cpp:347] Iteration 49600 (20.1139 iter/s, 4.97168s/100 iter), 79.3/90.9ep, loss = 1.81641
I0228 08:38:33.950875  7886 solver.cpp:371]     Train net output #0: loss = 1.81641 (* 1 = 1.81641 loss)
I0228 08:38:33.950887  7886 sgd_solver.cpp:170] Iteration 49600, lr = 0.0163615, m = 0.9, wd = 0.0005, gs = 356.7
I0228 08:38:38.958209  7886 solver.cpp:347] Iteration 49700 (19.9705 iter/s, 5.00739s/100 iter), 79.4/90.9ep, loss = 1.59961
I0228 08:38:38.958384  7886 solver.cpp:371]     Train net output #0: loss = 1.59961 (* 1 = 1.59961 loss)
I0228 08:38:38.958397  7886 sgd_solver.cpp:170] Iteration 49700, lr = 0.0159148, m = 0.9, wd = 0.0005, gs = 424.37
I0228 08:38:43.958668  7886 solver.cpp:347] Iteration 49800 (19.9986 iter/s, 5.00035s/100 iter), 79.6/90.9ep, loss = 1.67285
I0228 08:38:43.958932  7886 solver.cpp:371]     Train net output #0: loss = 1.67285 (* 1 = 1.67285 loss)
I0228 08:38:43.958945  7886 sgd_solver.cpp:170] Iteration 49800, lr = 0.0154743, m = 0.9, wd = 0.0005, gs = 435.04
I0228 08:38:48.938242  7886 solver.cpp:347] Iteration 49900 (20.0827 iter/s, 4.97942s/100 iter), 79.8/90.9ep, loss = 1.68359
I0228 08:38:48.938369  7886 solver.cpp:371]     Train net output #0: loss = 1.68359 (* 1 = 1.68359 loss)
I0228 08:38:48.938380  7886 sgd_solver.cpp:170] Iteration 49900, lr = 0.0150399, m = 0.9, wd = 0.0005, gs = 419.67
I0228 08:38:53.913064  7886 solver.cpp:347] Iteration 50000 (20.1011 iter/s, 4.97485s/100 iter), 79.9/90.9ep, loss = 1.53027
I0228 08:38:53.913170  7886 solver.cpp:371]     Train net output #0: loss = 1.53027 (* 1 = 1.53027 loss)
I0228 08:38:53.913197  7886 sgd_solver.cpp:170] Iteration 50000, lr = 0.0146118, m = 0.9, wd = 0.0005, gs = 339.45
I0228 08:38:55.980558  7989 data_reader.cpp:178] Shuffling 1281167 records...
I0228 08:38:58.932584  7886 solver.cpp:347] Iteration 50100 (19.9225 iter/s, 5.01944s/100 iter), 80.1/90.9ep, loss = 1.79004
I0228 08:38:58.932706  7886 solver.cpp:371]     Train net output #0: loss = 1.79004 (* 1 = 1.79004 loss)
I0228 08:38:58.932719  7886 sgd_solver.cpp:170] Iteration 50100, lr = 0.0141898, m = 0.9, wd = 0.0005, gs = 406.54
I0228 08:39:03.940812  7886 solver.cpp:347] Iteration 50200 (19.9675 iter/s, 5.00814s/100 iter), 80.2/90.9ep, loss = 1.9043
I0228 08:39:03.940989  7886 solver.cpp:371]     Train net output #0: loss = 1.9043 (* 1 = 1.9043 loss)
I0228 08:39:03.941012  7886 sgd_solver.cpp:170] Iteration 50200, lr = 0.013774, m = 0.9, wd = 0.0005, gs = 402.1
I0228 08:39:08.932806  7886 solver.cpp:347] Iteration 50300 (20.0324 iter/s, 4.99192s/100 iter), 80.4/90.9ep, loss = 1.45508
I0228 08:39:08.932942  7886 solver.cpp:371]     Train net output #0: loss = 1.45508 (* 1 = 1.45508 loss)
I0228 08:39:08.932955  7886 sgd_solver.cpp:170] Iteration 50300, lr = 0.0133644, m = 0.9, wd = 0.0005, gs = 357.64
I0228 08:39:13.942824  7886 solver.cpp:347] Iteration 50400 (19.9605 iter/s, 5.0099s/100 iter), 80.6/90.9ep, loss = 1.77832
I0228 08:39:13.942950  7886 solver.cpp:371]     Train net output #0: loss = 1.77832 (* 1 = 1.77832 loss)
I0228 08:39:13.942962  7886 sgd_solver.cpp:170] Iteration 50400, lr = 0.012961, m = 0.9, wd = 0.0005, gs = 375.24
I0228 08:39:18.924650  7886 solver.cpp:347] Iteration 50500 (20.0732 iter/s, 4.98177s/100 iter), 80.7/90.9ep, loss = 1.55859
I0228 08:39:18.924772  7886 solver.cpp:371]     Train net output #0: loss = 1.55859 (* 1 = 1.55859 loss)
I0228 08:39:18.924787  7886 sgd_solver.cpp:170] Iteration 50500, lr = 0.0125637, m = 0.9, wd = 0.0005, gs = 381.37
I0228 08:39:23.937947  7886 solver.cpp:347] Iteration 50600 (19.9473 iter/s, 5.0132s/100 iter), 80.9/90.9ep, loss = 1.67578
I0228 08:39:23.938091  7886 solver.cpp:371]     Train net output #0: loss = 1.67578 (* 1 = 1.67578 loss)
I0228 08:39:23.938122  7886 sgd_solver.cpp:170] Iteration 50600, lr = 0.0121726, m = 0.9, wd = 0.0005, gs = 369.68
I0228 08:39:24.443264  7966 blocking_queue.cpp:40] Data layer prefetch queue empty
I0228 08:39:27.174286  7987 data_reader.cpp:178] Shuffling 1281167 records...
I0228 08:39:28.908802  7886 solver.cpp:347] Iteration 50700 (20.1177 iter/s, 4.97075s/100 iter), 81/90.9ep, loss = 1.42871
I0228 08:39:28.908953  7886 solver.cpp:371]     Train net output #0: loss = 1.42871 (* 1 = 1.42871 loss)
I0228 08:39:28.908967  7886 sgd_solver.cpp:170] Iteration 50700, lr = 0.0117878, m = 0.9, wd = 0.0005, gs = 374.87
I0228 08:39:33.961589  7886 solver.cpp:347] Iteration 50800 (19.7916 iter/s, 5.05266s/100 iter), 81.2/90.9ep, loss = 1.41406
I0228 08:39:33.961702  7886 solver.cpp:371]     Train net output #0: loss = 1.41406 (* 1 = 1.41406 loss)
I0228 08:39:33.961714  7886 sgd_solver.cpp:170] Iteration 50800, lr = 0.0114091, m = 0.9, wd = 0.0005, gs = 357.95
I0228 08:39:39.034080  7886 solver.cpp:347] Iteration 50900 (19.7144 iter/s, 5.07243s/100 iter), 81.4/90.9ep, loss = 1.40039
I0228 08:39:39.034296  7886 solver.cpp:371]     Train net output #0: loss = 1.40039 (* 1 = 1.40039 loss)
I0228 08:39:39.034308  7886 sgd_solver.cpp:170] Iteration 50900, lr = 0.0110365, m = 0.9, wd = 0.0005, gs = 385.2
I0228 08:39:44.053685  7886 solver.cpp:347] Iteration 51000 (19.9224 iter/s, 5.01949s/100 iter), 81.5/90.9ep, loss = 1.44922
I0228 08:39:44.053838  7886 solver.cpp:371]     Train net output #0: loss = 1.44922 (* 1 = 1.44922 loss)
I0228 08:39:44.053849  7886 sgd_solver.cpp:170] Iteration 51000, lr = 0.0106702, m = 0.9, wd = 0.0005, gs = 372.56
I0228 08:39:49.078533  7886 solver.cpp:347] Iteration 51100 (19.9014 iter/s, 5.02478s/100 iter), 81.7/90.9ep, loss = 1.59863
I0228 08:39:49.079149  7886 solver.cpp:371]     Train net output #0: loss = 1.59863 (* 1 = 1.59863 loss)
I0228 08:39:49.079170  7886 sgd_solver.cpp:170] Iteration 51100, lr = 0.0103101, m = 0.9, wd = 0.0005, gs = 380.48
I0228 08:39:54.027307  7886 solver.cpp:347] Iteration 51200 (20.2074 iter/s, 4.94868s/100 iter), 81.8/90.9ep, loss = 1.41211
I0228 08:39:54.027470  7886 solver.cpp:371]     Train net output #0: loss = 1.41211 (* 1 = 1.41211 loss)
I0228 08:39:54.027493  7886 sgd_solver.cpp:170] Iteration 51200, lr = 0.00995609, m = 0.9, wd = 0.0005, gs = 365.59
I0228 08:39:58.519125  7986 data_reader.cpp:178] Shuffling 1281167 records...
I0228 08:39:59.040225  7886 solver.cpp:347] Iteration 51300 (19.9487 iter/s, 5.01285s/100 iter), 82/90.9ep, loss = 1.5
I0228 08:39:59.040357  7886 solver.cpp:371]     Train net output #0: loss = 1.5 (* 1 = 1.5 loss)
I0228 08:39:59.040386  7886 sgd_solver.cpp:170] Iteration 51300, lr = 0.00960831, m = 0.9, wd = 0.0005, gs = 379.17
I0228 08:40:04.026314  7886 solver.cpp:347] Iteration 51400 (20.0562 iter/s, 4.986s/100 iter), 82.2/90.9ep, loss = 1.27051
I0228 08:40:04.026476  7886 solver.cpp:371]     Train net output #0: loss = 1.27051 (* 1 = 1.27051 loss)
I0228 08:40:04.026551  7886 sgd_solver.cpp:170] Iteration 51400, lr = 0.0092667, m = 0.9, wd = 0.0005, gs = 404.39
I0228 08:40:09.032327  7886 solver.cpp:347] Iteration 51500 (19.9762 iter/s, 5.00596s/100 iter), 82.3/90.9ep, loss = 1.57324
I0228 08:40:09.032447  7886 solver.cpp:371]     Train net output #0: loss = 1.57324 (* 1 = 1.57324 loss)
I0228 08:40:09.032457  7886 sgd_solver.cpp:170] Iteration 51500, lr = 0.00893129, m = 0.9, wd = 0.0005, gs = 391.85
I0228 08:40:14.032240  7886 solver.cpp:347] Iteration 51600 (20.0008 iter/s, 4.99979s/100 iter), 82.5/90.9ep, loss = 1.55469
I0228 08:40:14.032384  7886 solver.cpp:371]     Train net output #0: loss = 1.55469 (* 1 = 1.55469 loss)
I0228 08:40:14.032414  7886 sgd_solver.cpp:170] Iteration 51600, lr = 0.00860206, m = 0.9, wd = 0.0005, gs = 369.22
I0228 08:40:19.049063  7886 solver.cpp:347] Iteration 51700 (19.9333 iter/s, 5.01673s/100 iter), 82.6/90.9ep, loss = 1.54492
I0228 08:40:19.049201  7886 solver.cpp:371]     Train net output #0: loss = 1.54492 (* 1 = 1.54492 loss)
I0228 08:40:19.049212  7886 sgd_solver.cpp:170] Iteration 51700, lr = 0.008279, m = 0.9, wd = 0.0005, gs = 404.22
I0228 08:40:24.053762  7886 solver.cpp:347] Iteration 51800 (19.9814 iter/s, 5.00464s/100 iter), 82.8/90.9ep, loss = 1.38086
I0228 08:40:24.053905  7886 solver.cpp:371]     Train net output #0: loss = 1.38086 (* 1 = 1.38086 loss)
I0228 08:40:24.053967  7886 sgd_solver.cpp:170] Iteration 51800, lr = 0.00796213, m = 0.9, wd = 0.0005, gs = 387.83
I0228 08:40:29.047682  7886 solver.cpp:347] Iteration 51900 (20.0248 iter/s, 4.9938s/100 iter), 83/90.9ep, loss = 1.57617
I0228 08:40:29.048214  7886 solver.cpp:371]     Train net output #0: loss = 1.57617 (* 1 = 1.57617 loss)
I0228 08:40:29.048238  7886 sgd_solver.cpp:170] Iteration 51900, lr = 0.00765144, m = 0.9, wd = 0.0005, gs = 434.12
I0228 08:40:29.907570  7985 data_reader.cpp:178] Shuffling 1281167 records...
I0228 08:40:34.037508  7886 solver.cpp:347] Iteration 52000 (20.0411 iter/s, 4.98974s/100 iter), 83.1/90.9ep, loss = 1.47852
I0228 08:40:34.037664  7886 solver.cpp:371]     Train net output #0: loss = 1.47852 (* 1 = 1.47852 loss)
I0228 08:40:34.037684  7886 sgd_solver.cpp:170] Iteration 52000, lr = 0.00734694, m = 0.9, wd = 0.0005, gs = 424.8
I0228 08:40:39.017632  7886 solver.cpp:347] Iteration 52100 (20.0799 iter/s, 4.9801s/100 iter), 83.3/90.9ep, loss = 1.57812
I0228 08:40:39.017772  7886 solver.cpp:371]     Train net output #0: loss = 1.57812 (* 1 = 1.57812 loss)
I0228 08:40:39.017783  7886 sgd_solver.cpp:170] Iteration 52100, lr = 0.00704862, m = 0.9, wd = 0.0005, gs = 393.88
I0228 08:40:44.015480  7886 solver.cpp:347] Iteration 52200 (20.0091 iter/s, 4.99773s/100 iter), 83.4/90.9ep, loss = 1.34277
I0228 08:40:44.015668  7886 solver.cpp:371]     Train net output #0: loss = 1.34277 (* 1 = 1.34277 loss)
I0228 08:40:44.015678  7886 sgd_solver.cpp:170] Iteration 52200, lr = 0.00675648, m = 0.9, wd = 0.0005, gs = 365.78
I0228 08:40:49.026262  7886 solver.cpp:347] Iteration 52300 (19.9574 iter/s, 5.01066s/100 iter), 83.6/90.9ep, loss = 1.53516
I0228 08:40:49.026443  7886 solver.cpp:371]     Train net output #0: loss = 1.53516 (* 1 = 1.53516 loss)
I0228 08:40:49.026461  7886 sgd_solver.cpp:170] Iteration 52300, lr = 0.00647052, m = 0.9, wd = 0.0005, gs = 392.2
I0228 08:40:54.020764  7886 solver.cpp:347] Iteration 52400 (20.0222 iter/s, 4.99445s/100 iter), 83.8/90.9ep, loss = 1.4082
I0228 08:40:54.020962  7886 solver.cpp:371]     Train net output #0: loss = 1.4082 (* 1 = 1.4082 loss)
I0228 08:40:54.020992  7886 sgd_solver.cpp:170] Iteration 52400, lr = 0.00619075, m = 0.9, wd = 0.0005, gs = 393.82
I0228 08:40:59.008817  7886 solver.cpp:347] Iteration 52500 (20.0482 iter/s, 4.98797s/100 iter), 83.9/90.9ep, loss = 1.53516
I0228 08:40:59.008998  7886 solver.cpp:371]     Train net output #0: loss = 1.53516 (* 1 = 1.53516 loss)
I0228 08:40:59.009027  7886 sgd_solver.cpp:170] Iteration 52500, lr = 0.00591716, m = 0.9, wd = 0.0005, gs = 372.93
I0228 08:41:01.035096  7988 data_reader.cpp:178] Shuffling 1281167 records...
I0228 08:41:03.968422  7886 solver.cpp:347] Iteration 52600 (20.1634 iter/s, 4.95948s/100 iter), 84.1/90.9ep, loss = 1.15234
I0228 08:41:03.968600  7886 solver.cpp:371]     Train net output #0: loss = 1.15234 (* 1 = 1.15234 loss)
I0228 08:41:03.968612  7886 sgd_solver.cpp:170] Iteration 52600, lr = 0.00564976, m = 0.9, wd = 0.0005, gs = 396.91
I0228 08:41:08.978046  7886 solver.cpp:347] Iteration 52700 (19.9618 iter/s, 5.00957s/100 iter), 84.2/90.9ep, loss = 1.41113
I0228 08:41:08.978193  7886 solver.cpp:371]     Train net output #0: loss = 1.41113 (* 1 = 1.41113 loss)
I0228 08:41:08.978205  7886 sgd_solver.cpp:170] Iteration 52700, lr = 0.00538853, m = 0.9, wd = 0.0005, gs = 357.71
I0228 08:41:13.999997  7886 solver.cpp:347] Iteration 52800 (19.913 iter/s, 5.02184s/100 iter), 84.4/90.9ep, loss = 1.24023
I0228 08:41:14.000188  7886 solver.cpp:371]     Train net output #0: loss = 1.24023 (* 1 = 1.24023 loss)
I0228 08:41:14.000200  7886 sgd_solver.cpp:170] Iteration 52800, lr = 0.00513349, m = 0.9, wd = 0.0005, gs = 365.73
I0228 08:41:19.023347  7886 solver.cpp:347] Iteration 52900 (19.9074 iter/s, 5.02325s/100 iter), 84.6/90.9ep, loss = 1.29785
I0228 08:41:19.023496  7886 solver.cpp:371]     Train net output #0: loss = 1.29785 (* 1 = 1.29785 loss)
I0228 08:41:19.023509  7886 sgd_solver.cpp:170] Iteration 52900, lr = 0.00488462, m = 0.9, wd = 0.0005, gs = 365.93
I0228 08:41:24.020730  7886 solver.cpp:347] Iteration 53000 (20.0107 iter/s, 4.99732s/100 iter), 84.7/90.9ep, loss = 1.41309
I0228 08:41:24.020859  7886 solver.cpp:371]     Train net output #0: loss = 1.41309 (* 1 = 1.41309 loss)
I0228 08:41:24.020872  7886 sgd_solver.cpp:170] Iteration 53000, lr = 0.00464195, m = 0.9, wd = 0.0005, gs = 365.57
I0228 08:41:28.993660  7886 solver.cpp:347] Iteration 53100 (20.1092 iter/s, 4.97284s/100 iter), 84.9/90.9ep, loss = 1.68555
I0228 08:41:28.993808  7886 solver.cpp:371]     Train net output #0: loss = 1.68555 (* 1 = 1.68555 loss)
I0228 08:41:28.993822  7886 sgd_solver.cpp:170] Iteration 53100, lr = 0.00440546, m = 0.9, wd = 0.0005, gs = 347.47
I0228 08:41:32.428592  7988 data_reader.cpp:178] Shuffling 1281167 records...
I0228 08:41:34.013836  7886 solver.cpp:347] Iteration 53200 (19.9199 iter/s, 5.02011s/100 iter), 85/90.9ep, loss = 1.52344
I0228 08:41:34.013919  7886 solver.cpp:371]     Train net output #0: loss = 1.52344 (* 1 = 1.52344 loss)
I0228 08:41:34.013942  7886 sgd_solver.cpp:170] Iteration 53200, lr = 0.00417515, m = 0.9, wd = 0.0005, gs = 362.54
I0228 08:41:39.040225  7886 solver.cpp:347] Iteration 53300 (19.8953 iter/s, 5.0263s/100 iter), 85.2/90.9ep, loss = 1.46582
I0228 08:41:39.040329  7886 solver.cpp:371]     Train net output #0: loss = 1.46582 (* 1 = 1.46582 loss)
I0228 08:41:39.040340  7886 sgd_solver.cpp:170] Iteration 53300, lr = 0.00395102, m = 0.9, wd = 0.0005, gs = 347.3
I0228 08:41:44.026836  7886 solver.cpp:347] Iteration 53400 (20.0541 iter/s, 4.98651s/100 iter), 85.4/90.9ep, loss = 1.3457
I0228 08:41:44.027048  7886 solver.cpp:371]     Train net output #0: loss = 1.3457 (* 1 = 1.3457 loss)
I0228 08:41:44.027063  7886 sgd_solver.cpp:170] Iteration 53400, lr = 0.00373307, m = 0.9, wd = 0.0005, gs = 354.9
I0228 08:41:49.036954  7886 solver.cpp:347] Iteration 53500 (19.9603 iter/s, 5.00994s/100 iter), 85.5/90.9ep, loss = 1.31152
I0228 08:41:49.037168  7886 solver.cpp:371]     Train net output #0: loss = 1.31152 (* 1 = 1.31152 loss)
I0228 08:41:49.037181  7886 sgd_solver.cpp:170] Iteration 53500, lr = 0.00352131, m = 0.9, wd = 0.0005, gs = 377.95
I0228 08:41:54.054656  7886 solver.cpp:347] Iteration 53600 (19.9295 iter/s, 5.01768s/100 iter), 85.7/90.9ep, loss = 1.26562
I0228 08:41:54.054775  7886 solver.cpp:371]     Train net output #0: loss = 1.26562 (* 1 = 1.26562 loss)
I0228 08:41:54.054785  7886 sgd_solver.cpp:170] Iteration 53600, lr = 0.00331574, m = 0.9, wd = 0.0005, gs = 372.26
I0228 08:41:59.039767  7886 solver.cpp:347] Iteration 53700 (20.06 iter/s, 4.98504s/100 iter), 85.8/90.9ep, loss = 1.14551
I0228 08:41:59.039875  7886 solver.cpp:371]     Train net output #0: loss = 1.14551 (* 1 = 1.14551 loss)
I0228 08:41:59.039904  7886 sgd_solver.cpp:170] Iteration 53700, lr = 0.00311634, m = 0.9, wd = 0.0005, gs = 361.27
I0228 08:42:03.677333  7987 data_reader.cpp:178] Shuffling 1281167 records...
I0228 08:42:04.026451  7886 solver.cpp:347] Iteration 53800 (20.054 iter/s, 4.98654s/100 iter), 86/90.9ep, loss = 1.09961
I0228 08:42:04.026564  7886 solver.cpp:371]     Train net output #0: loss = 1.09961 (* 1 = 1.09961 loss)
I0228 08:42:04.026594  7886 sgd_solver.cpp:170] Iteration 53800, lr = 0.00292313, m = 0.9, wd = 0.0005, gs = 361.95
I0228 08:42:09.016829  7886 solver.cpp:347] Iteration 53900 (20.039 iter/s, 4.99027s/100 iter), 86.2/90.9ep, loss = 1.21289
I0228 08:42:09.016994  7886 solver.cpp:371]     Train net output #0: loss = 1.21289 (* 1 = 1.21289 loss)
I0228 08:42:09.017005  7886 sgd_solver.cpp:170] Iteration 53900, lr = 0.00273609, m = 0.9, wd = 0.0005, gs = 378.53
I0228 08:42:14.016752  7886 solver.cpp:347] Iteration 54000 (20.0005 iter/s, 4.99988s/100 iter), 86.3/90.9ep, loss = 1.13184
I0228 08:42:14.016922  7886 solver.cpp:371]     Train net output #0: loss = 1.13184 (* 1 = 1.13184 loss)
I0228 08:42:14.016950  7886 sgd_solver.cpp:170] Iteration 54000, lr = 0.00255525, m = 0.9, wd = 0.0005, gs = 357.86
I0228 08:42:16.483202  7981 blocking_queue.cpp:40] Data layer prefetch queue empty
I0228 08:42:19.056551  7886 solver.cpp:347] Iteration 54100 (19.8425 iter/s, 5.03969s/100 iter), 86.5/90.9ep, loss = 1.16602
I0228 08:42:19.056764  7886 solver.cpp:371]     Train net output #0: loss = 1.16602 (* 1 = 1.16602 loss)
I0228 08:42:19.056804  7886 sgd_solver.cpp:170] Iteration 54100, lr = 0.00238058, m = 0.9, wd = 0.0005, gs = 360.84
I0228 08:42:24.063169  7886 solver.cpp:347] Iteration 54200 (19.974 iter/s, 5.00652s/100 iter), 86.6/90.9ep, loss = 1.31348
I0228 08:42:24.063319  7886 solver.cpp:371]     Train net output #0: loss = 1.31348 (* 1 = 1.31348 loss)
I0228 08:42:24.063344  7886 sgd_solver.cpp:170] Iteration 54200, lr = 0.0022121, m = 0.9, wd = 0.0005, gs = 358.01
I0228 08:42:29.054018  7886 solver.cpp:347] Iteration 54300 (20.037 iter/s, 4.99078s/100 iter), 86.8/90.9ep, loss = 1.3418
I0228 08:42:29.054189  7886 solver.cpp:371]     Train net output #0: loss = 1.3418 (* 1 = 1.3418 loss)
I0228 08:42:29.054201  7886 sgd_solver.cpp:170] Iteration 54300, lr = 0.0020498, m = 0.9, wd = 0.0005, gs = 350.59
I0228 08:42:32.668586  7886 solver.cpp:513] Iteration 54374, Testing net (#0)
I0228 08:42:35.380210  7883 data_reader.cpp:320] Restarting data pre-fetching
I0228 08:42:35.461740  7886 solver.cpp:599]     Test net output #0: loss = 1.76149 (* 1 = 1.76149 loss)
I0228 08:42:35.461807  7886 solver.cpp:599]     Test net output #1: top-1 = 0.590813
I0228 08:42:35.461813  7886 solver.cpp:599]     Test net output #2: top-5 = 0.815604
I0228 08:42:35.461876  7886 solver.cpp:278] [MultiGPU] Tests completed in 6.40779s
I0228 08:42:35.519289  7886 solver.cpp:779] Snapshotting to binary proto file snapshots/alexnet_fp16_2K.91ep.0023_iter_54375_score0_1.76149_score1_0.590813_score2_0.815604.caffemodel
I0228 08:42:36.240206  7886 sgd_solver.cpp:396] Snapshotting solver state to binary proto file snapshots/alexnet_fp16_2K.91ep.0023_iter_54375.solverstate
I0228 08:42:37.999910  7886 solver.cpp:347] Iteration 54400 (15.606 iter/s, 6.40779s/100 iter), 87/90.9ep, loss = 1.33691
I0228 08:42:38.000079  7886 solver.cpp:371]     Train net output #0: loss = 1.33691 (* 1 = 1.33691 loss)
I0228 08:42:38.000126  7886 sgd_solver.cpp:170] Iteration 54400, lr = 0.00189368, m = 0.9, wd = 0.0005, gs = 396.2
I0228 08:42:38.868686  7985 data_reader.cpp:178] Shuffling 1281167 records...
I0228 08:42:43.007649  7886 solver.cpp:347] Iteration 54500 (19.9694 iter/s, 5.00767s/100 iter), 87.1/90.9ep, loss = 1.4375
I0228 08:42:43.007776  7886 solver.cpp:371]     Train net output #0: loss = 1.4375 (* 1 = 1.4375 loss)
I0228 08:42:43.007786  7886 sgd_solver.cpp:170] Iteration 54500, lr = 0.00174375, m = 0.9, wd = 0.0005, gs = 338
I0228 08:42:48.039742  7886 solver.cpp:347] Iteration 54600 (19.8729 iter/s, 5.03198s/100 iter), 87.3/90.9ep, loss = 1.18945
I0228 08:42:48.039872  7886 solver.cpp:371]     Train net output #0: loss = 1.18945 (* 1 = 1.18945 loss)
I0228 08:42:48.039903  7886 sgd_solver.cpp:170] Iteration 54600, lr = 0.0016, m = 0.9, wd = 0.0005, gs = 362.44
I0228 08:42:48.146591  7971 blocking_queue.cpp:40] Data layer prefetch queue empty
I0228 08:42:53.059628  7886 solver.cpp:347] Iteration 54700 (19.9212 iter/s, 5.01978s/100 iter), 87.4/90.9ep, loss = 1.24609
I0228 08:42:53.059808  7886 solver.cpp:371]     Train net output #0: loss = 1.24609 (* 1 = 1.24609 loss)
I0228 08:42:53.059820  7886 sgd_solver.cpp:170] Iteration 54700, lr = 0.00146243, m = 0.9, wd = 0.0005, gs = 361.18
I0228 08:42:58.041180  7886 solver.cpp:347] Iteration 54800 (20.0741 iter/s, 4.98155s/100 iter), 87.6/90.9ep, loss = 1.27637
I0228 08:42:58.041296  7886 solver.cpp:371]     Train net output #0: loss = 1.27637 (* 1 = 1.27637 loss)
I0228 08:42:58.041306  7886 sgd_solver.cpp:170] Iteration 54800, lr = 0.00133105, m = 0.9, wd = 0.0005, gs = 331.04
I0228 08:43:03.025262  7886 solver.cpp:347] Iteration 54900 (20.0642 iter/s, 4.984s/100 iter), 87.8/90.9ep, loss = 1.14355
I0228 08:43:03.025413  7886 solver.cpp:371]     Train net output #0: loss = 1.14355 (* 1 = 1.14355 loss)
I0228 08:43:03.025423  7886 sgd_solver.cpp:170] Iteration 54900, lr = 0.00120584, m = 0.9, wd = 0.0005, gs = 360.7
I0228 08:43:07.958003  7886 solver.cpp:513] Iteration 55000, Testing net (#0)
I0228 08:43:10.760774  7883 data_reader.cpp:320] Restarting data pre-fetching
I0228 08:43:10.783457  7886 solver.cpp:599]     Test net output #0: loss = 1.70089 (* 1 = 1.70089 loss)
I0228 08:43:10.783478  7886 solver.cpp:599]     Test net output #1: top-1 = 0.59978
I0228 08:43:10.783499  7886 solver.cpp:599]     Test net output #2: top-5 = 0.820888
I0228 08:43:10.783944  7886 solver.cpp:278] [MultiGPU] Tests completed in 7.75858s
I0228 08:43:10.834022  7886 solver.cpp:347] Iteration 55000 (12.8889 iter/s, 7.75858s/100 iter), 87.9/90.9ep, loss = 1.2793
I0228 08:43:10.834146  7886 solver.cpp:371]     Train net output #0: loss = 1.2793 (* 1 = 1.2793 loss)
I0228 08:43:10.834158  7886 sgd_solver.cpp:170] Iteration 55000, lr = 0.00108683, m = 0.9, wd = 0.0005, gs = 344.22
I0228 08:43:10.834177  7886 solver.cpp:779] Snapshotting to binary proto file snapshots/alexnet_fp16_2K.91ep.0023_iter_55001_score0_1.70089_score1_0.59978_score2_0.820888.caffemodel
I0228 08:43:11.476761  7886 sgd_solver.cpp:396] Snapshotting solver state to binary proto file snapshots/alexnet_fp16_2K.91ep.0023_iter_55001.solverstate
I0228 08:43:14.114707  7988 data_reader.cpp:178] Shuffling 1281167 records...
I0228 08:43:16.893932  7886 solver.cpp:347] Iteration 55100 (16.5022 iter/s, 6.05981s/100 iter), 88.1/90.9ep, loss = 1.13086
I0228 08:43:16.894140  7886 solver.cpp:371]     Train net output #0: loss = 1.13086 (* 1 = 1.13086 loss)
I0228 08:43:16.894151  7886 sgd_solver.cpp:170] Iteration 55100, lr = 0.00097399, m = 0.9, wd = 0.0005, gs = 338.31
I0228 08:43:19.401861  7974 blocking_queue.cpp:40] Data layer prefetch queue empty
I0228 08:43:21.925382  7886 solver.cpp:347] Iteration 55200 (19.8754 iter/s, 5.03134s/100 iter), 88.2/90.9ep, loss = 1.1582
I0228 08:43:21.925498  7886 solver.cpp:371]     Train net output #0: loss = 1.1582 (* 1 = 1.1582 loss)
I0228 08:43:21.925519  7886 sgd_solver.cpp:170] Iteration 55200, lr = 0.000867334, m = 0.9, wd = 0.0005, gs = 349.9
I0228 08:43:26.953246  7886 solver.cpp:347] Iteration 55300 (19.8898 iter/s, 5.02771s/100 iter), 88.4/90.9ep, loss = 1.1377
I0228 08:43:26.953410  7886 solver.cpp:371]     Train net output #0: loss = 1.1377 (* 1 = 1.1377 loss)
I0228 08:43:26.953445  7886 sgd_solver.cpp:170] Iteration 55300, lr = 0.000766864, m = 0.9, wd = 0.0005, gs = 339.24
I0228 08:43:31.935688  7886 solver.cpp:347] Iteration 55400 (20.0706 iter/s, 4.9824s/100 iter), 88.6/90.9ep, loss = 1.30469
I0228 08:43:31.935868  7886 solver.cpp:371]     Train net output #0: loss = 1.30469 (* 1 = 1.30469 loss)
I0228 08:43:31.935880  7886 sgd_solver.cpp:170] Iteration 55400, lr = 0.000672574, m = 0.9, wd = 0.0005, gs = 341.37
I0228 08:43:36.924584  7886 solver.cpp:347] Iteration 55500 (20.0452 iter/s, 4.98873s/100 iter), 88.7/90.9ep, loss = 1.27539
I0228 08:43:36.924793  7886 solver.cpp:371]     Train net output #0: loss = 1.27539 (* 1 = 1.27539 loss)
I0228 08:43:36.924836  7886 sgd_solver.cpp:170] Iteration 55500, lr = 0.00058447, m = 0.9, wd = 0.0005, gs = 348.91
I0228 08:43:41.912451  7886 solver.cpp:347] Iteration 55600 (20.0488 iter/s, 4.98782s/100 iter), 88.9/90.9ep, loss = 1.25195
I0228 08:43:41.912991  7886 solver.cpp:371]     Train net output #0: loss = 1.25195 (* 1 = 1.25195 loss)
I0228 08:43:41.913015  7886 sgd_solver.cpp:170] Iteration 55600, lr = 0.000502549, m = 0.9, wd = 0.0005, gs = 352.59
I0228 08:43:43.092877  7886 solver.cpp:513] Iteration 55625, Testing net (#0)
I0228 08:43:45.803098  7883 data_reader.cpp:320] Restarting data pre-fetching
I0228 08:43:45.901948  7886 solver.cpp:599]     Test net output #0: loss = 1.71846 (* 1 = 1.71846 loss)
I0228 08:43:45.901983  7886 solver.cpp:599]     Test net output #1: top-1 = 0.584413
I0228 08:43:45.902006  7886 solver.cpp:599]     Test net output #2: top-5 = 0.818808
I0228 08:43:45.902038  7886 solver.cpp:278] [MultiGPU] Tests completed in 3.98955s
I0228 08:43:45.948067  7886 solver.cpp:779] Snapshotting to binary proto file snapshots/alexnet_fp16_2K.91ep.0023_iter_55626_score0_1.71846_score1_0.584413_score2_0.818808.caffemodel
I0228 08:43:46.604426  7886 sgd_solver.cpp:396] Snapshotting solver state to binary proto file snapshots/alexnet_fp16_2K.91ep.0023_iter_55626.solverstate
I0228 08:43:49.203833  7985 data_reader.cpp:178] Shuffling 1281167 records...
I0228 08:43:50.762641  7886 solver.cpp:347] Iteration 55700 (25.0655 iter/s, 3.98955s/100 iter), 89/90.9ep, loss = 1.19922
I0228 08:43:50.762753  7886 solver.cpp:371]     Train net output #0: loss = 1.19922 (* 1 = 1.19922 loss)
I0228 08:43:50.762764  7886 sgd_solver.cpp:170] Iteration 55700, lr = 0.000426808, m = 0.9, wd = 0.0005, gs = 357.65
I0228 08:43:51.069310  7966 blocking_queue.cpp:40] Data layer prefetch queue empty
I0228 08:43:55.779626  7886 solver.cpp:347] Iteration 55800 (19.9327 iter/s, 5.01689s/100 iter), 89.2/90.9ep, loss = 1.36328
I0228 08:43:55.779774  7886 solver.cpp:371]     Train net output #0: loss = 1.36328 (* 1 = 1.36328 loss)
I0228 08:43:55.779796  7886 sgd_solver.cpp:170] Iteration 55800, lr = 0.000357252, m = 0.9, wd = 0.0005, gs = 327
I0228 08:44:00.776804  7886 solver.cpp:347] Iteration 55900 (20.0116 iter/s, 4.99709s/100 iter), 89.4/90.9ep, loss = 1.31152
I0228 08:44:00.776952  7886 solver.cpp:371]     Train net output #0: loss = 1.31152 (* 1 = 1.31152 loss)
I0228 08:44:00.776965  7886 sgd_solver.cpp:170] Iteration 55900, lr = 0.000293877, m = 0.9, wd = 0.0005, gs = 343.45
I0228 08:44:05.760143  7886 solver.cpp:347] Iteration 56000 (20.0674 iter/s, 4.98321s/100 iter), 89.5/90.9ep, loss = 1.32422
I0228 08:44:05.760313  7886 solver.cpp:371]     Train net output #0: loss = 1.32422 (* 1 = 1.32422 loss)
I0228 08:44:05.760324  7886 sgd_solver.cpp:170] Iteration 56000, lr = 0.000236686, m = 0.9, wd = 0.0005, gs = 355.3
I0228 08:44:10.712919  7886 solver.cpp:347] Iteration 56100 (20.1909 iter/s, 4.95274s/100 iter), 89.7/90.9ep, loss = 1.0459
I0228 08:44:10.713070  7886 solver.cpp:371]     Train net output #0: loss = 1.0459 (* 1 = 1.0459 loss)
I0228 08:44:10.713093  7886 sgd_solver.cpp:170] Iteration 56100, lr = 0.000185679, m = 0.9, wd = 0.0005, gs = 346.53
I0228 08:44:15.666239  7886 solver.cpp:347] Iteration 56200 (20.1891 iter/s, 4.95318s/100 iter), 89.8/90.9ep, loss = 1.18555
I0228 08:44:15.666800  7886 solver.cpp:371]     Train net output #0: loss = 1.18555 (* 1 = 1.18555 loss)
I0228 08:44:15.666816  7886 sgd_solver.cpp:170] Iteration 56200, lr = 0.000140852, m = 0.9, wd = 0.0005, gs = 335.93
I0228 08:44:18.139814  7886 solver.cpp:513] Iteration 56251, Testing net (#0)
I0228 08:44:20.862222  7883 data_reader.cpp:320] Restarting data pre-fetching
I0228 08:44:20.909426  7886 solver.cpp:599]     Test net output #0: loss = 1.73859 (* 1 = 1.73859 loss)
I0228 08:44:20.909474  7886 solver.cpp:599]     Test net output #1: top-1 = 0.596735
I0228 08:44:20.909482  7886 solver.cpp:599]     Test net output #2: top-5 = 0.817848
I0228 08:44:20.909875  7886 solver.cpp:278] [MultiGPU] Tests completed in 5.24362s
I0228 08:44:20.954414  7886 solver.cpp:779] Snapshotting to binary proto file snapshots/alexnet_fp16_2K.91ep.0023_iter_56252_score0_1.73859_score1_0.596735_score2_0.817848.caffemodel
I0228 08:44:21.556751  7886 sgd_solver.cpp:396] Snapshotting solver state to binary proto file snapshots/alexnet_fp16_2K.91ep.0023_iter_56252.solverstate
I0228 08:44:22.828577  7966 blocking_queue.cpp:40] Data layer prefetch queue empty
I0228 08:44:24.206732  7990 data_reader.cpp:178] Shuffling 1281167 records...
I0228 08:44:24.367076  7886 solver.cpp:347] Iteration 56300 (19.0708 iter/s, 5.24362s/100 iter), 90/90.9ep, loss = 1.2998
I0228 08:44:24.367322  7886 solver.cpp:371]     Train net output #0: loss = 1.2998 (* 1 = 1.2998 loss)
I0228 08:44:24.367336  7886 sgd_solver.cpp:170] Iteration 56300, lr = 0.00010221, m = 0.9, wd = 0.0005, gs = 338.03
I0228 08:44:29.378639  7886 solver.cpp:347] Iteration 56400 (19.9542 iter/s, 5.01148s/100 iter), 90.2/90.9ep, loss = 1.17383
I0228 08:44:29.378806  7886 solver.cpp:371]     Train net output #0: loss = 1.17383 (* 1 = 1.17383 loss)
I0228 08:44:29.378819  7886 sgd_solver.cpp:170] Iteration 56400, lr = 6.97496e-05, m = 0.9, wd = 0.0005, gs = 328.23
I0228 08:44:34.405339  7886 solver.cpp:347] Iteration 56500 (19.8942 iter/s, 5.02659s/100 iter), 90.3/90.9ep, loss = 1.2041
I0228 08:44:34.405504  7886 solver.cpp:371]     Train net output #0: loss = 1.2041 (* 1 = 1.2041 loss)
I0228 08:44:34.405514  7886 sgd_solver.cpp:170] Iteration 56500, lr = 4.3473e-05, m = 0.9, wd = 0.0005, gs = 336.2
I0228 08:44:39.442399  7886 solver.cpp:347] Iteration 56600 (19.8533 iter/s, 5.03695s/100 iter), 90.5/90.9ep, loss = 1.05566
I0228 08:44:39.442539  7886 solver.cpp:371]     Train net output #0: loss = 1.05566 (* 1 = 1.05566 loss)
I0228 08:44:39.442589  7886 sgd_solver.cpp:170] Iteration 56600, lr = 2.3379e-05, m = 0.9, wd = 0.0005, gs = 340.18
I0228 08:44:44.426537  7886 solver.cpp:347] Iteration 56700 (20.0638 iter/s, 4.98409s/100 iter), 90.6/90.9ep, loss = 1.08789
I0228 08:44:44.426682  7886 solver.cpp:371]     Train net output #0: loss = 1.08789 (* 1 = 1.08789 loss)
I0228 08:44:44.426694  7886 sgd_solver.cpp:170] Iteration 56700, lr = 1e-05, m = 0.9, wd = 0.0005, gs = 322.47
I0228 08:44:49.405946  7886 solver.cpp:347] Iteration 56800 (20.0831 iter/s, 4.9793s/100 iter), 90.8/90.9ep, loss = 1.06152
I0228 08:44:49.406524  7886 solver.cpp:371]     Train net output #0: loss = 1.06152 (* 1 = 1.06152 loss)
I0228 08:44:49.406548  7886 sgd_solver.cpp:170] Iteration 56800, lr = 1e-05, m = 0.9, wd = 0.0005, gs = 335.69
I0228 08:44:53.019361  7886 solver.cpp:513] Iteration 56874, Testing net (#0)
I0228 08:44:55.676580  7882 blocking_queue.cpp:40] Data layer prefetch queue empty
I0228 08:44:55.729846  7883 data_reader.cpp:320] Restarting data pre-fetching
I0228 08:44:55.758558  7886 solver.cpp:599]     Test net output #0: loss = 1.6905 (* 1 = 1.6905 loss)
I0228 08:44:55.758590  7886 solver.cpp:599]     Test net output #1: top-1 = 0.601378
I0228 08:44:55.758613  7886 solver.cpp:599]     Test net output #2: top-5 = 0.821047
I0228 08:44:55.759001  7886 solver.cpp:278] [MultiGPU] Tests completed in 6.35301s
I0228 08:44:55.814393  7886 solver.cpp:347] Iteration 56874 (11.648 iter/s, 6.35301s/74 iter), 90.9/90.9ep, loss = 1.20801
I0228 08:44:55.814509  7886 solver.cpp:371]     Train net output #0: loss = 1.20801 (* 1 = 1.20801 loss)
I0228 08:44:55.814527  7886 solver.cpp:779] Snapshotting to binary proto file snapshots/alexnet_fp16_2K.91ep.0023_iter_56875_score0_1.6905_score1_0.601378_score2_0.821047.caffemodel
I0228 08:44:56.448729  7886 sgd_solver.cpp:396] Snapshotting solver state to binary proto file snapshots/alexnet_fp16_2K.91ep.0023_iter_56875.solverstate
I0228 08:44:56.839730  7805 parallel.cpp:67] Root Solver performance on device 0: 19.88 * 256 = 5089 img/sec (56875 itr in 2861 sec)
I0228 08:44:56.839762  7805 parallel.cpp:72]      Solver performance on device 1: 19.88 * 256 = 5089 img/sec (56875 itr in 2861 sec)
I0228 08:44:56.839771  7805 parallel.cpp:72]      Solver performance on device 2: 19.88 * 256 = 5089 img/sec (56875 itr in 2861 sec)
I0228 08:44:56.839776  7805 parallel.cpp:72]      Solver performance on device 3: 19.88 * 256 = 5089 img/sec (56875 itr in 2861 sec)
I0228 08:44:56.839781  7805 parallel.cpp:72]      Solver performance on device 4: 19.88 * 256 = 5089 img/sec (56875 itr in 2861 sec)
I0228 08:44:56.839787  7805 parallel.cpp:72]      Solver performance on device 5: 19.88 * 256 = 5089 img/sec (56875 itr in 2861 sec)
I0228 08:44:56.839792  7805 parallel.cpp:72]      Solver performance on device 6: 19.88 * 256 = 5089 img/sec (56875 itr in 2861 sec)
I0228 08:44:56.839797  7805 parallel.cpp:72]      Solver performance on device 7: 19.88 * 256 = 5089 img/sec (56875 itr in 2861 sec)
I0228 08:44:56.839799  7805 parallel.cpp:75] Overall multi-GPU performance: 40708.3 img/sec
I0228 08:45:03.395539  7805 caffe.cpp:237] Optimization Done in 48m 26s
